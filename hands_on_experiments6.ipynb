{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improve experiment 3 on Kanerva side (To generate Kanerva points adaptive to the previous q-table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "prototypes = np.random.rand(10, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import gym_puddle\n",
    "import numpy as np\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.dqn import MlpPolicy as DQNPolicy\n",
    "from stable_baselines3.ppo import MlpPolicy as PPOPolicy\n",
    "\n",
    "import time\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from IPython import display\n",
    "import pyvirtualdisplay\n",
    "import cv2\n",
    "\n",
    "import libs.tiles3 as tc\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_seed = 0\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#some functions to help the visualization and interaction wit the environment\n",
    "\n",
    "def visualize(frames, video_name = \"/Video/video.mp4\"):\n",
    "    # Saves the frames as an mp4 video using cv2\n",
    "    video_path = video_name\n",
    "    height, width, _ = frames[0].shape\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    video_writer = cv2.VideoWriter(video_path, fourcc, 30, (width, height))\n",
    "    for frame in frames:\n",
    "        video_writer.write(frame)\n",
    "    video_writer.release()\n",
    "\n",
    "def online_rendering(image):\n",
    "    #Visualize one frame of the image in a display\n",
    "    ax.axis('off')\n",
    "    img_with_frame = np.zeros((image.shape[0]+2, image.shape[1]+2, 3), dtype=np.uint8)\n",
    "    img_with_frame[1:-1, 1:-1, :] = image\n",
    "    ax.imshow(img_with_frame)\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "\n",
    "\n",
    "def prepare_display():\n",
    "  #Prepares display for onine rendering of the frames in the game\n",
    "  _display = pyvirtualdisplay.Display(visible=False,size=(1400, 900))\n",
    "  _ = _display.start()\n",
    "  fig, ax = plt.subplots(figsize=(5, 5))\n",
    "  ax.axis('off')\n",
    "\n",
    "\n",
    "def get_action():\n",
    "    action = None\n",
    "    while action not in [\"w\", \"a\", \"s\", \"d\", \"W\", \"A\", \"S\", \"D\"]:\n",
    "        action = input(\"Enter action (w/a/s/d): \")\n",
    "    if action == \"w\":\n",
    "        return 3\n",
    "    elif action == \"a\":\n",
    "        return 0\n",
    "    elif action == \"s\":\n",
    "        return 2\n",
    "    elif action == \"d\":\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Different Environment Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "json_file = f\"/Users/hadiaghazadeh/Library/CloudStorage/OneDrive-UniversityofCalgary/@upperboundCompetition/gym-puddle/gym_puddle/env_configs/pw1.json\"\n",
    "\n",
    "with open(json_file) as f:\n",
    "  env_setup = json.load(f)\n",
    "\n",
    "\n",
    "env = gym.make(\n",
    "  \"PuddleWorld-v0\",\n",
    "  start=env_setup[\"start\"],\n",
    "  goal=env_setup[\"goal\"],\n",
    "  goal_threshold=env_setup[\"goal_threshold\"],\n",
    "  noise=env_setup[\"noise\"],\n",
    "  thrust=env_setup[\"thrust\"],\n",
    "  puddle_top_left=env_setup[\"puddle_top_left\"],\n",
    "  puddle_width=env_setup[\"puddle_width\"],\n",
    ")\n",
    "\n",
    "\n",
    "obs, info = env.reset()\n",
    "image = env.render()\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "online_rendering(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start position: [0.2 0.4]\n",
      "goal position: [1. 1.]\n",
      "goal threshold: 0.1\n",
      "action noise: 0.01\n",
      "agent's thrust: 0.05\n",
      "puddle top left positions: [array([0.  , 0.85]), array([0.35, 0.9 ])]\n",
      "puddle widths and heights: [array([0.55, 0.2 ]), array([0.2, 0.6])]\n",
      "action space: [array([-0.05,  0.  ]), array([0.05, 0.  ]), array([ 0.  , -0.05]), array([0.  , 0.05])]\n",
      "observation space: Box(0.0, 1.0, (2,), float64)\n"
     ]
    }
   ],
   "source": [
    "print(\"start position:\", env.get_wrapper_attr(\"start\"))\n",
    "print(\"goal position:\", env.get_wrapper_attr(\"goal\"))\n",
    "print(\"goal threshold:\", env.get_wrapper_attr(\"goal_threshold\"))\n",
    "print(\"action noise:\", env.get_wrapper_attr(\"noise\"))\n",
    "print(\"agent's thrust:\", env.get_wrapper_attr(\"thrust\"))\n",
    "print(\"puddle top left positions:\", env.get_wrapper_attr(\"puddle_top_left\"))\n",
    "print(\"puddle widths and heights:\", env.get_wrapper_attr(\"puddle_width\"))\n",
    "print(\"action space:\", env.get_wrapper_attr(\"actions\"))\n",
    "print(\"observation space:\", env.get_wrapper_attr(\"observation_space\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling from State Sapce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "import sklearn.preprocessing\n",
    "                                    \n",
    "state_space_samples = np.array(\n",
    "    [env.observation_space.sample() for x in range(10000)])\n",
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "scaler.fit(state_space_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kanerva coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([408, 820, 555, 117, 286,  32, 278, 592])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from util.kanerva import BaseKanervaCoder\n",
    "from util.kanerva import BaseKanervaCoder\n",
    "\n",
    "num_features = 1500\n",
    "n_closest = 8\n",
    "rep = BaseKanervaCoder(env.observation_space, n_prototypes= num_features, n_closest= n_closest, random_seed= selected_seed)\n",
    "rep.get_features(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tabularQlearning:\n",
    "    def __init__(self, num_feature, num_actions, alpha=0.1, gamma=0.9, epsilon=0.05, seed = selected_seed):\n",
    "        self.num_feature = num_feature\n",
    "        self.num_actions = num_actions\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    \n",
    "        self.q_table = np.zeros((self.num_feature, self.num_actions))  \n",
    "\n",
    "        self.seed = seed    \n",
    "        # Set random seed\n",
    "        np.random.seed(self.seed)\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        \"\"\"Choose an action using epsilon-greedy policy\"\"\"\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            return np.random.choice(self.num_actions)\n",
    "        else:\n",
    "            q = self.q_table[state].sum(axis=0)\n",
    "            return q.argmax()\n",
    "    \n",
    "    def update(self, state, action, reward, next_state):\n",
    "        \"\"\"Update the Q-table using the Q-learning update rule\"\"\"\n",
    "        self.q_table[state, action] += self.alpha * (reward + self.gamma * np.max(self.q_table[next_state]) - self.q_table[state, action])\n",
    "    \n",
    "    def get_q_table(self):\n",
    "        return self.q_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0, Total Reward: -6389.192653715536\n",
      "Episode 20, Total Reward: -599\n",
      "Episode 40, Total Reward: -2902\n",
      "Episode 60, Total Reward: -196\n",
      "Episode 80, Total Reward: -160\n",
      "Episode 100, Total Reward: -1434\n",
      "Episode 120, Total Reward: -317\n",
      "Episode 140, Total Reward: -558.9015634015745\n",
      "Episode 160, Total Reward: -122\n",
      "Episode 180, Total Reward: -517.0388104165798\n",
      "Episode 200, Total Reward: -79\n",
      "Episode 220, Total Reward: -50\n",
      "Episode 240, Total Reward: -113\n",
      "Episode 260, Total Reward: -155\n",
      "Episode 280, Total Reward: -1793.9230658930092\n",
      "Episode 300, Total Reward: -1943.8772953378566\n",
      "Episode 320, Total Reward: -50\n",
      "Episode 340, Total Reward: -581\n",
      "Episode 360, Total Reward: -123\n",
      "Episode 380, Total Reward: -60\n",
      "Episode 400, Total Reward: -190\n",
      "Episode 420, Total Reward: -82\n",
      "Episode 440, Total Reward: -162\n",
      "Episode 460, Total Reward: -81\n",
      "Episode 480, Total Reward: -619.0566124727613\n",
      "Episode 500, Total Reward: -113\n",
      "Episode 520, Total Reward: -45\n",
      "Episode 540, Total Reward: -33\n",
      "Episode 560, Total Reward: -70\n",
      "Episode 580, Total Reward: -38\n",
      "Episode 600, Total Reward: -38\n",
      "Episode 620, Total Reward: -103\n",
      "Episode 640, Total Reward: -39\n",
      "Episode 660, Total Reward: -64\n",
      "Episode 680, Total Reward: -258\n",
      "Episode 700, Total Reward: -32\n",
      "Episode 720, Total Reward: -35\n",
      "Episode 740, Total Reward: -45\n",
      "Episode 760, Total Reward: -46\n",
      "Episode 780, Total Reward: -30\n",
      "Episode 800, Total Reward: -37\n",
      "Episode 820, Total Reward: -34\n",
      "Episode 840, Total Reward: -34\n",
      "Episode 860, Total Reward: -34\n",
      "Episode 880, Total Reward: -37\n",
      "Episode 900, Total Reward: -41\n",
      "Episode 920, Total Reward: -40\n",
      "Episode 940, Total Reward: -37\n",
      "Episode 960, Total Reward: -33\n",
      "Episode 980, Total Reward: -38\n",
      "Episode 1000, Total Reward: -38\n",
      "Episode 1020, Total Reward: -40\n",
      "Episode 1040, Total Reward: -36\n",
      "Episode 1060, Total Reward: -37\n",
      "Episode 1080, Total Reward: -32\n",
      "Episode 1100, Total Reward: -33\n",
      "Episode 1120, Total Reward: -37\n",
      "Episode 1140, Total Reward: -32\n",
      "Episode 1160, Total Reward: -37\n",
      "Episode 1180, Total Reward: -46\n",
      "Episode 1200, Total Reward: -47\n",
      "Episode 1220, Total Reward: -52\n",
      "Episode 1240, Total Reward: -34\n",
      "Episode 1260, Total Reward: -47\n",
      "Episode 1280, Total Reward: -51\n",
      "Episode 1300, Total Reward: -41\n",
      "Episode 1320, Total Reward: -49\n",
      "Episode 1340, Total Reward: -120\n",
      "Episode 1360, Total Reward: -41\n",
      "Episode 1380, Total Reward: -117\n",
      "Episode 1400, Total Reward: -46\n",
      "Episode 1420, Total Reward: -45\n",
      "Episode 1440, Total Reward: -39\n",
      "Episode 1460, Total Reward: -40\n",
      "Episode 1480, Total Reward: -41\n",
      "Episode 1500, Total Reward: -40\n",
      "Episode 1520, Total Reward: -34\n",
      "Episode 1540, Total Reward: -34\n",
      "Episode 1560, Total Reward: -33\n",
      "Episode 1580, Total Reward: -42\n",
      "Episode 1600, Total Reward: -34\n",
      "Episode 1620, Total Reward: -31\n",
      "Episode 1640, Total Reward: -49\n",
      "Episode 1660, Total Reward: -37\n",
      "Episode 1680, Total Reward: -33\n",
      "Episode 1700, Total Reward: -38\n",
      "Episode 1720, Total Reward: -35\n",
      "Episode 1740, Total Reward: -38\n",
      "Episode 1760, Total Reward: -41\n",
      "Episode 1780, Total Reward: -35\n",
      "Episode 1800, Total Reward: -35\n",
      "Episode 1820, Total Reward: -42\n",
      "Episode 1840, Total Reward: -37\n",
      "Episode 1860, Total Reward: -36\n",
      "Episode 1880, Total Reward: -31\n",
      "Episode 1900, Total Reward: -29\n",
      "Episode 1920, Total Reward: -37\n",
      "Episode 1940, Total Reward: -33\n",
      "Episode 1960, Total Reward: -34\n",
      "Episode 1980, Total Reward: -279.8131655848418\n",
      "Episode 2000, Total Reward: -39\n",
      "Episode 2020, Total Reward: -32\n",
      "Episode 2040, Total Reward: -52\n",
      "Episode 2060, Total Reward: -34\n",
      "Episode 2080, Total Reward: -85\n",
      "Episode 2100, Total Reward: -34\n",
      "Episode 2120, Total Reward: -38\n",
      "Episode 2140, Total Reward: -35\n",
      "Episode 2160, Total Reward: -38\n",
      "Episode 2180, Total Reward: -38\n",
      "Episode 2200, Total Reward: -40\n",
      "Episode 2220, Total Reward: -34\n",
      "Episode 2240, Total Reward: -33\n",
      "Episode 2260, Total Reward: -34\n",
      "Episode 2280, Total Reward: -34\n",
      "Episode 2300, Total Reward: -39\n",
      "Episode 2320, Total Reward: -34\n",
      "Episode 2340, Total Reward: -33\n",
      "Episode 2360, Total Reward: -37\n",
      "Episode 2380, Total Reward: -41\n",
      "Episode 2400, Total Reward: -35\n",
      "Episode 2420, Total Reward: -32\n",
      "Episode 2440, Total Reward: -35\n",
      "Episode 2460, Total Reward: -36\n",
      "Episode 2480, Total Reward: -38\n",
      "Episode 2500, Total Reward: -34\n",
      "Episode 2520, Total Reward: -35\n",
      "Episode 2540, Total Reward: -36\n",
      "Episode 2560, Total Reward: -35\n",
      "Episode 2580, Total Reward: -37\n",
      "Episode 2600, Total Reward: -36\n",
      "Episode 2620, Total Reward: -36\n",
      "Episode 2640, Total Reward: -35\n",
      "Episode 2660, Total Reward: -33\n",
      "Episode 2680, Total Reward: -33\n",
      "Episode 2700, Total Reward: -45\n",
      "Episode 2720, Total Reward: -39\n",
      "Episode 2740, Total Reward: -36\n",
      "Episode 2760, Total Reward: -34\n",
      "Episode 2780, Total Reward: -37\n",
      "Episode 2800, Total Reward: -33\n",
      "Episode 2820, Total Reward: -36\n",
      "Episode 2840, Total Reward: -41\n",
      "Episode 2860, Total Reward: -40\n",
      "Episode 2880, Total Reward: -33\n",
      "Episode 2900, Total Reward: -40\n",
      "Episode 2920, Total Reward: -36\n",
      "Episode 2940, Total Reward: -39\n",
      "Episode 2960, Total Reward: -37\n",
      "Episode 2980, Total Reward: -39\n",
      "Episode 3000, Total Reward: -35\n",
      "Episode 3020, Total Reward: -35\n",
      "Episode 3040, Total Reward: -37\n",
      "Episode 3060, Total Reward: -37\n",
      "Episode 3080, Total Reward: -39\n",
      "Episode 3100, Total Reward: -273.658203120778\n",
      "Episode 3120, Total Reward: -39\n",
      "Episode 3140, Total Reward: -36\n",
      "Episode 3160, Total Reward: -34\n",
      "Episode 3180, Total Reward: -34\n",
      "Episode 3200, Total Reward: -41\n",
      "Episode 3220, Total Reward: -36\n",
      "Episode 3240, Total Reward: -32\n",
      "Episode 3260, Total Reward: -30\n",
      "Episode 3280, Total Reward: -32\n",
      "Episode 3300, Total Reward: -35\n",
      "Episode 3320, Total Reward: -33\n",
      "Episode 3340, Total Reward: -35\n",
      "Episode 3360, Total Reward: -47\n",
      "Episode 3380, Total Reward: -37\n",
      "Episode 3400, Total Reward: -32\n",
      "Episode 3420, Total Reward: -35\n",
      "Episode 3440, Total Reward: -36\n",
      "Episode 3460, Total Reward: -42\n",
      "Episode 3480, Total Reward: -40\n",
      "Episode 3500, Total Reward: -40\n",
      "Episode 3520, Total Reward: -211.82823855078772\n",
      "Episode 3540, Total Reward: -35\n",
      "Episode 3560, Total Reward: -34\n",
      "Episode 3580, Total Reward: -33\n",
      "Episode 3600, Total Reward: -35\n",
      "Episode 3620, Total Reward: -38\n",
      "Episode 3640, Total Reward: -30\n",
      "Episode 3660, Total Reward: -36\n",
      "Episode 3680, Total Reward: -37\n",
      "Episode 3700, Total Reward: -33\n",
      "Episode 3720, Total Reward: -32\n",
      "Episode 3740, Total Reward: -38\n",
      "Episode 3760, Total Reward: -37\n",
      "Episode 3780, Total Reward: -32\n",
      "Episode 3800, Total Reward: -39\n",
      "Episode 3820, Total Reward: -33\n",
      "Episode 3840, Total Reward: -35\n",
      "Episode 3860, Total Reward: -34\n",
      "Episode 3880, Total Reward: -34\n",
      "Episode 3900, Total Reward: -37\n",
      "Episode 3920, Total Reward: -34\n",
      "Episode 3940, Total Reward: -40\n",
      "Episode 3960, Total Reward: -35\n",
      "Episode 3980, Total Reward: -33\n",
      "Episode 4000, Total Reward: -36\n",
      "Episode 4020, Total Reward: -40\n",
      "Episode 4040, Total Reward: -36\n",
      "Episode 4060, Total Reward: -34\n",
      "Episode 4080, Total Reward: -36\n",
      "Episode 4100, Total Reward: -40\n",
      "Episode 4120, Total Reward: -38\n",
      "Episode 4140, Total Reward: -37\n",
      "Episode 4160, Total Reward: -39\n",
      "Episode 4180, Total Reward: -33\n",
      "Episode 4200, Total Reward: -35\n",
      "Episode 4220, Total Reward: -34\n",
      "Episode 4240, Total Reward: -34\n",
      "Episode 4260, Total Reward: -37\n",
      "Episode 4280, Total Reward: -37\n",
      "Episode 4300, Total Reward: -34\n",
      "Episode 4320, Total Reward: -35\n",
      "Episode 4340, Total Reward: -32\n",
      "Episode 4360, Total Reward: -29\n",
      "Episode 4380, Total Reward: -33\n",
      "Episode 4400, Total Reward: -36\n",
      "Episode 4420, Total Reward: -31\n",
      "Episode 4440, Total Reward: -36\n",
      "Episode 4460, Total Reward: -34\n",
      "Episode 4480, Total Reward: -29\n",
      "Episode 4500, Total Reward: -35\n",
      "Episode 4520, Total Reward: -273.270410850634\n",
      "Episode 4540, Total Reward: -31\n",
      "Episode 4560, Total Reward: -32\n",
      "Episode 4580, Total Reward: -37\n",
      "Episode 4600, Total Reward: -39\n",
      "Episode 4620, Total Reward: -32\n",
      "Episode 4640, Total Reward: -34\n",
      "Episode 4660, Total Reward: -40\n",
      "Episode 4680, Total Reward: -35\n",
      "Episode 4700, Total Reward: -34\n",
      "Episode 4720, Total Reward: -37\n",
      "Episode 4740, Total Reward: -39\n",
      "Episode 4760, Total Reward: -38\n",
      "Episode 4780, Total Reward: -36\n",
      "Episode 4800, Total Reward: -33\n",
      "Episode 4820, Total Reward: -34\n",
      "Episode 4840, Total Reward: -36\n",
      "Episode 4860, Total Reward: -41\n",
      "Episode 4880, Total Reward: -34\n",
      "Episode 4900, Total Reward: -36\n",
      "Episode 4920, Total Reward: -36\n",
      "Episode 4940, Total Reward: -41\n",
      "Episode 4960, Total Reward: -36\n",
      "Episode 4980, Total Reward: -34\n",
      "Episode 5000, Total Reward: -69\n",
      "Episode 5020, Total Reward: -85\n",
      "Episode 5040, Total Reward: -35\n",
      "Episode 5060, Total Reward: -61\n",
      "Episode 5080, Total Reward: -48\n",
      "Episode 5100, Total Reward: -35\n",
      "Episode 5120, Total Reward: -50\n",
      "Episode 5140, Total Reward: -37\n",
      "Episode 5160, Total Reward: -33\n",
      "Episode 5180, Total Reward: -41\n",
      "Episode 5200, Total Reward: -34\n",
      "Episode 5220, Total Reward: -37\n",
      "Episode 5240, Total Reward: -37\n",
      "Episode 5260, Total Reward: -37\n",
      "Episode 5280, Total Reward: -35\n",
      "Episode 5300, Total Reward: -40\n",
      "Episode 5320, Total Reward: -38\n",
      "Episode 5340, Total Reward: -36\n",
      "Episode 5360, Total Reward: -33\n",
      "Episode 5380, Total Reward: -39\n",
      "Episode 5400, Total Reward: -33\n",
      "Episode 5420, Total Reward: -35\n",
      "Episode 5440, Total Reward: -36\n",
      "Episode 5460, Total Reward: -31\n",
      "Episode 5480, Total Reward: -35\n",
      "Episode 5500, Total Reward: -38\n",
      "Episode 5520, Total Reward: -34\n",
      "Episode 5540, Total Reward: -33\n",
      "Episode 5560, Total Reward: -39\n",
      "Episode 5580, Total Reward: -31\n",
      "Episode 5600, Total Reward: -36\n",
      "Episode 5620, Total Reward: -34\n",
      "Episode 5640, Total Reward: -35\n",
      "Episode 5660, Total Reward: -32\n",
      "Episode 5680, Total Reward: -36\n",
      "Episode 5700, Total Reward: -34\n",
      "Episode 5720, Total Reward: -42\n",
      "Episode 5740, Total Reward: -39\n",
      "Episode 5760, Total Reward: -35\n",
      "Episode 5780, Total Reward: -33\n",
      "Episode 5800, Total Reward: -39\n",
      "Episode 5820, Total Reward: -35\n",
      "Episode 5840, Total Reward: -35\n",
      "Episode 5860, Total Reward: -40\n",
      "Episode 5880, Total Reward: -39\n",
      "Episode 5900, Total Reward: -36\n",
      "Episode 5920, Total Reward: -37\n",
      "Episode 5940, Total Reward: -31\n",
      "Episode 5960, Total Reward: -33\n",
      "Episode 5980, Total Reward: -46\n",
      "Episode 6000, Total Reward: -33\n",
      "Episode 6020, Total Reward: -32\n",
      "Episode 6040, Total Reward: -40\n",
      "Episode 6060, Total Reward: -36\n",
      "Episode 6080, Total Reward: -38\n",
      "Episode 6100, Total Reward: -38\n",
      "Episode 6120, Total Reward: -33\n",
      "Episode 6140, Total Reward: -33\n",
      "Episode 6160, Total Reward: -38\n",
      "Episode 6180, Total Reward: -33\n",
      "Episode 6200, Total Reward: -39\n",
      "Episode 6220, Total Reward: -35\n",
      "Episode 6240, Total Reward: -31\n",
      "Episode 6260, Total Reward: -37\n",
      "Episode 6280, Total Reward: -35\n",
      "Episode 6300, Total Reward: -33\n",
      "Episode 6320, Total Reward: -34\n",
      "Episode 6340, Total Reward: -34\n",
      "Episode 6360, Total Reward: -35\n",
      "Episode 6380, Total Reward: -40\n",
      "Episode 6400, Total Reward: -36\n",
      "Episode 6420, Total Reward: -36\n",
      "Episode 6440, Total Reward: -36\n",
      "Episode 6460, Total Reward: -34\n",
      "Episode 6480, Total Reward: -36\n",
      "Episode 6500, Total Reward: -37\n",
      "Episode 6520, Total Reward: -42\n",
      "Episode 6540, Total Reward: -38\n",
      "Episode 6560, Total Reward: -36\n",
      "Episode 6580, Total Reward: -37\n",
      "Episode 6600, Total Reward: -39\n",
      "Episode 6620, Total Reward: -36\n",
      "Episode 6640, Total Reward: -37\n",
      "Episode 6660, Total Reward: -45\n",
      "Episode 6680, Total Reward: -30\n",
      "Episode 6700, Total Reward: -32\n",
      "Episode 6720, Total Reward: -34\n",
      "Episode 6740, Total Reward: -35\n",
      "Episode 6760, Total Reward: -42\n",
      "Episode 6780, Total Reward: -38\n",
      "Episode 6800, Total Reward: -34\n",
      "Episode 6820, Total Reward: -33\n",
      "Episode 6840, Total Reward: -49\n",
      "Episode 6860, Total Reward: -99\n",
      "Episode 6880, Total Reward: -35\n",
      "Episode 6900, Total Reward: -34\n",
      "Episode 6920, Total Reward: -39\n",
      "Episode 6940, Total Reward: -33\n",
      "Episode 6960, Total Reward: -42\n",
      "Episode 6980, Total Reward: -35\n",
      "Episode 7000, Total Reward: -39\n",
      "Episode 7020, Total Reward: -33\n",
      "Episode 7040, Total Reward: -39\n",
      "Episode 7060, Total Reward: -35\n",
      "Episode 7080, Total Reward: -34\n",
      "Episode 7100, Total Reward: -34\n",
      "Episode 7120, Total Reward: -33\n",
      "Episode 7140, Total Reward: -43\n",
      "Episode 7160, Total Reward: -36\n",
      "Episode 7180, Total Reward: -37\n",
      "Episode 7200, Total Reward: -34\n",
      "Episode 7220, Total Reward: -38\n",
      "Episode 7240, Total Reward: -33\n",
      "Episode 7260, Total Reward: -34\n",
      "Episode 7280, Total Reward: -38\n",
      "Episode 7300, Total Reward: -35\n",
      "Episode 7320, Total Reward: -34\n",
      "Episode 7340, Total Reward: -41\n",
      "Episode 7360, Total Reward: -38\n",
      "Episode 7380, Total Reward: -37\n",
      "Episode 7400, Total Reward: -42\n",
      "Episode 7420, Total Reward: -34\n",
      "Episode 7440, Total Reward: -33\n",
      "Episode 7460, Total Reward: -41\n",
      "Episode 7480, Total Reward: -37\n",
      "Episode 7500, Total Reward: -33\n",
      "Episode 7520, Total Reward: -38\n",
      "Episode 7540, Total Reward: -34\n",
      "Episode 7560, Total Reward: -36\n",
      "Episode 7580, Total Reward: -32\n",
      "Episode 7600, Total Reward: -268.4637537362858\n",
      "Episode 7620, Total Reward: -34\n",
      "Episode 7640, Total Reward: -37\n",
      "Episode 7660, Total Reward: -36\n",
      "Episode 7680, Total Reward: -39\n",
      "Episode 7700, Total Reward: -35\n",
      "Episode 7720, Total Reward: -43\n",
      "Episode 7740, Total Reward: -38\n",
      "Episode 7760, Total Reward: -36\n",
      "Episode 7780, Total Reward: -36\n",
      "Episode 7800, Total Reward: -34\n",
      "Episode 7820, Total Reward: -36\n",
      "Episode 7840, Total Reward: -39\n",
      "Episode 7860, Total Reward: -38\n",
      "Episode 7880, Total Reward: -35\n",
      "Episode 7900, Total Reward: -38\n",
      "Episode 7920, Total Reward: -48\n",
      "Episode 7940, Total Reward: -36\n",
      "Episode 7960, Total Reward: -39\n",
      "Episode 7980, Total Reward: -33\n",
      "Episode 8000, Total Reward: -39\n",
      "Episode 8020, Total Reward: -34\n",
      "Episode 8040, Total Reward: -38\n",
      "Episode 8060, Total Reward: -36\n",
      "Episode 8080, Total Reward: -34\n",
      "Episode 8100, Total Reward: -34\n",
      "Episode 8120, Total Reward: -37\n",
      "Episode 8140, Total Reward: -36\n",
      "Episode 8160, Total Reward: -33\n",
      "Episode 8180, Total Reward: -41\n",
      "Episode 8200, Total Reward: -37\n",
      "Episode 8220, Total Reward: -34\n",
      "Episode 8240, Total Reward: -32\n",
      "Episode 8260, Total Reward: -35\n",
      "Episode 8280, Total Reward: -41\n",
      "Episode 8300, Total Reward: -41\n",
      "Episode 8320, Total Reward: -32\n",
      "Episode 8340, Total Reward: -33\n",
      "Episode 8360, Total Reward: -42\n",
      "Episode 8380, Total Reward: -38\n",
      "Episode 8400, Total Reward: -36\n",
      "Episode 8420, Total Reward: -34\n",
      "Episode 8440, Total Reward: -36\n",
      "Episode 8460, Total Reward: -40\n",
      "Episode 8480, Total Reward: -33\n",
      "Episode 8500, Total Reward: -37\n",
      "Episode 8520, Total Reward: -32\n",
      "Episode 8540, Total Reward: -37\n",
      "Episode 8560, Total Reward: -36\n",
      "Episode 8580, Total Reward: -36\n",
      "Episode 8600, Total Reward: -35\n",
      "Episode 8620, Total Reward: -32\n",
      "Episode 8640, Total Reward: -35\n",
      "Episode 8660, Total Reward: -35\n",
      "Episode 8680, Total Reward: -38\n",
      "Episode 8700, Total Reward: -36\n",
      "Episode 8720, Total Reward: -35\n",
      "Episode 8740, Total Reward: -34\n",
      "Episode 8760, Total Reward: -35\n",
      "Episode 8780, Total Reward: -33\n",
      "Episode 8800, Total Reward: -35\n",
      "Episode 8820, Total Reward: -34\n",
      "Episode 8840, Total Reward: -34\n",
      "Episode 8860, Total Reward: -35\n",
      "Episode 8880, Total Reward: -37\n",
      "Episode 8900, Total Reward: -35\n",
      "Episode 8920, Total Reward: -34\n",
      "Episode 8940, Total Reward: -37\n",
      "Episode 8960, Total Reward: -36\n",
      "Episode 8980, Total Reward: -32\n",
      "Episode 9000, Total Reward: -34\n",
      "Episode 9020, Total Reward: -34\n",
      "Episode 9040, Total Reward: -40\n",
      "Episode 9060, Total Reward: -40\n",
      "Episode 9080, Total Reward: -36\n",
      "Episode 9100, Total Reward: -35\n",
      "Episode 9120, Total Reward: -37\n",
      "Episode 9140, Total Reward: -38\n",
      "Episode 9160, Total Reward: -34\n",
      "Episode 9180, Total Reward: -31\n",
      "Episode 9200, Total Reward: -34\n",
      "Episode 9220, Total Reward: -37\n",
      "Episode 9240, Total Reward: -39\n",
      "Episode 9260, Total Reward: -34\n",
      "Episode 9280, Total Reward: -34\n",
      "Episode 9300, Total Reward: -34\n",
      "Episode 9320, Total Reward: -37\n",
      "Episode 9340, Total Reward: -44\n",
      "Episode 9360, Total Reward: -42\n",
      "Episode 9380, Total Reward: -36\n",
      "Episode 9400, Total Reward: -33\n",
      "Episode 9420, Total Reward: -32\n",
      "Episode 9440, Total Reward: -41\n",
      "Episode 9460, Total Reward: -42\n",
      "Episode 9480, Total Reward: -35\n",
      "Episode 9500, Total Reward: -38\n",
      "Episode 9520, Total Reward: -36\n",
      "Episode 9540, Total Reward: -39\n",
      "Episode 9560, Total Reward: -40\n",
      "Episode 9580, Total Reward: -35\n",
      "Episode 9600, Total Reward: -37\n",
      "Episode 9620, Total Reward: -43\n",
      "Episode 9640, Total Reward: -41\n",
      "Episode 9660, Total Reward: -35\n",
      "Episode 9680, Total Reward: -39\n",
      "Episode 9700, Total Reward: -35\n",
      "Episode 9720, Total Reward: -37\n",
      "Episode 9740, Total Reward: -41\n",
      "Episode 9760, Total Reward: -35\n",
      "Episode 9780, Total Reward: -36\n",
      "Episode 9800, Total Reward: -33\n",
      "Episode 9820, Total Reward: -34\n",
      "Episode 9840, Total Reward: -35\n",
      "Episode 9860, Total Reward: -38\n",
      "Episode 9880, Total Reward: -35\n",
      "Episode 9900, Total Reward: -36\n",
      "Episode 9920, Total Reward: -39\n",
      "Episode 9940, Total Reward: -42\n",
      "Episode 9960, Total Reward: -46\n",
      "Episode 9980, Total Reward: -34\n",
      "Episode 10000, Total Reward: -34\n",
      "Episode 10020, Total Reward: -41\n",
      "Episode 10040, Total Reward: -41\n",
      "Episode 10060, Total Reward: -36\n",
      "Episode 10080, Total Reward: -39\n",
      "Episode 10100, Total Reward: -38\n",
      "Episode 10120, Total Reward: -38\n",
      "Episode 10140, Total Reward: -40\n",
      "Episode 10160, Total Reward: -39\n",
      "Episode 10180, Total Reward: -39\n",
      "Episode 10200, Total Reward: -35\n",
      "Episode 10220, Total Reward: -39\n",
      "Episode 10240, Total Reward: -38\n",
      "Episode 10260, Total Reward: -37\n",
      "Episode 10280, Total Reward: -33\n",
      "Episode 10300, Total Reward: -39\n",
      "Episode 10320, Total Reward: -36\n",
      "Episode 10340, Total Reward: -39\n",
      "Episode 10360, Total Reward: -38\n",
      "Episode 10380, Total Reward: -34\n",
      "Episode 10400, Total Reward: -32\n",
      "Episode 10420, Total Reward: -37\n",
      "Episode 10440, Total Reward: -36\n",
      "Episode 10460, Total Reward: -36\n",
      "Episode 10480, Total Reward: -31\n",
      "Episode 10500, Total Reward: -34\n",
      "Episode 10520, Total Reward: -36\n",
      "Episode 10540, Total Reward: -38\n",
      "Episode 10560, Total Reward: -35\n",
      "Episode 10580, Total Reward: -44\n",
      "Episode 10600, Total Reward: -41\n",
      "Episode 10620, Total Reward: -32\n",
      "Episode 10640, Total Reward: -64\n",
      "Episode 10660, Total Reward: -34\n",
      "Episode 10680, Total Reward: -42\n",
      "Episode 10700, Total Reward: -38\n",
      "Episode 10720, Total Reward: -35\n",
      "Episode 10740, Total Reward: -36\n",
      "Episode 10760, Total Reward: -33\n",
      "Episode 10780, Total Reward: -37\n",
      "Episode 10800, Total Reward: -34\n",
      "Episode 10820, Total Reward: -40\n",
      "Episode 10840, Total Reward: -36\n",
      "Episode 10860, Total Reward: -35\n",
      "Episode 10880, Total Reward: -32\n",
      "Episode 10900, Total Reward: -35\n",
      "Episode 10920, Total Reward: -33\n",
      "Episode 10940, Total Reward: -32\n",
      "Episode 10960, Total Reward: -37\n",
      "Episode 10980, Total Reward: -36\n",
      "Episode 11000, Total Reward: -36\n",
      "Episode 11020, Total Reward: -36\n",
      "Episode 11040, Total Reward: -34\n",
      "Episode 11060, Total Reward: -33\n",
      "Episode 11080, Total Reward: -31\n",
      "Episode 11100, Total Reward: -40\n",
      "Episode 11120, Total Reward: -33\n",
      "Episode 11140, Total Reward: -34\n",
      "Episode 11160, Total Reward: -33\n",
      "Episode 11180, Total Reward: -40\n",
      "Episode 11200, Total Reward: -44\n",
      "Episode 11220, Total Reward: -38\n",
      "Episode 11240, Total Reward: -38\n",
      "Episode 11260, Total Reward: -35\n",
      "Episode 11280, Total Reward: -34\n",
      "Episode 11300, Total Reward: -35\n",
      "Episode 11320, Total Reward: -39\n",
      "Episode 11340, Total Reward: -35\n",
      "Episode 11360, Total Reward: -34\n",
      "Episode 11380, Total Reward: -35\n",
      "Episode 11400, Total Reward: -39\n",
      "Episode 11420, Total Reward: -40\n",
      "Episode 11440, Total Reward: -34\n",
      "Episode 11460, Total Reward: -35\n",
      "Episode 11480, Total Reward: -39\n",
      "Episode 11500, Total Reward: -35\n",
      "Episode 11520, Total Reward: -36\n",
      "Episode 11540, Total Reward: -32\n",
      "Episode 11560, Total Reward: -32\n",
      "Episode 11580, Total Reward: -35\n",
      "Episode 11600, Total Reward: -41\n",
      "Episode 11620, Total Reward: -38\n",
      "Episode 11640, Total Reward: -38\n",
      "Episode 11660, Total Reward: -36\n",
      "Episode 11680, Total Reward: -32\n",
      "Episode 11700, Total Reward: -37\n",
      "Episode 11720, Total Reward: -36\n",
      "Episode 11740, Total Reward: -39\n",
      "Episode 11760, Total Reward: -39\n",
      "Episode 11780, Total Reward: -38\n",
      "Episode 11800, Total Reward: -36\n",
      "Episode 11820, Total Reward: -44\n",
      "Episode 11840, Total Reward: -38\n",
      "Episode 11860, Total Reward: -34\n",
      "Episode 11880, Total Reward: -38\n",
      "Episode 11900, Total Reward: -34\n",
      "Episode 11920, Total Reward: -35\n",
      "Episode 11940, Total Reward: -37\n",
      "Episode 11960, Total Reward: -35\n",
      "Episode 11980, Total Reward: -37\n",
      "Episode 12000, Total Reward: -37\n",
      "Episode 12020, Total Reward: -32\n",
      "Episode 12040, Total Reward: -35\n",
      "Episode 12060, Total Reward: -37\n",
      "Episode 12080, Total Reward: -33\n",
      "Episode 12100, Total Reward: -41\n",
      "Episode 12120, Total Reward: -34\n",
      "Episode 12140, Total Reward: -37\n",
      "Episode 12160, Total Reward: -37\n",
      "Episode 12180, Total Reward: -34\n",
      "Episode 12200, Total Reward: -36\n",
      "Episode 12220, Total Reward: -33\n",
      "Episode 12240, Total Reward: -36\n",
      "Episode 12260, Total Reward: -33\n",
      "Episode 12280, Total Reward: -41\n",
      "Episode 12300, Total Reward: -36\n",
      "Episode 12320, Total Reward: -33\n",
      "Episode 12340, Total Reward: -36\n",
      "Episode 12360, Total Reward: -34\n",
      "Episode 12380, Total Reward: -36\n",
      "Episode 12400, Total Reward: -35\n",
      "Episode 12420, Total Reward: -36\n",
      "Episode 12440, Total Reward: -33\n",
      "Episode 12460, Total Reward: -36\n",
      "Episode 12480, Total Reward: -37\n",
      "Episode 12500, Total Reward: -39\n",
      "Episode 12520, Total Reward: -36\n",
      "Episode 12540, Total Reward: -32\n",
      "Episode 12560, Total Reward: -34\n",
      "Episode 12580, Total Reward: -35\n",
      "Episode 12600, Total Reward: -37\n",
      "Episode 12620, Total Reward: -37\n",
      "Episode 12640, Total Reward: -36\n",
      "Episode 12660, Total Reward: -34\n",
      "Episode 12680, Total Reward: -39\n",
      "Episode 12700, Total Reward: -31\n",
      "Episode 12720, Total Reward: -35\n",
      "Episode 12740, Total Reward: -33\n",
      "Episode 12760, Total Reward: -35\n",
      "Episode 12780, Total Reward: -37\n",
      "Episode 12800, Total Reward: -39\n",
      "Episode 12820, Total Reward: -37\n",
      "Episode 12840, Total Reward: -36\n",
      "Episode 12860, Total Reward: -34\n",
      "Episode 12880, Total Reward: -35\n",
      "Episode 12900, Total Reward: -31\n",
      "Episode 12920, Total Reward: -36\n",
      "Episode 12940, Total Reward: -35\n",
      "Episode 12960, Total Reward: -35\n",
      "Episode 12980, Total Reward: -33\n",
      "Episode 13000, Total Reward: -32\n",
      "Episode 13020, Total Reward: -37\n",
      "Episode 13040, Total Reward: -32\n",
      "Episode 13060, Total Reward: -35\n",
      "Episode 13080, Total Reward: -34\n",
      "Episode 13100, Total Reward: -39\n",
      "Episode 13120, Total Reward: -39\n",
      "Episode 13140, Total Reward: -35\n",
      "Episode 13160, Total Reward: -34\n",
      "Episode 13180, Total Reward: -33\n",
      "Episode 13200, Total Reward: -38\n",
      "Episode 13220, Total Reward: -33\n",
      "Episode 13240, Total Reward: -41\n",
      "Episode 13260, Total Reward: -34\n",
      "Episode 13280, Total Reward: -273.357031424469\n",
      "Episode 13300, Total Reward: -33\n",
      "Episode 13320, Total Reward: -32\n",
      "Episode 13340, Total Reward: -33\n",
      "Episode 13360, Total Reward: -32\n",
      "Episode 13380, Total Reward: -36\n",
      "Episode 13400, Total Reward: -33\n",
      "Episode 13420, Total Reward: -36\n",
      "Episode 13440, Total Reward: -39\n",
      "Episode 13460, Total Reward: -35\n",
      "Episode 13480, Total Reward: -36\n",
      "Episode 13500, Total Reward: -37\n",
      "Episode 13520, Total Reward: -35\n",
      "Episode 13540, Total Reward: -32\n",
      "Episode 13560, Total Reward: -36\n",
      "Episode 13580, Total Reward: -35\n",
      "Episode 13600, Total Reward: -36\n",
      "Episode 13620, Total Reward: -39\n",
      "Episode 13640, Total Reward: -35\n",
      "Episode 13660, Total Reward: -37\n",
      "Episode 13680, Total Reward: -38\n",
      "Episode 13700, Total Reward: -37\n",
      "Episode 13720, Total Reward: -34\n",
      "Episode 13740, Total Reward: -36\n",
      "Episode 13760, Total Reward: -36\n",
      "Episode 13780, Total Reward: -32\n",
      "Episode 13800, Total Reward: -33\n",
      "Episode 13820, Total Reward: -39\n",
      "Episode 13840, Total Reward: -33\n",
      "Episode 13860, Total Reward: -33\n",
      "Episode 13880, Total Reward: -36\n",
      "Episode 13900, Total Reward: -33\n",
      "Episode 13920, Total Reward: -36\n",
      "Episode 13940, Total Reward: -34\n",
      "Episode 13960, Total Reward: -42\n",
      "Episode 13980, Total Reward: -34\n",
      "Episode 14000, Total Reward: -42\n",
      "Episode 14020, Total Reward: -33\n",
      "Episode 14040, Total Reward: -32\n",
      "Episode 14060, Total Reward: -33\n",
      "Episode 14080, Total Reward: -32\n",
      "Episode 14100, Total Reward: -37\n",
      "Episode 14120, Total Reward: -39\n",
      "Episode 14140, Total Reward: -35\n",
      "Episode 14160, Total Reward: -35\n",
      "Episode 14180, Total Reward: -39\n",
      "Episode 14200, Total Reward: -34\n",
      "Episode 14220, Total Reward: -32\n",
      "Episode 14240, Total Reward: -38\n",
      "Episode 14260, Total Reward: -34\n",
      "Episode 14280, Total Reward: -34\n",
      "Episode 14300, Total Reward: -38\n",
      "Episode 14320, Total Reward: -31\n",
      "Episode 14340, Total Reward: -38\n",
      "Episode 14360, Total Reward: -34\n",
      "Episode 14380, Total Reward: -39\n",
      "Episode 14400, Total Reward: -34\n",
      "Episode 14420, Total Reward: -34\n",
      "Episode 14440, Total Reward: -39\n",
      "Episode 14460, Total Reward: -33\n",
      "Episode 14480, Total Reward: -34\n",
      "Episode 14500, Total Reward: -32\n",
      "Episode 14520, Total Reward: -34\n",
      "Episode 14540, Total Reward: -34\n",
      "Episode 14560, Total Reward: -31\n",
      "Episode 14580, Total Reward: -32\n",
      "Episode 14600, Total Reward: -34\n",
      "Episode 14620, Total Reward: -39\n",
      "Episode 14640, Total Reward: -33\n",
      "Episode 14660, Total Reward: -36\n",
      "Episode 14680, Total Reward: -36\n",
      "Episode 14700, Total Reward: -34\n",
      "Episode 14720, Total Reward: -35\n",
      "Episode 14740, Total Reward: -37\n",
      "Episode 14760, Total Reward: -36\n",
      "Episode 14780, Total Reward: -34\n",
      "Episode 14800, Total Reward: -34\n",
      "Episode 14820, Total Reward: -44\n",
      "Episode 14840, Total Reward: -33\n",
      "Episode 14860, Total Reward: -36\n",
      "Episode 14880, Total Reward: -35\n",
      "Episode 14900, Total Reward: -40\n",
      "Episode 14920, Total Reward: -37\n",
      "Episode 14940, Total Reward: -39\n",
      "Episode 14960, Total Reward: -32\n",
      "Episode 14980, Total Reward: -31\n"
     ]
    }
   ],
   "source": [
    "## simulare the agent in the environment\n",
    "num_actions = len(env.get_wrapper_attr(\"actions\"))\n",
    "agent = tabularQlearning(num_feature= num_features, num_actions=num_actions)\n",
    "\n",
    "num_episodes = 15000\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    obs, info = env.reset()\n",
    "    state = rep.get_features(obs)\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        action = agent.choose_action(state)\n",
    "        next_obs, reward, done, trunc, _ = env.step(action)\n",
    "        next_state = rep.get_features(next_obs)\n",
    "        agent.update(state, action, reward, next_state)\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "    if episode % 20 == 0:\n",
    "        print(f\"Episode {episode}, Total Reward: {total_reward}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " t: 0, observation: [0.2053227  0.34224568], reward: -1\n",
      " t: 1, observation: [0.20538847 0.26641174], reward: -1\n",
      " t: 2, observation: [0.26306535 0.2823582 ], reward: -1\n",
      " t: 3, observation: [0.25904991 0.2441531 ], reward: -1\n",
      " t: 4, observation: [0.30093845 0.2573566 ], reward: -1\n",
      " t: 5, observation: [0.30570418 0.23311963], reward: -1\n",
      " t: 6, observation: [0.35497623 0.24310981], reward: -1\n",
      " t: 7, observation: [0.40986577 0.22862083], reward: -1\n",
      " t: 8, observation: [0.45370715 0.21302335], reward: -1\n",
      " t: 9, observation: [0.49577311 0.21198117], reward: -1\n",
      " t: 10, observation: [0.55110772 0.21880772], reward: -1\n",
      " t: 11, observation: [0.59559129 0.22572214], reward: -1\n",
      " t: 12, observation: [0.59963896 0.28145391], reward: -1\n",
      " t: 13, observation: [0.63524194 0.26440918], reward: -1\n",
      " t: 14, observation: [0.62126963 0.31488999], reward: -1\n",
      " t: 15, observation: [0.62177596 0.3732773 ], reward: -1\n",
      " t: 16, observation: [0.6131531  0.44652343], reward: -1\n",
      " t: 17, observation: [0.59771144 0.48972061], reward: -1\n",
      " t: 18, observation: [0.64382015 0.4929231 ], reward: -1\n",
      " t: 19, observation: [0.6562153  0.53985342], reward: -1\n",
      " t: 20, observation: [0.65618221 0.59036858], reward: -1\n",
      " t: 21, observation: [0.66367996 0.64708575], reward: -1\n",
      " t: 22, observation: [0.66730446 0.69867485], reward: -1\n",
      " t: 23, observation: [0.69933655 0.69061143], reward: -1\n",
      " t: 24, observation: [0.73506977 0.692702  ], reward: -1\n",
      " t: 25, observation: [0.73538528 0.74530954], reward: -1\n",
      " t: 26, observation: [0.72841231 0.78990302], reward: -1\n",
      " t: 27, observation: [0.72261914 0.85046301], reward: -1\n",
      " t: 28, observation: [0.79043823 0.84175332], reward: -1\n",
      " t: 29, observation: [0.83366785 0.8407229 ], reward: -1\n",
      " t: 30, observation: [0.83789462 0.89841555], reward: -1\n",
      " t: 31, observation: [0.89531998 0.91237184], reward: -1\n",
      " t: 32, observation: [0.91016915 0.96128763], reward: -1\n",
      " t: 33, observation: [0.9743776  0.96201372], reward: 0\n",
      "total reward in this episode: -33\n",
      "episode 0: reward: -33\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Test the trained model\n",
    "obs, info = env.reset()\n",
    "total_reward = 0\n",
    "episode_rewards = []\n",
    "frames = []\n",
    "observation = obs\n",
    "\n",
    "max_video_length = 120\n",
    "\n",
    "\n",
    "observation_list = []\n",
    "\n",
    "observation_rep_list = []\n",
    "\n",
    "def greedy_policy(state):\n",
    "    q_table = agent.get_q_table()\n",
    "    q = q_table[state].sum(axis=0)\n",
    "    return q.argmax()\n",
    "\n",
    "def e_greedy_policy(state, epsilon=0.01):\n",
    "    q_table = agent.get_q_table()\n",
    "    q = q_table[state].sum(axis=0)\n",
    "    if np.random.rand() < epsilon:\n",
    "        return np.random.choice(num_actions)\n",
    "    else:\n",
    "        return q.argmax()\n",
    "\n",
    "for time_step in range(max_video_length):\n",
    "    \n",
    "    frames.append(env.render())\n",
    "\n",
    "    action = e_greedy_policy(rep.get_features(observation))\n",
    "    #action = agent.choose_action(rep.get_features(observation))\n",
    "    observation, reward, done, trunc, _ = env.step(action)\n",
    "\n",
    "    # get the state representation\n",
    "    observation_rep = rep.get_features(observation)\n",
    "\n",
    "    # store the observation for visualization\n",
    "    observation_list.append(observation)\n",
    "\n",
    "    # store the state representation for visualization\n",
    "    observation_rep_list.append(observation_rep[0])\n",
    "    \n",
    "    total_reward += reward\n",
    "    image = env.render()\n",
    "    #online_rendering(image) #uncomment this line to see the online rendering of the environment frame by frame\n",
    "    frames.append(image)\n",
    "\n",
    "    print(f\" t: {time_step}, observation: {observation}, reward: {reward}\") #uncomment this line to see the environment-agent interaction details\n",
    "\n",
    "    if done:\n",
    "      print(f\"total reward in this episode: {total_reward}\")\n",
    "      episode_rewards.append(total_reward)\n",
    "      total_reward = 0\n",
    "      break\n",
    "\n",
    "env.close()\n",
    "\n",
    "if episode_rewards == []:\n",
    "  print(\"no episode finished in this run.\")\n",
    "else:\n",
    "  for i, reward in enumerate(episode_rewards):\n",
    "    print(f\"episode {i}: reward: {reward}\")\n",
    "\n",
    "visualize(frames, \"./Video/q_learning_Kan.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.97352124, -1.17411501, -2.2806168 , -1.23912997])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print q-value for observation_rep_list \n",
    "q_values = []\n",
    "for state in observation_rep_list:\n",
    "    q_values.append(agent.get_q_table()[state])\n",
    "\n",
    "q_values[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize the observation list as a scatter plot\n",
    "observation_list = np.array(observation_list)\n",
    "plt.scatter(observation_list[:, 0], observation_list[:, 1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to generate random points based on observation list\n",
    "def generate_random_points(observation_list, num_points=100, st_scale=0.02):\n",
    "    # Initialize an empty list to store the generated points\n",
    "    generated_points = []\n",
    "    \n",
    "    # Generate num_points random points\n",
    "    for _ in range(num_points):\n",
    "        # Select a random point from observation_list\n",
    "        selected_point = observation_list[np.random.choice(len(observation_list))]\n",
    "        \n",
    "        # Generate a random point close to the selected point\n",
    "        random_point = selected_point + np.random.normal(loc= 0, scale = st_scale, size=2)\n",
    "        \n",
    "        # Ensure the generated point is bounded between 0 and 1\n",
    "        random_point = np.clip(random_point, 0, 1)\n",
    "        \n",
    "        # Append the generated point to the list\n",
    "        generated_points.append(random_point)\n",
    "    \n",
    "    return np.array(generated_points)\n",
    "\n",
    "# Generate 100 random points based on the observation list\n",
    "random_points = generate_random_points(observation_list, num_points=100, st_scale=0.04)\n",
    "\n",
    "# Visualize the random points\n",
    "plt.scatter(random_points[:, 0], random_points[:, 1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([814, 329, 607, 582, 933, 677, 188, 408])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from util.adaptive_kanerva import adaptiveKanervaCoder\n",
    "\n",
    "num_features = 1000\n",
    "n_closest = 8\n",
    "rep2 = adaptiveKanervaCoder(env.observation_space, st_scale = 0.05,  n_prototypes= num_features, observation_list= observation_list,\n",
    "                             n_closest= n_closest, random_seed= selected_seed)\n",
    "rep2.get_features(obs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with adaptive kanerva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0, Total Reward: -3636.071159214889\n",
      "Episode 20, Total Reward: -213\n",
      "Episode 40, Total Reward: -181\n",
      "Episode 60, Total Reward: -137\n",
      "Episode 80, Total Reward: -87\n",
      "Episode 100, Total Reward: -213\n",
      "Episode 120, Total Reward: -124\n",
      "Episode 140, Total Reward: -107\n",
      "Episode 160, Total Reward: -81\n",
      "Episode 180, Total Reward: -165\n",
      "Episode 200, Total Reward: -116\n",
      "Episode 220, Total Reward: -97\n",
      "Episode 240, Total Reward: -101\n",
      "Episode 260, Total Reward: -84\n",
      "Episode 280, Total Reward: -57\n",
      "Episode 300, Total Reward: -114\n",
      "Episode 320, Total Reward: -224\n",
      "Episode 340, Total Reward: -62\n",
      "Episode 360, Total Reward: -129\n",
      "Episode 380, Total Reward: -60\n",
      "Episode 400, Total Reward: -44\n",
      "Episode 420, Total Reward: -81\n",
      "Episode 440, Total Reward: -63\n",
      "Episode 460, Total Reward: -57\n",
      "Episode 480, Total Reward: -74\n",
      "Episode 500, Total Reward: -77\n",
      "Episode 520, Total Reward: -50\n",
      "Episode 540, Total Reward: -44\n",
      "Episode 560, Total Reward: -40\n",
      "Episode 580, Total Reward: -35\n",
      "Episode 600, Total Reward: -46\n",
      "Episode 620, Total Reward: -40\n",
      "Episode 640, Total Reward: -83\n",
      "Episode 660, Total Reward: -51\n",
      "Episode 680, Total Reward: -277.1705160683557\n",
      "Episode 700, Total Reward: -65\n",
      "Episode 720, Total Reward: -118\n",
      "Episode 740, Total Reward: -33\n",
      "Episode 760, Total Reward: -43\n",
      "Episode 780, Total Reward: -68\n",
      "Episode 800, Total Reward: -46\n",
      "Episode 820, Total Reward: -32\n",
      "Episode 840, Total Reward: -30\n",
      "Episode 860, Total Reward: -41\n",
      "Episode 880, Total Reward: -81\n",
      "Episode 900, Total Reward: -48\n",
      "Episode 920, Total Reward: -43\n",
      "Episode 940, Total Reward: -48\n",
      "Episode 960, Total Reward: -30\n",
      "Episode 980, Total Reward: -38\n",
      "Episode 1000, Total Reward: -41\n",
      "Episode 1020, Total Reward: -39\n",
      "Episode 1040, Total Reward: -37\n",
      "Episode 1060, Total Reward: -41\n",
      "Episode 1080, Total Reward: -33\n",
      "Episode 1100, Total Reward: -33\n",
      "Episode 1120, Total Reward: -48\n",
      "Episode 1140, Total Reward: -43\n",
      "Episode 1160, Total Reward: -34\n",
      "Episode 1180, Total Reward: -32\n",
      "Episode 1200, Total Reward: -48\n",
      "Episode 1220, Total Reward: -37\n",
      "Episode 1240, Total Reward: -39\n",
      "Episode 1260, Total Reward: -38\n",
      "Episode 1280, Total Reward: -34\n",
      "Episode 1300, Total Reward: -37\n",
      "Episode 1320, Total Reward: -32\n",
      "Episode 1340, Total Reward: -273.14413789334975\n",
      "Episode 1360, Total Reward: -33\n",
      "Episode 1380, Total Reward: -40\n",
      "Episode 1400, Total Reward: -34\n",
      "Episode 1420, Total Reward: -38\n",
      "Episode 1440, Total Reward: -36\n",
      "Episode 1460, Total Reward: -37\n",
      "Episode 1480, Total Reward: -33\n",
      "Episode 1500, Total Reward: -35\n",
      "Episode 1520, Total Reward: -36\n",
      "Episode 1540, Total Reward: -37\n",
      "Episode 1560, Total Reward: -51\n",
      "Episode 1580, Total Reward: -33\n",
      "Episode 1600, Total Reward: -34\n",
      "Episode 1620, Total Reward: -33\n",
      "Episode 1640, Total Reward: -32\n",
      "Episode 1660, Total Reward: -35\n",
      "Episode 1680, Total Reward: -37\n",
      "Episode 1700, Total Reward: -36\n",
      "Episode 1720, Total Reward: -33\n",
      "Episode 1740, Total Reward: -34\n",
      "Episode 1760, Total Reward: -38\n",
      "Episode 1780, Total Reward: -41\n",
      "Episode 1800, Total Reward: -32\n",
      "Episode 1820, Total Reward: -36\n",
      "Episode 1840, Total Reward: -34\n",
      "Episode 1860, Total Reward: -35\n",
      "Episode 1880, Total Reward: -34\n",
      "Episode 1900, Total Reward: -37\n",
      "Episode 1920, Total Reward: -41\n",
      "Episode 1940, Total Reward: -504.54581381278473\n",
      "Episode 1960, Total Reward: -39\n",
      "Episode 1980, Total Reward: -37\n",
      "Episode 2000, Total Reward: -39\n",
      "Episode 2020, Total Reward: -36\n",
      "Episode 2040, Total Reward: -39\n",
      "Episode 2060, Total Reward: -31\n",
      "Episode 2080, Total Reward: -35\n",
      "Episode 2100, Total Reward: -47\n",
      "Episode 2120, Total Reward: -40\n",
      "Episode 2140, Total Reward: -38\n",
      "Episode 2160, Total Reward: -37\n",
      "Episode 2180, Total Reward: -43\n",
      "Episode 2200, Total Reward: -37\n",
      "Episode 2220, Total Reward: -45\n",
      "Episode 2240, Total Reward: -52\n",
      "Episode 2260, Total Reward: -59\n",
      "Episode 2280, Total Reward: -64\n",
      "Episode 2300, Total Reward: -39\n",
      "Episode 2320, Total Reward: -45\n",
      "Episode 2340, Total Reward: -49\n",
      "Episode 2360, Total Reward: -39\n",
      "Episode 2380, Total Reward: -39\n",
      "Episode 2400, Total Reward: -36\n",
      "Episode 2420, Total Reward: -36\n",
      "Episode 2440, Total Reward: -42\n",
      "Episode 2460, Total Reward: -45\n",
      "Episode 2480, Total Reward: -39\n",
      "Episode 2500, Total Reward: -51\n",
      "Episode 2520, Total Reward: -40\n",
      "Episode 2540, Total Reward: -34\n",
      "Episode 2560, Total Reward: -36\n",
      "Episode 2580, Total Reward: -36\n",
      "Episode 2600, Total Reward: -76\n",
      "Episode 2620, Total Reward: -36\n",
      "Episode 2640, Total Reward: -38\n",
      "Episode 2660, Total Reward: -39\n",
      "Episode 2680, Total Reward: -36\n",
      "Episode 2700, Total Reward: -37\n",
      "Episode 2720, Total Reward: -34\n",
      "Episode 2740, Total Reward: -38\n",
      "Episode 2760, Total Reward: -35\n",
      "Episode 2780, Total Reward: -35\n",
      "Episode 2800, Total Reward: -36\n",
      "Episode 2820, Total Reward: -36\n",
      "Episode 2840, Total Reward: -36\n",
      "Episode 2860, Total Reward: -34\n",
      "Episode 2880, Total Reward: -37\n",
      "Episode 2900, Total Reward: -32\n",
      "Episode 2920, Total Reward: -37\n",
      "Episode 2940, Total Reward: -39\n",
      "Episode 2960, Total Reward: -32\n",
      "Episode 2980, Total Reward: -35\n",
      "Episode 3000, Total Reward: -39\n",
      "Episode 3020, Total Reward: -38\n",
      "Episode 3040, Total Reward: -36\n",
      "Episode 3060, Total Reward: -37\n",
      "Episode 3080, Total Reward: -49\n",
      "Episode 3100, Total Reward: -35\n",
      "Episode 3120, Total Reward: -47\n",
      "Episode 3140, Total Reward: -35\n",
      "Episode 3160, Total Reward: -36\n",
      "Episode 3180, Total Reward: -43\n",
      "Episode 3200, Total Reward: -31\n",
      "Episode 3220, Total Reward: -34\n",
      "Episode 3240, Total Reward: -32\n",
      "Episode 3260, Total Reward: -276.14913321734946\n",
      "Episode 3280, Total Reward: -37\n",
      "Episode 3300, Total Reward: -35\n",
      "Episode 3320, Total Reward: -49\n",
      "Episode 3340, Total Reward: -43\n",
      "Episode 3360, Total Reward: -35\n",
      "Episode 3380, Total Reward: -45\n",
      "Episode 3400, Total Reward: -42\n",
      "Episode 3420, Total Reward: -36\n",
      "Episode 3440, Total Reward: -39\n",
      "Episode 3460, Total Reward: -42\n",
      "Episode 3480, Total Reward: -39\n",
      "Episode 3500, Total Reward: -35\n",
      "Episode 3520, Total Reward: -41\n",
      "Episode 3540, Total Reward: -40\n",
      "Episode 3560, Total Reward: -42\n",
      "Episode 3580, Total Reward: -39\n",
      "Episode 3600, Total Reward: -38\n",
      "Episode 3620, Total Reward: -37\n",
      "Episode 3640, Total Reward: -40\n",
      "Episode 3660, Total Reward: -36\n",
      "Episode 3680, Total Reward: -72\n",
      "Episode 3700, Total Reward: -37\n",
      "Episode 3720, Total Reward: -35\n",
      "Episode 3740, Total Reward: -34\n",
      "Episode 3760, Total Reward: -37\n",
      "Episode 3780, Total Reward: -40\n",
      "Episode 3800, Total Reward: -37\n",
      "Episode 3820, Total Reward: -33\n",
      "Episode 3840, Total Reward: -33\n",
      "Episode 3860, Total Reward: -36\n",
      "Episode 3880, Total Reward: -38\n",
      "Episode 3900, Total Reward: -40\n",
      "Episode 3920, Total Reward: -38\n",
      "Episode 3940, Total Reward: -40\n",
      "Episode 3960, Total Reward: -35\n",
      "Episode 3980, Total Reward: -36\n",
      "Episode 4000, Total Reward: -38\n",
      "Episode 4020, Total Reward: -279.03258534363437\n",
      "Episode 4040, Total Reward: -34\n",
      "Episode 4060, Total Reward: -38\n",
      "Episode 4080, Total Reward: -32\n",
      "Episode 4100, Total Reward: -39\n",
      "Episode 4120, Total Reward: -33\n",
      "Episode 4140, Total Reward: -38\n",
      "Episode 4160, Total Reward: -37\n",
      "Episode 4180, Total Reward: -36\n",
      "Episode 4200, Total Reward: -37\n",
      "Episode 4220, Total Reward: -39\n",
      "Episode 4240, Total Reward: -36\n",
      "Episode 4260, Total Reward: -39\n",
      "Episode 4280, Total Reward: -41\n",
      "Episode 4300, Total Reward: -47\n",
      "Episode 4320, Total Reward: -31\n",
      "Episode 4340, Total Reward: -38\n",
      "Episode 4360, Total Reward: -39\n",
      "Episode 4380, Total Reward: -39\n",
      "Episode 4400, Total Reward: -491.0012032019008\n",
      "Episode 4420, Total Reward: -36\n",
      "Episode 4440, Total Reward: -33\n",
      "Episode 4460, Total Reward: -36\n",
      "Episode 4480, Total Reward: -37\n",
      "Episode 4500, Total Reward: -39\n",
      "Episode 4520, Total Reward: -36\n",
      "Episode 4540, Total Reward: -37\n",
      "Episode 4560, Total Reward: -35\n",
      "Episode 4580, Total Reward: -35\n",
      "Episode 4600, Total Reward: -34\n",
      "Episode 4620, Total Reward: -38\n",
      "Episode 4640, Total Reward: -32\n",
      "Episode 4660, Total Reward: -36\n",
      "Episode 4680, Total Reward: -37\n",
      "Episode 4700, Total Reward: -33\n",
      "Episode 4720, Total Reward: -38\n",
      "Episode 4740, Total Reward: -34\n",
      "Episode 4760, Total Reward: -32\n",
      "Episode 4780, Total Reward: -32\n",
      "Episode 4800, Total Reward: -36\n",
      "Episode 4820, Total Reward: -35\n",
      "Episode 4840, Total Reward: -30\n",
      "Episode 4860, Total Reward: -37\n",
      "Episode 4880, Total Reward: -34\n",
      "Episode 4900, Total Reward: -38\n",
      "Episode 4920, Total Reward: -32\n",
      "Episode 4940, Total Reward: -39\n",
      "Episode 4960, Total Reward: -35\n",
      "Episode 4980, Total Reward: -33\n",
      "Episode 5000, Total Reward: -34\n",
      "Episode 5020, Total Reward: -33\n",
      "Episode 5040, Total Reward: -39\n",
      "Episode 5060, Total Reward: -38\n",
      "Episode 5080, Total Reward: -36\n",
      "Episode 5100, Total Reward: -35\n",
      "Episode 5120, Total Reward: -36\n",
      "Episode 5140, Total Reward: -32\n",
      "Episode 5160, Total Reward: -34\n",
      "Episode 5180, Total Reward: -36\n",
      "Episode 5200, Total Reward: -36\n",
      "Episode 5220, Total Reward: -35\n",
      "Episode 5240, Total Reward: -35\n",
      "Episode 5260, Total Reward: -32\n",
      "Episode 5280, Total Reward: -38\n",
      "Episode 5300, Total Reward: -38\n",
      "Episode 5320, Total Reward: -38\n",
      "Episode 5340, Total Reward: -32\n",
      "Episode 5360, Total Reward: -36\n",
      "Episode 5380, Total Reward: -38\n",
      "Episode 5400, Total Reward: -32\n",
      "Episode 5420, Total Reward: -37\n",
      "Episode 5440, Total Reward: -40\n",
      "Episode 5460, Total Reward: -42\n",
      "Episode 5480, Total Reward: -35\n",
      "Episode 5500, Total Reward: -43\n",
      "Episode 5520, Total Reward: -33\n",
      "Episode 5540, Total Reward: -38\n",
      "Episode 5560, Total Reward: -34\n",
      "Episode 5580, Total Reward: -35\n",
      "Episode 5600, Total Reward: -36\n",
      "Episode 5620, Total Reward: -31\n",
      "Episode 5640, Total Reward: -39\n",
      "Episode 5660, Total Reward: -40\n",
      "Episode 5680, Total Reward: -38\n",
      "Episode 5700, Total Reward: -35\n",
      "Episode 5720, Total Reward: -37\n",
      "Episode 5740, Total Reward: -34\n",
      "Episode 5760, Total Reward: -38\n",
      "Episode 5780, Total Reward: -37\n",
      "Episode 5800, Total Reward: -36\n",
      "Episode 5820, Total Reward: -41\n",
      "Episode 5840, Total Reward: -38\n",
      "Episode 5860, Total Reward: -35\n",
      "Episode 5880, Total Reward: -36\n",
      "Episode 5900, Total Reward: -40\n",
      "Episode 5920, Total Reward: -32\n",
      "Episode 5940, Total Reward: -35\n",
      "Episode 5960, Total Reward: -33\n",
      "Episode 5980, Total Reward: -36\n",
      "Episode 6000, Total Reward: -40\n",
      "Episode 6020, Total Reward: -35\n",
      "Episode 6040, Total Reward: -37\n",
      "Episode 6060, Total Reward: -37\n",
      "Episode 6080, Total Reward: -38\n",
      "Episode 6100, Total Reward: -31\n",
      "Episode 6120, Total Reward: -35\n",
      "Episode 6140, Total Reward: -32\n",
      "Episode 6160, Total Reward: -34\n",
      "Episode 6180, Total Reward: -36\n",
      "Episode 6200, Total Reward: -33\n",
      "Episode 6220, Total Reward: -34\n",
      "Episode 6240, Total Reward: -37\n",
      "Episode 6260, Total Reward: -40\n",
      "Episode 6280, Total Reward: -32\n",
      "Episode 6300, Total Reward: -39\n",
      "Episode 6320, Total Reward: -44\n",
      "Episode 6340, Total Reward: -38\n",
      "Episode 6360, Total Reward: -39\n",
      "Episode 6380, Total Reward: -39\n",
      "Episode 6400, Total Reward: -38\n",
      "Episode 6420, Total Reward: -45\n",
      "Episode 6440, Total Reward: -35\n",
      "Episode 6460, Total Reward: -33\n",
      "Episode 6480, Total Reward: -40\n",
      "Episode 6500, Total Reward: -39\n",
      "Episode 6520, Total Reward: -42\n",
      "Episode 6540, Total Reward: -38\n",
      "Episode 6560, Total Reward: -32\n",
      "Episode 6580, Total Reward: -33\n",
      "Episode 6600, Total Reward: -36\n",
      "Episode 6620, Total Reward: -33\n",
      "Episode 6640, Total Reward: -35\n",
      "Episode 6660, Total Reward: -31\n",
      "Episode 6680, Total Reward: -34\n",
      "Episode 6700, Total Reward: -39\n",
      "Episode 6720, Total Reward: -36\n",
      "Episode 6740, Total Reward: -34\n",
      "Episode 6760, Total Reward: -40\n",
      "Episode 6780, Total Reward: -48\n",
      "Episode 6800, Total Reward: -38\n",
      "Episode 6820, Total Reward: -39\n",
      "Episode 6840, Total Reward: -32\n",
      "Episode 6860, Total Reward: -34\n",
      "Episode 6880, Total Reward: -41\n",
      "Episode 6900, Total Reward: -36\n",
      "Episode 6920, Total Reward: -31\n",
      "Episode 6940, Total Reward: -36\n",
      "Episode 6960, Total Reward: -35\n",
      "Episode 6980, Total Reward: -37\n",
      "Episode 7000, Total Reward: -40\n",
      "Episode 7020, Total Reward: -33\n",
      "Episode 7040, Total Reward: -35\n",
      "Episode 7060, Total Reward: -43\n",
      "Episode 7080, Total Reward: -39\n",
      "Episode 7100, Total Reward: -38\n",
      "Episode 7120, Total Reward: -35\n",
      "Episode 7140, Total Reward: -35\n",
      "Episode 7160, Total Reward: -36\n",
      "Episode 7180, Total Reward: -38\n",
      "Episode 7200, Total Reward: -34\n",
      "Episode 7220, Total Reward: -622\n",
      "Episode 7240, Total Reward: -34\n",
      "Episode 7260, Total Reward: -34\n",
      "Episode 7280, Total Reward: -34\n",
      "Episode 7300, Total Reward: -38\n",
      "Episode 7320, Total Reward: -37\n",
      "Episode 7340, Total Reward: -37\n",
      "Episode 7360, Total Reward: -37\n",
      "Episode 7380, Total Reward: -33\n",
      "Episode 7400, Total Reward: -37\n",
      "Episode 7420, Total Reward: -40\n",
      "Episode 7440, Total Reward: -35\n",
      "Episode 7460, Total Reward: -34\n",
      "Episode 7480, Total Reward: -40\n",
      "Episode 7500, Total Reward: -34\n",
      "Episode 7520, Total Reward: -39\n",
      "Episode 7540, Total Reward: -35\n",
      "Episode 7560, Total Reward: -37\n",
      "Episode 7580, Total Reward: -37\n",
      "Episode 7600, Total Reward: -39\n",
      "Episode 7620, Total Reward: -41\n",
      "Episode 7640, Total Reward: -40\n",
      "Episode 7660, Total Reward: -31\n",
      "Episode 7680, Total Reward: -42\n",
      "Episode 7700, Total Reward: -38\n",
      "Episode 7720, Total Reward: -34\n",
      "Episode 7740, Total Reward: -39\n",
      "Episode 7760, Total Reward: -41\n",
      "Episode 7780, Total Reward: -35\n",
      "Episode 7800, Total Reward: -41\n",
      "Episode 7820, Total Reward: -44\n",
      "Episode 7840, Total Reward: -36\n",
      "Episode 7860, Total Reward: -34\n",
      "Episode 7880, Total Reward: -35\n",
      "Episode 7900, Total Reward: -35\n",
      "Episode 7920, Total Reward: -35\n",
      "Episode 7940, Total Reward: -33\n",
      "Episode 7960, Total Reward: -41\n",
      "Episode 7980, Total Reward: -33\n",
      "Episode 8000, Total Reward: -35\n",
      "Episode 8020, Total Reward: -35\n",
      "Episode 8040, Total Reward: -34\n",
      "Episode 8060, Total Reward: -36\n",
      "Episode 8080, Total Reward: -38\n",
      "Episode 8100, Total Reward: -37\n",
      "Episode 8120, Total Reward: -41\n",
      "Episode 8140, Total Reward: -39\n",
      "Episode 8160, Total Reward: -33\n",
      "Episode 8180, Total Reward: -34\n",
      "Episode 8200, Total Reward: -35\n",
      "Episode 8220, Total Reward: -37\n",
      "Episode 8240, Total Reward: -39\n",
      "Episode 8260, Total Reward: -34\n",
      "Episode 8280, Total Reward: -35\n",
      "Episode 8300, Total Reward: -32\n",
      "Episode 8320, Total Reward: -42\n",
      "Episode 8340, Total Reward: -38\n",
      "Episode 8360, Total Reward: -38\n",
      "Episode 8380, Total Reward: -36\n",
      "Episode 8400, Total Reward: -34\n",
      "Episode 8420, Total Reward: -37\n",
      "Episode 8440, Total Reward: -35\n",
      "Episode 8460, Total Reward: -32\n",
      "Episode 8480, Total Reward: -37\n",
      "Episode 8500, Total Reward: -36\n",
      "Episode 8520, Total Reward: -35\n",
      "Episode 8540, Total Reward: -39\n",
      "Episode 8560, Total Reward: -40\n",
      "Episode 8580, Total Reward: -33\n",
      "Episode 8600, Total Reward: -40\n",
      "Episode 8620, Total Reward: -37\n",
      "Episode 8640, Total Reward: -39\n",
      "Episode 8660, Total Reward: -32\n",
      "Episode 8680, Total Reward: -34\n",
      "Episode 8700, Total Reward: -36\n",
      "Episode 8720, Total Reward: -38\n",
      "Episode 8740, Total Reward: -33\n",
      "Episode 8760, Total Reward: -34\n",
      "Episode 8780, Total Reward: -37\n",
      "Episode 8800, Total Reward: -34\n",
      "Episode 8820, Total Reward: -36\n",
      "Episode 8840, Total Reward: -36\n",
      "Episode 8860, Total Reward: -39\n",
      "Episode 8880, Total Reward: -33\n",
      "Episode 8900, Total Reward: -39\n",
      "Episode 8920, Total Reward: -39\n",
      "Episode 8940, Total Reward: -38\n",
      "Episode 8960, Total Reward: -36\n",
      "Episode 8980, Total Reward: -34\n",
      "Episode 9000, Total Reward: -33\n",
      "Episode 9020, Total Reward: -39\n",
      "Episode 9040, Total Reward: -36\n",
      "Episode 9060, Total Reward: -31\n",
      "Episode 9080, Total Reward: -33\n",
      "Episode 9100, Total Reward: -36\n",
      "Episode 9120, Total Reward: -34\n",
      "Episode 9140, Total Reward: -40\n",
      "Episode 9160, Total Reward: -30\n",
      "Episode 9180, Total Reward: -36\n",
      "Episode 9200, Total Reward: -30\n",
      "Episode 9220, Total Reward: -33\n",
      "Episode 9240, Total Reward: -44\n",
      "Episode 9260, Total Reward: -34\n",
      "Episode 9280, Total Reward: -36\n",
      "Episode 9300, Total Reward: -38\n",
      "Episode 9320, Total Reward: -36\n",
      "Episode 9340, Total Reward: -34\n",
      "Episode 9360, Total Reward: -38\n",
      "Episode 9380, Total Reward: -32\n",
      "Episode 9400, Total Reward: -34\n",
      "Episode 9420, Total Reward: -34\n",
      "Episode 9440, Total Reward: -35\n",
      "Episode 9460, Total Reward: -33\n",
      "Episode 9480, Total Reward: -35\n",
      "Episode 9500, Total Reward: -34\n",
      "Episode 9520, Total Reward: -30\n",
      "Episode 9540, Total Reward: -35\n",
      "Episode 9560, Total Reward: -35\n",
      "Episode 9580, Total Reward: -32\n",
      "Episode 9600, Total Reward: -32\n",
      "Episode 9620, Total Reward: -35\n",
      "Episode 9640, Total Reward: -34\n",
      "Episode 9660, Total Reward: -35\n",
      "Episode 9680, Total Reward: -35\n",
      "Episode 9700, Total Reward: -32\n",
      "Episode 9720, Total Reward: -34\n",
      "Episode 9740, Total Reward: -34\n",
      "Episode 9760, Total Reward: -37\n",
      "Episode 9780, Total Reward: -33\n",
      "Episode 9800, Total Reward: -37\n",
      "Episode 9820, Total Reward: -34\n",
      "Episode 9840, Total Reward: -34\n",
      "Episode 9860, Total Reward: -37\n",
      "Episode 9880, Total Reward: -36\n",
      "Episode 9900, Total Reward: -37\n",
      "Episode 9920, Total Reward: -36\n",
      "Episode 9940, Total Reward: -40\n",
      "Episode 9960, Total Reward: -32\n",
      "Episode 9980, Total Reward: -34\n",
      "Episode 10000, Total Reward: -275.52976908672593\n",
      "Episode 10020, Total Reward: -34\n",
      "Episode 10040, Total Reward: -40\n",
      "Episode 10060, Total Reward: -31\n",
      "Episode 10080, Total Reward: -35\n",
      "Episode 10100, Total Reward: -37\n",
      "Episode 10120, Total Reward: -36\n",
      "Episode 10140, Total Reward: -34\n",
      "Episode 10160, Total Reward: -36\n",
      "Episode 10180, Total Reward: -36\n",
      "Episode 10200, Total Reward: -35\n",
      "Episode 10220, Total Reward: -34\n",
      "Episode 10240, Total Reward: -37\n",
      "Episode 10260, Total Reward: -36\n",
      "Episode 10280, Total Reward: -37\n",
      "Episode 10300, Total Reward: -34\n",
      "Episode 10320, Total Reward: -32\n",
      "Episode 10340, Total Reward: -36\n",
      "Episode 10360, Total Reward: -34\n",
      "Episode 10380, Total Reward: -30\n",
      "Episode 10400, Total Reward: -36\n",
      "Episode 10420, Total Reward: -38\n",
      "Episode 10440, Total Reward: -34\n",
      "Episode 10460, Total Reward: -38\n",
      "Episode 10480, Total Reward: -35\n",
      "Episode 10500, Total Reward: -33\n",
      "Episode 10520, Total Reward: -34\n",
      "Episode 10540, Total Reward: -37\n",
      "Episode 10560, Total Reward: -32\n",
      "Episode 10580, Total Reward: -35\n",
      "Episode 10600, Total Reward: -31\n",
      "Episode 10620, Total Reward: -36\n",
      "Episode 10640, Total Reward: -32\n",
      "Episode 10660, Total Reward: -33\n",
      "Episode 10680, Total Reward: -41\n",
      "Episode 10700, Total Reward: -37\n",
      "Episode 10720, Total Reward: -37\n",
      "Episode 10740, Total Reward: -42\n",
      "Episode 10760, Total Reward: -43\n",
      "Episode 10780, Total Reward: -40\n",
      "Episode 10800, Total Reward: -35\n",
      "Episode 10820, Total Reward: -32\n",
      "Episode 10840, Total Reward: -37\n",
      "Episode 10860, Total Reward: -39\n",
      "Episode 10880, Total Reward: -31\n",
      "Episode 10900, Total Reward: -37\n",
      "Episode 10920, Total Reward: -36\n",
      "Episode 10940, Total Reward: -41\n",
      "Episode 10960, Total Reward: -33\n",
      "Episode 10980, Total Reward: -37\n",
      "Episode 11000, Total Reward: -32\n",
      "Episode 11020, Total Reward: -41\n",
      "Episode 11040, Total Reward: -36\n",
      "Episode 11060, Total Reward: -37\n",
      "Episode 11080, Total Reward: -32\n",
      "Episode 11100, Total Reward: -36\n",
      "Episode 11120, Total Reward: -33\n",
      "Episode 11140, Total Reward: -30\n",
      "Episode 11160, Total Reward: -35\n",
      "Episode 11180, Total Reward: -33\n",
      "Episode 11200, Total Reward: -31\n",
      "Episode 11220, Total Reward: -35\n",
      "Episode 11240, Total Reward: -40\n",
      "Episode 11260, Total Reward: -33\n",
      "Episode 11280, Total Reward: -37\n",
      "Episode 11300, Total Reward: -34\n",
      "Episode 11320, Total Reward: -37\n",
      "Episode 11340, Total Reward: -36\n",
      "Episode 11360, Total Reward: -30\n",
      "Episode 11380, Total Reward: -38\n",
      "Episode 11400, Total Reward: -37\n",
      "Episode 11420, Total Reward: -32\n",
      "Episode 11440, Total Reward: -36\n",
      "Episode 11460, Total Reward: -38\n",
      "Episode 11480, Total Reward: -36\n",
      "Episode 11500, Total Reward: -32\n",
      "Episode 11520, Total Reward: -31\n",
      "Episode 11540, Total Reward: -37\n",
      "Episode 11560, Total Reward: -32\n",
      "Episode 11580, Total Reward: -42\n",
      "Episode 11600, Total Reward: -30\n",
      "Episode 11620, Total Reward: -37\n",
      "Episode 11640, Total Reward: -34\n",
      "Episode 11660, Total Reward: -33\n",
      "Episode 11680, Total Reward: -36\n",
      "Episode 11700, Total Reward: -32\n",
      "Episode 11720, Total Reward: -37\n",
      "Episode 11740, Total Reward: -32\n",
      "Episode 11760, Total Reward: -36\n",
      "Episode 11780, Total Reward: -32\n",
      "Episode 11800, Total Reward: -33\n",
      "Episode 11820, Total Reward: -33\n",
      "Episode 11840, Total Reward: -32\n",
      "Episode 11860, Total Reward: -35\n",
      "Episode 11880, Total Reward: -35\n",
      "Episode 11900, Total Reward: -32\n",
      "Episode 11920, Total Reward: -32\n",
      "Episode 11940, Total Reward: -40\n",
      "Episode 11960, Total Reward: -31\n",
      "Episode 11980, Total Reward: -37\n",
      "Episode 12000, Total Reward: -32\n",
      "Episode 12020, Total Reward: -31\n",
      "Episode 12040, Total Reward: -38\n",
      "Episode 12060, Total Reward: -34\n",
      "Episode 12080, Total Reward: -33\n",
      "Episode 12100, Total Reward: -31\n",
      "Episode 12120, Total Reward: -34\n",
      "Episode 12140, Total Reward: -37\n",
      "Episode 12160, Total Reward: -34\n",
      "Episode 12180, Total Reward: -41\n",
      "Episode 12200, Total Reward: -36\n",
      "Episode 12220, Total Reward: -39\n",
      "Episode 12240, Total Reward: -37\n",
      "Episode 12260, Total Reward: -34\n",
      "Episode 12280, Total Reward: -36\n",
      "Episode 12300, Total Reward: -35\n",
      "Episode 12320, Total Reward: -36\n",
      "Episode 12340, Total Reward: -35\n",
      "Episode 12360, Total Reward: -36\n",
      "Episode 12380, Total Reward: -32\n",
      "Episode 12400, Total Reward: -34\n",
      "Episode 12420, Total Reward: -43\n",
      "Episode 12440, Total Reward: -34\n",
      "Episode 12460, Total Reward: -32\n",
      "Episode 12480, Total Reward: -34\n",
      "Episode 12500, Total Reward: -40\n",
      "Episode 12520, Total Reward: -33\n",
      "Episode 12540, Total Reward: -32\n",
      "Episode 12560, Total Reward: -36\n",
      "Episode 12580, Total Reward: -32\n",
      "Episode 12600, Total Reward: -31\n",
      "Episode 12620, Total Reward: -34\n",
      "Episode 12640, Total Reward: -35\n",
      "Episode 12660, Total Reward: -34\n",
      "Episode 12680, Total Reward: -42\n",
      "Episode 12700, Total Reward: -39\n",
      "Episode 12720, Total Reward: -37\n",
      "Episode 12740, Total Reward: -37\n",
      "Episode 12760, Total Reward: -41\n",
      "Episode 12780, Total Reward: -35\n",
      "Episode 12800, Total Reward: -37\n",
      "Episode 12820, Total Reward: -35\n",
      "Episode 12840, Total Reward: -38\n",
      "Episode 12860, Total Reward: -35\n",
      "Episode 12880, Total Reward: -36\n",
      "Episode 12900, Total Reward: -36\n",
      "Episode 12920, Total Reward: -34\n",
      "Episode 12940, Total Reward: -34\n",
      "Episode 12960, Total Reward: -32\n",
      "Episode 12980, Total Reward: -35\n",
      "Episode 13000, Total Reward: -31\n",
      "Episode 13020, Total Reward: -34\n",
      "Episode 13040, Total Reward: -36\n",
      "Episode 13060, Total Reward: -36\n",
      "Episode 13080, Total Reward: -37\n",
      "Episode 13100, Total Reward: -35\n",
      "Episode 13120, Total Reward: -35\n",
      "Episode 13140, Total Reward: -33\n",
      "Episode 13160, Total Reward: -37\n",
      "Episode 13180, Total Reward: -37\n",
      "Episode 13200, Total Reward: -29\n",
      "Episode 13220, Total Reward: -39\n",
      "Episode 13240, Total Reward: -33\n",
      "Episode 13260, Total Reward: -269.92674312642896\n",
      "Episode 13280, Total Reward: -38\n",
      "Episode 13300, Total Reward: -35\n",
      "Episode 13320, Total Reward: -35\n",
      "Episode 13340, Total Reward: -33\n",
      "Episode 13360, Total Reward: -35\n",
      "Episode 13380, Total Reward: -31\n",
      "Episode 13400, Total Reward: -34\n",
      "Episode 13420, Total Reward: -34\n",
      "Episode 13440, Total Reward: -36\n",
      "Episode 13460, Total Reward: -35\n",
      "Episode 13480, Total Reward: -36\n",
      "Episode 13500, Total Reward: -34\n",
      "Episode 13520, Total Reward: -35\n",
      "Episode 13540, Total Reward: -34\n",
      "Episode 13560, Total Reward: -32\n",
      "Episode 13580, Total Reward: -41\n",
      "Episode 13600, Total Reward: -31\n",
      "Episode 13620, Total Reward: -32\n",
      "Episode 13640, Total Reward: -34\n",
      "Episode 13660, Total Reward: -30\n",
      "Episode 13680, Total Reward: -32\n",
      "Episode 13700, Total Reward: -38\n",
      "Episode 13720, Total Reward: -35\n",
      "Episode 13740, Total Reward: -34\n",
      "Episode 13760, Total Reward: -35\n",
      "Episode 13780, Total Reward: -35\n",
      "Episode 13800, Total Reward: -39\n",
      "Episode 13820, Total Reward: -32\n",
      "Episode 13840, Total Reward: -34\n",
      "Episode 13860, Total Reward: -34\n",
      "Episode 13880, Total Reward: -34\n",
      "Episode 13900, Total Reward: -36\n",
      "Episode 13920, Total Reward: -37\n",
      "Episode 13940, Total Reward: -32\n",
      "Episode 13960, Total Reward: -34\n",
      "Episode 13980, Total Reward: -33\n",
      "Episode 14000, Total Reward: -38\n",
      "Episode 14020, Total Reward: -36\n",
      "Episode 14040, Total Reward: -33\n",
      "Episode 14060, Total Reward: -38\n",
      "Episode 14080, Total Reward: -44\n",
      "Episode 14100, Total Reward: -39\n",
      "Episode 14120, Total Reward: -37\n",
      "Episode 14140, Total Reward: -37\n",
      "Episode 14160, Total Reward: -34\n",
      "Episode 14180, Total Reward: -34\n",
      "Episode 14200, Total Reward: -49\n",
      "Episode 14220, Total Reward: -35\n",
      "Episode 14240, Total Reward: -32\n",
      "Episode 14260, Total Reward: -35\n",
      "Episode 14280, Total Reward: -41\n",
      "Episode 14300, Total Reward: -41\n",
      "Episode 14320, Total Reward: -41\n",
      "Episode 14340, Total Reward: -37\n",
      "Episode 14360, Total Reward: -37\n",
      "Episode 14380, Total Reward: -35\n",
      "Episode 14400, Total Reward: -38\n",
      "Episode 14420, Total Reward: -37\n",
      "Episode 14440, Total Reward: -35\n",
      "Episode 14460, Total Reward: -37\n",
      "Episode 14480, Total Reward: -38\n",
      "Episode 14500, Total Reward: -37\n",
      "Episode 14520, Total Reward: -42\n",
      "Episode 14540, Total Reward: -37\n",
      "Episode 14560, Total Reward: -34\n",
      "Episode 14580, Total Reward: -43\n",
      "Episode 14600, Total Reward: -45\n",
      "Episode 14620, Total Reward: -34\n",
      "Episode 14640, Total Reward: -33\n",
      "Episode 14660, Total Reward: -37\n",
      "Episode 14680, Total Reward: -35\n",
      "Episode 14700, Total Reward: -39\n",
      "Episode 14720, Total Reward: -40\n",
      "Episode 14740, Total Reward: -37\n",
      "Episode 14760, Total Reward: -40\n",
      "Episode 14780, Total Reward: -34\n",
      "Episode 14800, Total Reward: -39\n",
      "Episode 14820, Total Reward: -35\n",
      "Episode 14840, Total Reward: -34\n",
      "Episode 14860, Total Reward: -34\n",
      "Episode 14880, Total Reward: -102\n",
      "Episode 14900, Total Reward: -38\n",
      "Episode 14920, Total Reward: -37\n",
      "Episode 14940, Total Reward: -40\n",
      "Episode 14960, Total Reward: -35\n",
      "Episode 14980, Total Reward: -41\n",
      "Episode 15000, Total Reward: -33\n",
      "Episode 15020, Total Reward: -35\n",
      "Episode 15040, Total Reward: -39\n",
      "Episode 15060, Total Reward: -42\n",
      "Episode 15080, Total Reward: -40\n",
      "Episode 15100, Total Reward: -42\n",
      "Episode 15120, Total Reward: -32\n",
      "Episode 15140, Total Reward: -39\n",
      "Episode 15160, Total Reward: -34\n",
      "Episode 15180, Total Reward: -40\n",
      "Episode 15200, Total Reward: -35\n",
      "Episode 15220, Total Reward: -37\n",
      "Episode 15240, Total Reward: -37\n",
      "Episode 15260, Total Reward: -36\n",
      "Episode 15280, Total Reward: -36\n",
      "Episode 15300, Total Reward: -35\n",
      "Episode 15320, Total Reward: -36\n",
      "Episode 15340, Total Reward: -36\n",
      "Episode 15360, Total Reward: -36\n",
      "Episode 15380, Total Reward: -36\n",
      "Episode 15400, Total Reward: -32\n",
      "Episode 15420, Total Reward: -38\n",
      "Episode 15440, Total Reward: -36\n",
      "Episode 15460, Total Reward: -37\n",
      "Episode 15480, Total Reward: -33\n",
      "Episode 15500, Total Reward: -36\n",
      "Episode 15520, Total Reward: -36\n",
      "Episode 15540, Total Reward: -34\n",
      "Episode 15560, Total Reward: -37\n",
      "Episode 15580, Total Reward: -37\n",
      "Episode 15600, Total Reward: -34\n",
      "Episode 15620, Total Reward: -36\n",
      "Episode 15640, Total Reward: -39\n",
      "Episode 15660, Total Reward: -42\n",
      "Episode 15680, Total Reward: -36\n",
      "Episode 15700, Total Reward: -38\n",
      "Episode 15720, Total Reward: -38\n",
      "Episode 15740, Total Reward: -37\n",
      "Episode 15760, Total Reward: -37\n",
      "Episode 15780, Total Reward: -43\n",
      "Episode 15800, Total Reward: -32\n",
      "Episode 15820, Total Reward: -36\n",
      "Episode 15840, Total Reward: -39\n",
      "Episode 15860, Total Reward: -39\n",
      "Episode 15880, Total Reward: -35\n",
      "Episode 15900, Total Reward: -35\n",
      "Episode 15920, Total Reward: -33\n",
      "Episode 15940, Total Reward: -37\n",
      "Episode 15960, Total Reward: -37\n",
      "Episode 15980, Total Reward: -34\n",
      "Episode 16000, Total Reward: -47\n",
      "Episode 16020, Total Reward: -39\n",
      "Episode 16040, Total Reward: -33\n",
      "Episode 16060, Total Reward: -39\n",
      "Episode 16080, Total Reward: -45\n",
      "Episode 16100, Total Reward: -35\n",
      "Episode 16120, Total Reward: -38\n",
      "Episode 16140, Total Reward: -38\n",
      "Episode 16160, Total Reward: -36\n",
      "Episode 16180, Total Reward: -34\n",
      "Episode 16200, Total Reward: -35\n",
      "Episode 16220, Total Reward: -38\n",
      "Episode 16240, Total Reward: -39\n",
      "Episode 16260, Total Reward: -37\n",
      "Episode 16280, Total Reward: -34\n",
      "Episode 16300, Total Reward: -35\n",
      "Episode 16320, Total Reward: -39\n",
      "Episode 16340, Total Reward: -38\n",
      "Episode 16360, Total Reward: -37\n",
      "Episode 16380, Total Reward: -41\n",
      "Episode 16400, Total Reward: -34\n",
      "Episode 16420, Total Reward: -43\n",
      "Episode 16440, Total Reward: -36\n",
      "Episode 16460, Total Reward: -41\n",
      "Episode 16480, Total Reward: -37\n",
      "Episode 16500, Total Reward: -36\n",
      "Episode 16520, Total Reward: -36\n",
      "Episode 16540, Total Reward: -37\n",
      "Episode 16560, Total Reward: -32\n",
      "Episode 16580, Total Reward: -39\n",
      "Episode 16600, Total Reward: -34\n",
      "Episode 16620, Total Reward: -40\n",
      "Episode 16640, Total Reward: -33\n",
      "Episode 16660, Total Reward: -37\n",
      "Episode 16680, Total Reward: -40\n",
      "Episode 16700, Total Reward: -37\n",
      "Episode 16720, Total Reward: -35\n",
      "Episode 16740, Total Reward: -38\n",
      "Episode 16760, Total Reward: -34\n",
      "Episode 16780, Total Reward: -35\n",
      "Episode 16800, Total Reward: -36\n",
      "Episode 16820, Total Reward: -35\n",
      "Episode 16840, Total Reward: -37\n",
      "Episode 16860, Total Reward: -38\n",
      "Episode 16880, Total Reward: -36\n",
      "Episode 16900, Total Reward: -39\n",
      "Episode 16920, Total Reward: -52\n",
      "Episode 16940, Total Reward: -35\n",
      "Episode 16960, Total Reward: -36\n",
      "Episode 16980, Total Reward: -31\n",
      "Episode 17000, Total Reward: -42\n",
      "Episode 17020, Total Reward: -41\n",
      "Episode 17040, Total Reward: -44\n",
      "Episode 17060, Total Reward: -38\n",
      "Episode 17080, Total Reward: -38\n",
      "Episode 17100, Total Reward: -32\n",
      "Episode 17120, Total Reward: -33\n",
      "Episode 17140, Total Reward: -39\n",
      "Episode 17160, Total Reward: -31\n",
      "Episode 17180, Total Reward: -35\n",
      "Episode 17200, Total Reward: -36\n",
      "Episode 17220, Total Reward: -36\n",
      "Episode 17240, Total Reward: -37\n",
      "Episode 17260, Total Reward: -31\n",
      "Episode 17280, Total Reward: -32\n",
      "Episode 17300, Total Reward: -34\n",
      "Episode 17320, Total Reward: -36\n",
      "Episode 17340, Total Reward: -38\n",
      "Episode 17360, Total Reward: -38\n",
      "Episode 17380, Total Reward: -34\n",
      "Episode 17400, Total Reward: -37\n",
      "Episode 17420, Total Reward: -36\n",
      "Episode 17440, Total Reward: -37\n",
      "Episode 17460, Total Reward: -41\n",
      "Episode 17480, Total Reward: -40\n",
      "Episode 17500, Total Reward: -38\n",
      "Episode 17520, Total Reward: -33\n",
      "Episode 17540, Total Reward: -40\n",
      "Episode 17560, Total Reward: -38\n",
      "Episode 17580, Total Reward: -37\n",
      "Episode 17600, Total Reward: -36\n",
      "Episode 17620, Total Reward: -39\n",
      "Episode 17640, Total Reward: -37\n",
      "Episode 17660, Total Reward: -35\n",
      "Episode 17680, Total Reward: -42\n",
      "Episode 17700, Total Reward: -35\n",
      "Episode 17720, Total Reward: -33\n",
      "Episode 17740, Total Reward: -35\n",
      "Episode 17760, Total Reward: -40\n",
      "Episode 17780, Total Reward: -39\n",
      "Episode 17800, Total Reward: -39\n",
      "Episode 17820, Total Reward: -37\n",
      "Episode 17840, Total Reward: -34\n",
      "Episode 17860, Total Reward: -37\n",
      "Episode 17880, Total Reward: -34\n",
      "Episode 17900, Total Reward: -41\n",
      "Episode 17920, Total Reward: -34\n",
      "Episode 17940, Total Reward: -35\n",
      "Episode 17960, Total Reward: -34\n",
      "Episode 17980, Total Reward: -37\n",
      "Episode 18000, Total Reward: -39\n",
      "Episode 18020, Total Reward: -35\n",
      "Episode 18040, Total Reward: -34\n",
      "Episode 18060, Total Reward: -34\n",
      "Episode 18080, Total Reward: -34\n",
      "Episode 18100, Total Reward: -36\n",
      "Episode 18120, Total Reward: -42\n",
      "Episode 18140, Total Reward: -33\n",
      "Episode 18160, Total Reward: -38\n",
      "Episode 18180, Total Reward: -34\n",
      "Episode 18200, Total Reward: -32\n",
      "Episode 18220, Total Reward: -35\n",
      "Episode 18240, Total Reward: -33\n",
      "Episode 18260, Total Reward: -37\n",
      "Episode 18280, Total Reward: -35\n",
      "Episode 18300, Total Reward: -39\n",
      "Episode 18320, Total Reward: -34\n",
      "Episode 18340, Total Reward: -39\n",
      "Episode 18360, Total Reward: -35\n",
      "Episode 18380, Total Reward: -39\n",
      "Episode 18400, Total Reward: -36\n",
      "Episode 18420, Total Reward: -32\n",
      "Episode 18440, Total Reward: -40\n",
      "Episode 18460, Total Reward: -31\n",
      "Episode 18480, Total Reward: -39\n",
      "Episode 18500, Total Reward: -36\n",
      "Episode 18520, Total Reward: -40\n",
      "Episode 18540, Total Reward: -30\n",
      "Episode 18560, Total Reward: -38\n",
      "Episode 18580, Total Reward: -40\n",
      "Episode 18600, Total Reward: -34\n",
      "Episode 18620, Total Reward: -37\n",
      "Episode 18640, Total Reward: -38\n",
      "Episode 18660, Total Reward: -39\n",
      "Episode 18680, Total Reward: -38\n",
      "Episode 18700, Total Reward: -36\n",
      "Episode 18720, Total Reward: -39\n",
      "Episode 18740, Total Reward: -41\n",
      "Episode 18760, Total Reward: -41\n",
      "Episode 18780, Total Reward: -39\n",
      "Episode 18800, Total Reward: -39\n",
      "Episode 18820, Total Reward: -48\n",
      "Episode 18840, Total Reward: -37\n",
      "Episode 18860, Total Reward: -37\n",
      "Episode 18880, Total Reward: -38\n",
      "Episode 18900, Total Reward: -46\n",
      "Episode 18920, Total Reward: -39\n",
      "Episode 18940, Total Reward: -39\n",
      "Episode 18960, Total Reward: -35\n",
      "Episode 18980, Total Reward: -36\n",
      "Episode 19000, Total Reward: -38\n",
      "Episode 19020, Total Reward: -37\n",
      "Episode 19040, Total Reward: -43\n",
      "Episode 19060, Total Reward: -36\n",
      "Episode 19080, Total Reward: -38\n",
      "Episode 19100, Total Reward: -41\n",
      "Episode 19120, Total Reward: -40\n",
      "Episode 19140, Total Reward: -37\n",
      "Episode 19160, Total Reward: -39\n",
      "Episode 19180, Total Reward: -41\n",
      "Episode 19200, Total Reward: -39\n",
      "Episode 19220, Total Reward: -38\n",
      "Episode 19240, Total Reward: -34\n",
      "Episode 19260, Total Reward: -40\n",
      "Episode 19280, Total Reward: -36\n",
      "Episode 19300, Total Reward: -38\n",
      "Episode 19320, Total Reward: -38\n",
      "Episode 19340, Total Reward: -42\n",
      "Episode 19360, Total Reward: -35\n",
      "Episode 19380, Total Reward: -41\n",
      "Episode 19400, Total Reward: -38\n",
      "Episode 19420, Total Reward: -37\n",
      "Episode 19440, Total Reward: -41\n",
      "Episode 19460, Total Reward: -43\n",
      "Episode 19480, Total Reward: -38\n",
      "Episode 19500, Total Reward: -41\n",
      "Episode 19520, Total Reward: -88\n",
      "Episode 19540, Total Reward: -40\n",
      "Episode 19560, Total Reward: -36\n",
      "Episode 19580, Total Reward: -45\n",
      "Episode 19600, Total Reward: -37\n",
      "Episode 19620, Total Reward: -37\n",
      "Episode 19640, Total Reward: -40\n",
      "Episode 19660, Total Reward: -36\n",
      "Episode 19680, Total Reward: -37\n",
      "Episode 19700, Total Reward: -37\n",
      "Episode 19720, Total Reward: -39\n",
      "Episode 19740, Total Reward: -40\n",
      "Episode 19760, Total Reward: -40\n",
      "Episode 19780, Total Reward: -41\n",
      "Episode 19800, Total Reward: -37\n",
      "Episode 19820, Total Reward: -39\n",
      "Episode 19840, Total Reward: -36\n",
      "Episode 19860, Total Reward: -38\n",
      "Episode 19880, Total Reward: -43\n",
      "Episode 19900, Total Reward: -41\n",
      "Episode 19920, Total Reward: -39\n",
      "Episode 19940, Total Reward: -37\n",
      "Episode 19960, Total Reward: -36\n",
      "Episode 19980, Total Reward: -40\n"
     ]
    }
   ],
   "source": [
    "## simulare the agent in the environment\n",
    "num_actions = len(env.get_wrapper_attr(\"actions\"))\n",
    "agent = tabularQlearning(num_feature= num_features, num_actions=num_actions)\n",
    "\n",
    "num_episodes = 20000\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    obs, info = env.reset()\n",
    "    state = rep2.get_features(obs)\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        action = agent.choose_action(state)\n",
    "        next_obs, reward, done, trunc, _ = env.step(action)\n",
    "        next_state = rep2.get_features(next_obs)\n",
    "        agent.update(state, action, reward, next_state)\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "    if episode % 20 == 0:\n",
    "        print(f\"Episode {episode}, Total Reward: {total_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " t: 0, observation: [0.21371513 0.36259785], reward: -1\n",
      " t: 1, observation: [0.23290961 0.30348163], reward: -1\n",
      " t: 2, observation: [0.29234912 0.31054592], reward: -1\n",
      " t: 3, observation: [0.28579703 0.23679995], reward: -1\n",
      " t: 4, observation: [0.34420396 0.22859063], reward: -1\n",
      " t: 5, observation: [0.38414518 0.22360445], reward: -1\n",
      " t: 6, observation: [0.39917397 0.15485799], reward: -1\n",
      " t: 7, observation: [0.42143574 0.15217083], reward: -1\n",
      " t: 8, observation: [0.46174983 0.14901301], reward: -1\n",
      " t: 9, observation: [0.5210789  0.14229894], reward: -1\n",
      " t: 10, observation: [0.55500813 0.14955454], reward: -1\n",
      " t: 11, observation: [0.58674531 0.14486291], reward: -1\n",
      " t: 12, observation: [0.65100055 0.14665314], reward: -1\n",
      " t: 13, observation: [0.70796233 0.14810806], reward: -1\n",
      " t: 14, observation: [0.72035433 0.20147673], reward: -1\n",
      " t: 15, observation: [0.74572434 0.21323116], reward: -1\n",
      " t: 16, observation: [0.75974332 0.28426362], reward: -1\n",
      " t: 17, observation: [0.81256805 0.26504935], reward: -1\n",
      " t: 18, observation: [0.80685676 0.31996775], reward: -1\n",
      " t: 19, observation: [0.80077293 0.37191464], reward: -1\n",
      " t: 20, observation: [0.85091604 0.34454861], reward: -1\n",
      " t: 21, observation: [0.84055145 0.4004128 ], reward: -1\n",
      " t: 22, observation: [0.83763286 0.44152982], reward: -1\n",
      " t: 23, observation: [0.8352976 0.466571 ], reward: -1\n",
      " t: 24, observation: [0.8527756  0.52273801], reward: -1\n",
      " t: 25, observation: [0.84828075 0.57905231], reward: -1\n",
      " t: 26, observation: [0.84987551 0.61875155], reward: -1\n",
      " t: 27, observation: [0.85823556 0.67580156], reward: -1\n",
      " t: 28, observation: [0.86595924 0.7395812 ], reward: -1\n",
      " t: 29, observation: [0.87731824 0.77844334], reward: -1\n",
      " t: 30, observation: [0.88457652 0.83904465], reward: -1\n",
      " t: 31, observation: [0.93795138 0.82744899], reward: -1\n",
      " t: 32, observation: [0.94843138 0.89106468], reward: -1\n",
      " t: 33, observation: [0.94794161 0.93135178], reward: -1\n",
      " t: 34, observation: [0.99816895 0.96282323], reward: 0\n",
      "total reward in this episode: -34\n",
      "episode 0: reward: -34\n"
     ]
    }
   ],
   "source": [
    "#Test the trained model\n",
    "obs, info = env.reset()\n",
    "total_reward = 0\n",
    "episode_rewards = []\n",
    "frames = []\n",
    "observation = obs\n",
    "\n",
    "max_video_length = 120\n",
    "\n",
    "\n",
    "observation_list = []\n",
    "\n",
    "def greedy_policy(state):\n",
    "    q_table = agent.get_q_table()\n",
    "    q = q_table[state].sum(axis=0)\n",
    "    return q.argmax()\n",
    "\n",
    "def e_greedy_policy(state, epsilon=0.01):\n",
    "    q_table = agent.get_q_table()\n",
    "    q = q_table[state].sum(axis=0)\n",
    "    if np.random.rand() < epsilon:\n",
    "        return np.random.choice(num_actions)\n",
    "    else:\n",
    "        return q.argmax()\n",
    "\n",
    "for time_step in range(max_video_length):\n",
    "    \n",
    "    frames.append(env.render())\n",
    "\n",
    "    #action = agent.choose_action(rep2.get_features(observation))\n",
    "    action = e_greedy_policy(rep2.get_features(observation))\n",
    "    observation, reward, done, trunc, _ = env.step(action)\n",
    "\n",
    "    # store the observation for visualization\n",
    "    observation_list.append(observation)\n",
    "    \n",
    "    total_reward += reward\n",
    "    image = env.render()\n",
    "    #online_rendering(image) #uncomment this line to see the online rendering of the environment frame by frame\n",
    "    frames.append(image)\n",
    "\n",
    "    print(f\" t: {time_step}, observation: {observation}, reward: {reward}\") #uncomment this line to see the environment-agent interaction details\n",
    "\n",
    "    if done:\n",
    "      print(f\"total reward in this episode: {total_reward}\")\n",
    "      episode_rewards.append(total_reward)\n",
    "      total_reward = 0\n",
    "      break\n",
    "\n",
    "env.close()\n",
    "\n",
    "if episode_rewards == []:\n",
    "  print(\"no episode finished in this run.\")\n",
    "else:\n",
    "  for i, reward in enumerate(episode_rewards):\n",
    "    print(f\"episode {i}: reward: {reward}\")\n",
    "\n",
    "visualize(frames, \"./Video/q_learning_adaKan.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SARSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tabularSARSA:\n",
    "    def __init__(self, num_feature, num_actions, alpha=0.1, gamma=0.9, epsilon=0.05, seed = selected_seed):\n",
    "        self.num_feature = num_feature\n",
    "        self.num_actions = num_actions\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "        # Initialize Q-table with -300\n",
    "        self.q_table = np.zeros((self.num_feature, self.num_actions))  \n",
    "\n",
    "        self.seed = seed    \n",
    "        # Set random seed\n",
    "        np.random.seed(self.seed)\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        \"\"\"Choose an action using epsilon-greedy policy\"\"\"\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            return np.random.choice(self.num_actions)\n",
    "        else:\n",
    "            q = self.q_table[state].sum(axis=0)\n",
    "            return q.argmax()\n",
    "    \n",
    "    def update(self, state, action, reward, next_state):\n",
    "        \"\"\"Update the Q-table using SARSA update rule\"\"\"\n",
    "        next_action = self.choose_action(next_state)\n",
    "        self.q_table[state, action] += self.alpha * (reward + self.gamma * self.q_table[next_state, next_action] - self.q_table[state, action])\n",
    "        \n",
    "    def get_q_table(self):\n",
    "        return self.q_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0, Total Reward: -1779.3214516202006\n",
      "Episode 20, Total Reward: -508.8267948300371\n",
      "Episode 40, Total Reward: -256\n",
      "Episode 60, Total Reward: -521\n",
      "Episode 80, Total Reward: -282\n",
      "Episode 100, Total Reward: -90\n",
      "Episode 120, Total Reward: -118\n",
      "Episode 140, Total Reward: -358\n",
      "Episode 160, Total Reward: -129\n",
      "Episode 180, Total Reward: -165\n",
      "Episode 200, Total Reward: -113\n",
      "Episode 220, Total Reward: -64\n",
      "Episode 240, Total Reward: -103\n",
      "Episode 260, Total Reward: -69\n",
      "Episode 280, Total Reward: -89\n",
      "Episode 300, Total Reward: -83\n",
      "Episode 320, Total Reward: -74\n",
      "Episode 340, Total Reward: -118\n",
      "Episode 360, Total Reward: -90\n",
      "Episode 380, Total Reward: -68\n",
      "Episode 400, Total Reward: -80\n",
      "Episode 420, Total Reward: -50\n",
      "Episode 440, Total Reward: -48\n",
      "Episode 460, Total Reward: -46\n",
      "Episode 480, Total Reward: -46\n",
      "Episode 500, Total Reward: -93\n",
      "Episode 520, Total Reward: -50\n",
      "Episode 540, Total Reward: -92\n",
      "Episode 560, Total Reward: -73\n",
      "Episode 580, Total Reward: -65\n",
      "Episode 600, Total Reward: -80\n",
      "Episode 620, Total Reward: -62\n",
      "Episode 640, Total Reward: -44\n",
      "Episode 660, Total Reward: -45\n",
      "Episode 680, Total Reward: -61\n",
      "Episode 700, Total Reward: -56\n",
      "Episode 720, Total Reward: -52\n",
      "Episode 740, Total Reward: -42\n",
      "Episode 760, Total Reward: -40\n",
      "Episode 780, Total Reward: -51\n",
      "Episode 800, Total Reward: -43\n",
      "Episode 820, Total Reward: -42\n",
      "Episode 840, Total Reward: -41\n",
      "Episode 860, Total Reward: -65\n",
      "Episode 880, Total Reward: -41\n",
      "Episode 900, Total Reward: -55\n",
      "Episode 920, Total Reward: -60\n",
      "Episode 940, Total Reward: -64\n",
      "Episode 960, Total Reward: -47\n",
      "Episode 980, Total Reward: -49\n",
      "Episode 1000, Total Reward: -51\n",
      "Episode 1020, Total Reward: -49\n",
      "Episode 1040, Total Reward: -46\n",
      "Episode 1060, Total Reward: -40\n",
      "Episode 1080, Total Reward: -53\n",
      "Episode 1100, Total Reward: -48\n",
      "Episode 1120, Total Reward: -39\n",
      "Episode 1140, Total Reward: -42\n",
      "Episode 1160, Total Reward: -47\n",
      "Episode 1180, Total Reward: -57\n",
      "Episode 1200, Total Reward: -37\n",
      "Episode 1220, Total Reward: -50\n",
      "Episode 1240, Total Reward: -46\n",
      "Episode 1260, Total Reward: -57\n",
      "Episode 1280, Total Reward: -48\n",
      "Episode 1300, Total Reward: -44\n",
      "Episode 1320, Total Reward: -44\n",
      "Episode 1340, Total Reward: -51\n",
      "Episode 1360, Total Reward: -48\n",
      "Episode 1380, Total Reward: -35\n",
      "Episode 1400, Total Reward: -47\n",
      "Episode 1420, Total Reward: -41\n",
      "Episode 1440, Total Reward: -36\n",
      "Episode 1460, Total Reward: -31\n",
      "Episode 1480, Total Reward: -41\n",
      "Episode 1500, Total Reward: -41\n",
      "Episode 1520, Total Reward: -49\n",
      "Episode 1540, Total Reward: -43\n",
      "Episode 1560, Total Reward: -42\n",
      "Episode 1580, Total Reward: -39\n",
      "Episode 1600, Total Reward: -45\n",
      "Episode 1620, Total Reward: -41\n",
      "Episode 1640, Total Reward: -39\n",
      "Episode 1660, Total Reward: -39\n",
      "Episode 1680, Total Reward: -42\n",
      "Episode 1700, Total Reward: -40\n",
      "Episode 1720, Total Reward: -50\n",
      "Episode 1740, Total Reward: -39\n",
      "Episode 1760, Total Reward: -40\n",
      "Episode 1780, Total Reward: -42\n",
      "Episode 1800, Total Reward: -45\n",
      "Episode 1820, Total Reward: -44\n",
      "Episode 1840, Total Reward: -40\n",
      "Episode 1860, Total Reward: -39\n",
      "Episode 1880, Total Reward: -38\n",
      "Episode 1900, Total Reward: -39\n",
      "Episode 1920, Total Reward: -45\n",
      "Episode 1940, Total Reward: -36\n",
      "Episode 1960, Total Reward: -57\n",
      "Episode 1980, Total Reward: -38\n",
      "Episode 2000, Total Reward: -44\n",
      "Episode 2020, Total Reward: -45\n",
      "Episode 2040, Total Reward: -41\n",
      "Episode 2060, Total Reward: -42\n",
      "Episode 2080, Total Reward: -51\n",
      "Episode 2100, Total Reward: -37\n",
      "Episode 2120, Total Reward: -38\n",
      "Episode 2140, Total Reward: -46\n",
      "Episode 2160, Total Reward: -38\n",
      "Episode 2180, Total Reward: -42\n",
      "Episode 2200, Total Reward: -41\n",
      "Episode 2220, Total Reward: -41\n",
      "Episode 2240, Total Reward: -38\n",
      "Episode 2260, Total Reward: -38\n",
      "Episode 2280, Total Reward: -36\n",
      "Episode 2300, Total Reward: -40\n",
      "Episode 2320, Total Reward: -45\n",
      "Episode 2340, Total Reward: -42\n",
      "Episode 2360, Total Reward: -34\n",
      "Episode 2380, Total Reward: -42\n",
      "Episode 2400, Total Reward: -38\n",
      "Episode 2420, Total Reward: -36\n",
      "Episode 2440, Total Reward: -37\n",
      "Episode 2460, Total Reward: -39\n",
      "Episode 2480, Total Reward: -40\n",
      "Episode 2500, Total Reward: -39\n",
      "Episode 2520, Total Reward: -41\n",
      "Episode 2540, Total Reward: -36\n",
      "Episode 2560, Total Reward: -42\n",
      "Episode 2580, Total Reward: -37\n",
      "Episode 2600, Total Reward: -38\n",
      "Episode 2620, Total Reward: -40\n",
      "Episode 2640, Total Reward: -37\n",
      "Episode 2660, Total Reward: -43\n",
      "Episode 2680, Total Reward: -39\n",
      "Episode 2700, Total Reward: -44\n",
      "Episode 2720, Total Reward: -36\n",
      "Episode 2740, Total Reward: -36\n",
      "Episode 2760, Total Reward: -43\n",
      "Episode 2780, Total Reward: -40\n",
      "Episode 2800, Total Reward: -42\n",
      "Episode 2820, Total Reward: -35\n",
      "Episode 2840, Total Reward: -42\n",
      "Episode 2860, Total Reward: -50\n",
      "Episode 2880, Total Reward: -42\n",
      "Episode 2900, Total Reward: -39\n",
      "Episode 2920, Total Reward: -35\n",
      "Episode 2940, Total Reward: -42\n",
      "Episode 2960, Total Reward: -38\n",
      "Episode 2980, Total Reward: -40\n",
      "Episode 3000, Total Reward: -42\n",
      "Episode 3020, Total Reward: -43\n",
      "Episode 3040, Total Reward: -41\n",
      "Episode 3060, Total Reward: -37\n",
      "Episode 3080, Total Reward: -40\n",
      "Episode 3100, Total Reward: -41\n",
      "Episode 3120, Total Reward: -33\n",
      "Episode 3140, Total Reward: -37\n",
      "Episode 3160, Total Reward: -39\n",
      "Episode 3180, Total Reward: -41\n",
      "Episode 3200, Total Reward: -47\n",
      "Episode 3220, Total Reward: -35\n",
      "Episode 3240, Total Reward: -44\n",
      "Episode 3260, Total Reward: -39\n",
      "Episode 3280, Total Reward: -39\n",
      "Episode 3300, Total Reward: -38\n",
      "Episode 3320, Total Reward: -38\n",
      "Episode 3340, Total Reward: -40\n",
      "Episode 3360, Total Reward: -41\n",
      "Episode 3380, Total Reward: -39\n",
      "Episode 3400, Total Reward: -42\n",
      "Episode 3420, Total Reward: -38\n",
      "Episode 3440, Total Reward: -38\n",
      "Episode 3460, Total Reward: -40\n",
      "Episode 3480, Total Reward: -40\n",
      "Episode 3500, Total Reward: -41\n",
      "Episode 3520, Total Reward: -38\n",
      "Episode 3540, Total Reward: -38\n",
      "Episode 3560, Total Reward: -37\n",
      "Episode 3580, Total Reward: -39\n",
      "Episode 3600, Total Reward: -40\n",
      "Episode 3620, Total Reward: -39\n",
      "Episode 3640, Total Reward: -44\n",
      "Episode 3660, Total Reward: -41\n",
      "Episode 3680, Total Reward: -37\n",
      "Episode 3700, Total Reward: -44\n",
      "Episode 3720, Total Reward: -37\n",
      "Episode 3740, Total Reward: -41\n",
      "Episode 3760, Total Reward: -41\n",
      "Episode 3780, Total Reward: -36\n",
      "Episode 3800, Total Reward: -34\n",
      "Episode 3820, Total Reward: -47\n",
      "Episode 3840, Total Reward: -39\n",
      "Episode 3860, Total Reward: -35\n",
      "Episode 3880, Total Reward: -40\n",
      "Episode 3900, Total Reward: -41\n",
      "Episode 3920, Total Reward: -41\n",
      "Episode 3940, Total Reward: -42\n",
      "Episode 3960, Total Reward: -35\n",
      "Episode 3980, Total Reward: -40\n",
      "Episode 4000, Total Reward: -39\n",
      "Episode 4020, Total Reward: -41\n",
      "Episode 4040, Total Reward: -37\n",
      "Episode 4060, Total Reward: -41\n",
      "Episode 4080, Total Reward: -41\n",
      "Episode 4100, Total Reward: -38\n",
      "Episode 4120, Total Reward: -40\n",
      "Episode 4140, Total Reward: -44\n",
      "Episode 4160, Total Reward: -43\n",
      "Episode 4180, Total Reward: -36\n",
      "Episode 4200, Total Reward: -47\n",
      "Episode 4220, Total Reward: -34\n",
      "Episode 4240, Total Reward: -43\n",
      "Episode 4260, Total Reward: -39\n",
      "Episode 4280, Total Reward: -36\n",
      "Episode 4300, Total Reward: -38\n",
      "Episode 4320, Total Reward: -35\n",
      "Episode 4340, Total Reward: -39\n",
      "Episode 4360, Total Reward: -39\n",
      "Episode 4380, Total Reward: -37\n",
      "Episode 4400, Total Reward: -41\n",
      "Episode 4420, Total Reward: -35\n",
      "Episode 4440, Total Reward: -37\n",
      "Episode 4460, Total Reward: -39\n",
      "Episode 4480, Total Reward: -35\n",
      "Episode 4500, Total Reward: -38\n",
      "Episode 4520, Total Reward: -40\n",
      "Episode 4540, Total Reward: -34\n",
      "Episode 4560, Total Reward: -35\n",
      "Episode 4580, Total Reward: -38\n",
      "Episode 4600, Total Reward: -37\n",
      "Episode 4620, Total Reward: -39\n",
      "Episode 4640, Total Reward: -39\n",
      "Episode 4660, Total Reward: -42\n",
      "Episode 4680, Total Reward: -41\n",
      "Episode 4700, Total Reward: -43\n",
      "Episode 4720, Total Reward: -43\n",
      "Episode 4740, Total Reward: -43\n",
      "Episode 4760, Total Reward: -41\n",
      "Episode 4780, Total Reward: -43\n",
      "Episode 4800, Total Reward: -40\n",
      "Episode 4820, Total Reward: -38\n",
      "Episode 4840, Total Reward: -40\n",
      "Episode 4860, Total Reward: -33\n",
      "Episode 4880, Total Reward: -45\n",
      "Episode 4900, Total Reward: -35\n",
      "Episode 4920, Total Reward: -39\n",
      "Episode 4940, Total Reward: -37\n",
      "Episode 4960, Total Reward: -40\n",
      "Episode 4980, Total Reward: -37\n",
      "Episode 5000, Total Reward: -42\n",
      "Episode 5020, Total Reward: -34\n",
      "Episode 5040, Total Reward: -36\n",
      "Episode 5060, Total Reward: -40\n",
      "Episode 5080, Total Reward: -34\n",
      "Episode 5100, Total Reward: -36\n",
      "Episode 5120, Total Reward: -35\n",
      "Episode 5140, Total Reward: -43\n",
      "Episode 5160, Total Reward: -41\n",
      "Episode 5180, Total Reward: -36\n",
      "Episode 5200, Total Reward: -37\n",
      "Episode 5220, Total Reward: -36\n",
      "Episode 5240, Total Reward: -36\n",
      "Episode 5260, Total Reward: -34\n",
      "Episode 5280, Total Reward: -36\n",
      "Episode 5300, Total Reward: -37\n",
      "Episode 5320, Total Reward: -44\n",
      "Episode 5340, Total Reward: -37\n",
      "Episode 5360, Total Reward: -38\n",
      "Episode 5380, Total Reward: -41\n",
      "Episode 5400, Total Reward: -37\n",
      "Episode 5420, Total Reward: -43\n",
      "Episode 5440, Total Reward: -42\n",
      "Episode 5460, Total Reward: -42\n",
      "Episode 5480, Total Reward: -36\n",
      "Episode 5500, Total Reward: -40\n",
      "Episode 5520, Total Reward: -38\n",
      "Episode 5540, Total Reward: -41\n",
      "Episode 5560, Total Reward: -38\n",
      "Episode 5580, Total Reward: -38\n",
      "Episode 5600, Total Reward: -39\n",
      "Episode 5620, Total Reward: -43\n",
      "Episode 5640, Total Reward: -38\n",
      "Episode 5660, Total Reward: -42\n",
      "Episode 5680, Total Reward: -35\n",
      "Episode 5700, Total Reward: -40\n",
      "Episode 5720, Total Reward: -44\n",
      "Episode 5740, Total Reward: -42\n",
      "Episode 5760, Total Reward: -37\n",
      "Episode 5780, Total Reward: -39\n",
      "Episode 5800, Total Reward: -40\n",
      "Episode 5820, Total Reward: -42\n",
      "Episode 5840, Total Reward: -38\n",
      "Episode 5860, Total Reward: -37\n",
      "Episode 5880, Total Reward: -39\n",
      "Episode 5900, Total Reward: -36\n",
      "Episode 5920, Total Reward: -41\n",
      "Episode 5940, Total Reward: -37\n",
      "Episode 5960, Total Reward: -39\n",
      "Episode 5980, Total Reward: -37\n",
      "Episode 6000, Total Reward: -43\n",
      "Episode 6020, Total Reward: -42\n",
      "Episode 6040, Total Reward: -36\n",
      "Episode 6060, Total Reward: -44\n",
      "Episode 6080, Total Reward: -41\n",
      "Episode 6100, Total Reward: -35\n",
      "Episode 6120, Total Reward: -42\n",
      "Episode 6140, Total Reward: -40\n",
      "Episode 6160, Total Reward: -41\n",
      "Episode 6180, Total Reward: -38\n",
      "Episode 6200, Total Reward: -38\n",
      "Episode 6220, Total Reward: -37\n",
      "Episode 6240, Total Reward: -42\n",
      "Episode 6260, Total Reward: -36\n",
      "Episode 6280, Total Reward: -38\n",
      "Episode 6300, Total Reward: -41\n",
      "Episode 6320, Total Reward: -43\n",
      "Episode 6340, Total Reward: -37\n",
      "Episode 6360, Total Reward: -34\n",
      "Episode 6380, Total Reward: -36\n",
      "Episode 6400, Total Reward: -36\n",
      "Episode 6420, Total Reward: -37\n",
      "Episode 6440, Total Reward: -34\n",
      "Episode 6460, Total Reward: -39\n",
      "Episode 6480, Total Reward: -39\n",
      "Episode 6500, Total Reward: -47\n",
      "Episode 6520, Total Reward: -36\n",
      "Episode 6540, Total Reward: -44\n",
      "Episode 6560, Total Reward: -36\n",
      "Episode 6580, Total Reward: -40\n",
      "Episode 6600, Total Reward: -40\n",
      "Episode 6620, Total Reward: -38\n",
      "Episode 6640, Total Reward: -38\n",
      "Episode 6660, Total Reward: -37\n",
      "Episode 6680, Total Reward: -43\n",
      "Episode 6700, Total Reward: -39\n",
      "Episode 6720, Total Reward: -33\n",
      "Episode 6740, Total Reward: -43\n",
      "Episode 6760, Total Reward: -42\n",
      "Episode 6780, Total Reward: -40\n",
      "Episode 6800, Total Reward: -36\n",
      "Episode 6820, Total Reward: -36\n",
      "Episode 6840, Total Reward: -42\n",
      "Episode 6860, Total Reward: -34\n",
      "Episode 6880, Total Reward: -35\n",
      "Episode 6900, Total Reward: -38\n",
      "Episode 6920, Total Reward: -38\n",
      "Episode 6940, Total Reward: -41\n",
      "Episode 6960, Total Reward: -43\n",
      "Episode 6980, Total Reward: -44\n",
      "Episode 7000, Total Reward: -37\n",
      "Episode 7020, Total Reward: -42\n",
      "Episode 7040, Total Reward: -37\n",
      "Episode 7060, Total Reward: -39\n",
      "Episode 7080, Total Reward: -36\n",
      "Episode 7100, Total Reward: -37\n",
      "Episode 7120, Total Reward: -35\n",
      "Episode 7140, Total Reward: -35\n",
      "Episode 7160, Total Reward: -39\n",
      "Episode 7180, Total Reward: -36\n",
      "Episode 7200, Total Reward: -34\n",
      "Episode 7220, Total Reward: -38\n",
      "Episode 7240, Total Reward: -47\n",
      "Episode 7260, Total Reward: -39\n",
      "Episode 7280, Total Reward: -37\n",
      "Episode 7300, Total Reward: -42\n",
      "Episode 7320, Total Reward: -37\n",
      "Episode 7340, Total Reward: -36\n",
      "Episode 7360, Total Reward: -43\n",
      "Episode 7380, Total Reward: -35\n",
      "Episode 7400, Total Reward: -39\n",
      "Episode 7420, Total Reward: -39\n",
      "Episode 7440, Total Reward: -39\n",
      "Episode 7460, Total Reward: -39\n",
      "Episode 7480, Total Reward: -37\n",
      "Episode 7500, Total Reward: -38\n",
      "Episode 7520, Total Reward: -44\n",
      "Episode 7540, Total Reward: -38\n",
      "Episode 7560, Total Reward: -40\n",
      "Episode 7580, Total Reward: -37\n",
      "Episode 7600, Total Reward: -39\n",
      "Episode 7620, Total Reward: -42\n",
      "Episode 7640, Total Reward: -43\n",
      "Episode 7660, Total Reward: -43\n",
      "Episode 7680, Total Reward: -42\n",
      "Episode 7700, Total Reward: -36\n",
      "Episode 7720, Total Reward: -35\n",
      "Episode 7740, Total Reward: -36\n",
      "Episode 7760, Total Reward: -43\n",
      "Episode 7780, Total Reward: -43\n",
      "Episode 7800, Total Reward: -37\n",
      "Episode 7820, Total Reward: -36\n",
      "Episode 7840, Total Reward: -44\n",
      "Episode 7860, Total Reward: -36\n",
      "Episode 7880, Total Reward: -47\n",
      "Episode 7900, Total Reward: -36\n",
      "Episode 7920, Total Reward: -38\n",
      "Episode 7940, Total Reward: -37\n",
      "Episode 7960, Total Reward: -38\n",
      "Episode 7980, Total Reward: -38\n",
      "Episode 8000, Total Reward: -35\n",
      "Episode 8020, Total Reward: -36\n",
      "Episode 8040, Total Reward: -45\n",
      "Episode 8060, Total Reward: -44\n",
      "Episode 8080, Total Reward: -42\n",
      "Episode 8100, Total Reward: -38\n",
      "Episode 8120, Total Reward: -37\n",
      "Episode 8140, Total Reward: -41\n",
      "Episode 8160, Total Reward: -35\n",
      "Episode 8180, Total Reward: -42\n",
      "Episode 8200, Total Reward: -43\n",
      "Episode 8220, Total Reward: -37\n",
      "Episode 8240, Total Reward: -46\n",
      "Episode 8260, Total Reward: -41\n",
      "Episode 8280, Total Reward: -36\n",
      "Episode 8300, Total Reward: -37\n",
      "Episode 8320, Total Reward: -36\n",
      "Episode 8340, Total Reward: -38\n",
      "Episode 8360, Total Reward: -35\n",
      "Episode 8380, Total Reward: -40\n",
      "Episode 8400, Total Reward: -36\n",
      "Episode 8420, Total Reward: -36\n",
      "Episode 8440, Total Reward: -42\n",
      "Episode 8460, Total Reward: -38\n",
      "Episode 8480, Total Reward: -37\n",
      "Episode 8500, Total Reward: -39\n",
      "Episode 8520, Total Reward: -37\n",
      "Episode 8540, Total Reward: -35\n",
      "Episode 8560, Total Reward: -34\n",
      "Episode 8580, Total Reward: -41\n",
      "Episode 8600, Total Reward: -41\n",
      "Episode 8620, Total Reward: -35\n",
      "Episode 8640, Total Reward: -40\n",
      "Episode 8660, Total Reward: -40\n",
      "Episode 8680, Total Reward: -38\n",
      "Episode 8700, Total Reward: -35\n",
      "Episode 8720, Total Reward: -35\n",
      "Episode 8740, Total Reward: -40\n",
      "Episode 8760, Total Reward: -37\n",
      "Episode 8780, Total Reward: -37\n",
      "Episode 8800, Total Reward: -40\n",
      "Episode 8820, Total Reward: -37\n",
      "Episode 8840, Total Reward: -38\n",
      "Episode 8860, Total Reward: -42\n",
      "Episode 8880, Total Reward: -34\n",
      "Episode 8900, Total Reward: -40\n",
      "Episode 8920, Total Reward: -40\n",
      "Episode 8940, Total Reward: -37\n",
      "Episode 8960, Total Reward: -34\n",
      "Episode 8980, Total Reward: -37\n",
      "Episode 9000, Total Reward: -35\n",
      "Episode 9020, Total Reward: -41\n",
      "Episode 9040, Total Reward: -41\n",
      "Episode 9060, Total Reward: -35\n",
      "Episode 9080, Total Reward: -41\n",
      "Episode 9100, Total Reward: -38\n",
      "Episode 9120, Total Reward: -36\n",
      "Episode 9140, Total Reward: -37\n",
      "Episode 9160, Total Reward: -38\n",
      "Episode 9180, Total Reward: -40\n",
      "Episode 9200, Total Reward: -34\n",
      "Episode 9220, Total Reward: -35\n",
      "Episode 9240, Total Reward: -43\n",
      "Episode 9260, Total Reward: -40\n",
      "Episode 9280, Total Reward: -42\n",
      "Episode 9300, Total Reward: -41\n",
      "Episode 9320, Total Reward: -36\n",
      "Episode 9340, Total Reward: -38\n",
      "Episode 9360, Total Reward: -36\n",
      "Episode 9380, Total Reward: -38\n",
      "Episode 9400, Total Reward: -45\n",
      "Episode 9420, Total Reward: -39\n",
      "Episode 9440, Total Reward: -38\n",
      "Episode 9460, Total Reward: -37\n",
      "Episode 9480, Total Reward: -42\n",
      "Episode 9500, Total Reward: -39\n",
      "Episode 9520, Total Reward: -36\n",
      "Episode 9540, Total Reward: -37\n",
      "Episode 9560, Total Reward: -42\n",
      "Episode 9580, Total Reward: -38\n",
      "Episode 9600, Total Reward: -39\n",
      "Episode 9620, Total Reward: -39\n",
      "Episode 9640, Total Reward: -40\n",
      "Episode 9660, Total Reward: -33\n",
      "Episode 9680, Total Reward: -43\n",
      "Episode 9700, Total Reward: -45\n",
      "Episode 9720, Total Reward: -35\n",
      "Episode 9740, Total Reward: -35\n",
      "Episode 9760, Total Reward: -34\n",
      "Episode 9780, Total Reward: -37\n",
      "Episode 9800, Total Reward: -38\n",
      "Episode 9820, Total Reward: -37\n",
      "Episode 9840, Total Reward: -41\n",
      "Episode 9860, Total Reward: -37\n",
      "Episode 9880, Total Reward: -39\n",
      "Episode 9900, Total Reward: -35\n",
      "Episode 9920, Total Reward: -43\n",
      "Episode 9940, Total Reward: -38\n",
      "Episode 9960, Total Reward: -38\n",
      "Episode 9980, Total Reward: -33\n",
      "Episode 10000, Total Reward: -41\n",
      "Episode 10020, Total Reward: -37\n",
      "Episode 10040, Total Reward: -41\n",
      "Episode 10060, Total Reward: -36\n",
      "Episode 10080, Total Reward: -39\n",
      "Episode 10100, Total Reward: -35\n",
      "Episode 10120, Total Reward: -38\n",
      "Episode 10140, Total Reward: -34\n",
      "Episode 10160, Total Reward: -36\n",
      "Episode 10180, Total Reward: -38\n",
      "Episode 10200, Total Reward: -39\n",
      "Episode 10220, Total Reward: -36\n",
      "Episode 10240, Total Reward: -37\n",
      "Episode 10260, Total Reward: -35\n",
      "Episode 10280, Total Reward: -41\n",
      "Episode 10300, Total Reward: -38\n",
      "Episode 10320, Total Reward: -42\n",
      "Episode 10340, Total Reward: -40\n",
      "Episode 10360, Total Reward: -41\n",
      "Episode 10380, Total Reward: -35\n",
      "Episode 10400, Total Reward: -39\n",
      "Episode 10420, Total Reward: -36\n",
      "Episode 10440, Total Reward: -39\n",
      "Episode 10460, Total Reward: -36\n",
      "Episode 10480, Total Reward: -44\n",
      "Episode 10500, Total Reward: -35\n",
      "Episode 10520, Total Reward: -47\n",
      "Episode 10540, Total Reward: -36\n",
      "Episode 10560, Total Reward: -35\n",
      "Episode 10580, Total Reward: -38\n",
      "Episode 10600, Total Reward: -39\n",
      "Episode 10620, Total Reward: -36\n",
      "Episode 10640, Total Reward: -35\n",
      "Episode 10660, Total Reward: -38\n",
      "Episode 10680, Total Reward: -40\n",
      "Episode 10700, Total Reward: -45\n",
      "Episode 10720, Total Reward: -38\n",
      "Episode 10740, Total Reward: -38\n",
      "Episode 10760, Total Reward: -37\n",
      "Episode 10780, Total Reward: -36\n",
      "Episode 10800, Total Reward: -41\n",
      "Episode 10820, Total Reward: -39\n",
      "Episode 10840, Total Reward: -36\n",
      "Episode 10860, Total Reward: -35\n",
      "Episode 10880, Total Reward: -35\n",
      "Episode 10900, Total Reward: -44\n",
      "Episode 10920, Total Reward: -36\n",
      "Episode 10940, Total Reward: -36\n",
      "Episode 10960, Total Reward: -38\n",
      "Episode 10980, Total Reward: -33\n",
      "Episode 11000, Total Reward: -39\n",
      "Episode 11020, Total Reward: -42\n",
      "Episode 11040, Total Reward: -37\n",
      "Episode 11060, Total Reward: -38\n",
      "Episode 11080, Total Reward: -38\n",
      "Episode 11100, Total Reward: -38\n",
      "Episode 11120, Total Reward: -37\n",
      "Episode 11140, Total Reward: -37\n",
      "Episode 11160, Total Reward: -44\n",
      "Episode 11180, Total Reward: -35\n",
      "Episode 11200, Total Reward: -38\n",
      "Episode 11220, Total Reward: -42\n",
      "Episode 11240, Total Reward: -37\n",
      "Episode 11260, Total Reward: -39\n",
      "Episode 11280, Total Reward: -38\n",
      "Episode 11300, Total Reward: -39\n",
      "Episode 11320, Total Reward: -37\n",
      "Episode 11340, Total Reward: -38\n",
      "Episode 11360, Total Reward: -37\n",
      "Episode 11380, Total Reward: -37\n",
      "Episode 11400, Total Reward: -35\n",
      "Episode 11420, Total Reward: -38\n",
      "Episode 11440, Total Reward: -36\n",
      "Episode 11460, Total Reward: -37\n",
      "Episode 11480, Total Reward: -37\n",
      "Episode 11500, Total Reward: -33\n",
      "Episode 11520, Total Reward: -45\n",
      "Episode 11540, Total Reward: -37\n",
      "Episode 11560, Total Reward: -42\n",
      "Episode 11580, Total Reward: -41\n",
      "Episode 11600, Total Reward: -44\n",
      "Episode 11620, Total Reward: -36\n",
      "Episode 11640, Total Reward: -39\n",
      "Episode 11660, Total Reward: -41\n",
      "Episode 11680, Total Reward: -36\n",
      "Episode 11700, Total Reward: -36\n",
      "Episode 11720, Total Reward: -36\n",
      "Episode 11740, Total Reward: -44\n",
      "Episode 11760, Total Reward: -37\n",
      "Episode 11780, Total Reward: -40\n",
      "Episode 11800, Total Reward: -43\n",
      "Episode 11820, Total Reward: -38\n",
      "Episode 11840, Total Reward: -44\n",
      "Episode 11860, Total Reward: -39\n",
      "Episode 11880, Total Reward: -38\n",
      "Episode 11900, Total Reward: -36\n",
      "Episode 11920, Total Reward: -43\n",
      "Episode 11940, Total Reward: -39\n",
      "Episode 11960, Total Reward: -40\n",
      "Episode 11980, Total Reward: -34\n",
      "Episode 12000, Total Reward: -39\n",
      "Episode 12020, Total Reward: -38\n",
      "Episode 12040, Total Reward: -43\n",
      "Episode 12060, Total Reward: -42\n",
      "Episode 12080, Total Reward: -39\n",
      "Episode 12100, Total Reward: -37\n",
      "Episode 12120, Total Reward: -39\n",
      "Episode 12140, Total Reward: -38\n",
      "Episode 12160, Total Reward: -37\n",
      "Episode 12180, Total Reward: -36\n",
      "Episode 12200, Total Reward: -39\n",
      "Episode 12220, Total Reward: -42\n",
      "Episode 12240, Total Reward: -43\n",
      "Episode 12260, Total Reward: -40\n",
      "Episode 12280, Total Reward: -36\n",
      "Episode 12300, Total Reward: -35\n",
      "Episode 12320, Total Reward: -38\n",
      "Episode 12340, Total Reward: -38\n",
      "Episode 12360, Total Reward: -37\n",
      "Episode 12380, Total Reward: -37\n",
      "Episode 12400, Total Reward: -36\n",
      "Episode 12420, Total Reward: -34\n",
      "Episode 12440, Total Reward: -34\n",
      "Episode 12460, Total Reward: -37\n",
      "Episode 12480, Total Reward: -42\n",
      "Episode 12500, Total Reward: -38\n",
      "Episode 12520, Total Reward: -42\n",
      "Episode 12540, Total Reward: -37\n",
      "Episode 12560, Total Reward: -39\n",
      "Episode 12580, Total Reward: -35\n",
      "Episode 12600, Total Reward: -37\n",
      "Episode 12620, Total Reward: -38\n",
      "Episode 12640, Total Reward: -35\n",
      "Episode 12660, Total Reward: -36\n",
      "Episode 12680, Total Reward: -39\n",
      "Episode 12700, Total Reward: -43\n",
      "Episode 12720, Total Reward: -34\n",
      "Episode 12740, Total Reward: -37\n",
      "Episode 12760, Total Reward: -38\n",
      "Episode 12780, Total Reward: -42\n",
      "Episode 12800, Total Reward: -40\n",
      "Episode 12820, Total Reward: -43\n",
      "Episode 12840, Total Reward: -36\n",
      "Episode 12860, Total Reward: -34\n",
      "Episode 12880, Total Reward: -39\n",
      "Episode 12900, Total Reward: -36\n",
      "Episode 12920, Total Reward: -39\n",
      "Episode 12940, Total Reward: -37\n",
      "Episode 12960, Total Reward: -35\n",
      "Episode 12980, Total Reward: -35\n",
      "Episode 13000, Total Reward: -38\n",
      "Episode 13020, Total Reward: -35\n",
      "Episode 13040, Total Reward: -35\n",
      "Episode 13060, Total Reward: -32\n",
      "Episode 13080, Total Reward: -41\n",
      "Episode 13100, Total Reward: -37\n",
      "Episode 13120, Total Reward: -32\n",
      "Episode 13140, Total Reward: -38\n",
      "Episode 13160, Total Reward: -37\n",
      "Episode 13180, Total Reward: -39\n",
      "Episode 13200, Total Reward: -36\n",
      "Episode 13220, Total Reward: -37\n",
      "Episode 13240, Total Reward: -39\n",
      "Episode 13260, Total Reward: -39\n",
      "Episode 13280, Total Reward: -37\n",
      "Episode 13300, Total Reward: -39\n",
      "Episode 13320, Total Reward: -35\n",
      "Episode 13340, Total Reward: -38\n",
      "Episode 13360, Total Reward: -36\n",
      "Episode 13380, Total Reward: -40\n",
      "Episode 13400, Total Reward: -34\n",
      "Episode 13420, Total Reward: -40\n",
      "Episode 13440, Total Reward: -43\n",
      "Episode 13460, Total Reward: -34\n",
      "Episode 13480, Total Reward: -39\n",
      "Episode 13500, Total Reward: -39\n",
      "Episode 13520, Total Reward: -39\n",
      "Episode 13540, Total Reward: -42\n",
      "Episode 13560, Total Reward: -40\n",
      "Episode 13580, Total Reward: -46\n",
      "Episode 13600, Total Reward: -42\n",
      "Episode 13620, Total Reward: -44\n",
      "Episode 13640, Total Reward: -41\n",
      "Episode 13660, Total Reward: -38\n",
      "Episode 13680, Total Reward: -34\n",
      "Episode 13700, Total Reward: -40\n",
      "Episode 13720, Total Reward: -37\n",
      "Episode 13740, Total Reward: -41\n",
      "Episode 13760, Total Reward: -37\n",
      "Episode 13780, Total Reward: -41\n",
      "Episode 13800, Total Reward: -36\n",
      "Episode 13820, Total Reward: -34\n",
      "Episode 13840, Total Reward: -37\n",
      "Episode 13860, Total Reward: -39\n",
      "Episode 13880, Total Reward: -40\n",
      "Episode 13900, Total Reward: -41\n",
      "Episode 13920, Total Reward: -39\n",
      "Episode 13940, Total Reward: -42\n",
      "Episode 13960, Total Reward: -37\n",
      "Episode 13980, Total Reward: -43\n",
      "Episode 14000, Total Reward: -42\n",
      "Episode 14020, Total Reward: -41\n",
      "Episode 14040, Total Reward: -39\n",
      "Episode 14060, Total Reward: -35\n",
      "Episode 14080, Total Reward: -36\n",
      "Episode 14100, Total Reward: -42\n",
      "Episode 14120, Total Reward: -37\n",
      "Episode 14140, Total Reward: -40\n",
      "Episode 14160, Total Reward: -40\n",
      "Episode 14180, Total Reward: -40\n",
      "Episode 14200, Total Reward: -41\n",
      "Episode 14220, Total Reward: -44\n",
      "Episode 14240, Total Reward: -40\n",
      "Episode 14260, Total Reward: -42\n",
      "Episode 14280, Total Reward: -41\n",
      "Episode 14300, Total Reward: -44\n",
      "Episode 14320, Total Reward: -44\n",
      "Episode 14340, Total Reward: -40\n",
      "Episode 14360, Total Reward: -43\n",
      "Episode 14380, Total Reward: -41\n",
      "Episode 14400, Total Reward: -43\n",
      "Episode 14420, Total Reward: -56\n",
      "Episode 14440, Total Reward: -38\n",
      "Episode 14460, Total Reward: -37\n",
      "Episode 14480, Total Reward: -41\n",
      "Episode 14500, Total Reward: -42\n",
      "Episode 14520, Total Reward: -46\n",
      "Episode 14540, Total Reward: -37\n",
      "Episode 14560, Total Reward: -34\n",
      "Episode 14580, Total Reward: -41\n",
      "Episode 14600, Total Reward: -38\n",
      "Episode 14620, Total Reward: -40\n",
      "Episode 14640, Total Reward: -36\n",
      "Episode 14660, Total Reward: -36\n",
      "Episode 14680, Total Reward: -35\n",
      "Episode 14700, Total Reward: -40\n",
      "Episode 14720, Total Reward: -34\n",
      "Episode 14740, Total Reward: -48\n",
      "Episode 14760, Total Reward: -35\n",
      "Episode 14780, Total Reward: -41\n",
      "Episode 14800, Total Reward: -42\n",
      "Episode 14820, Total Reward: -43\n",
      "Episode 14840, Total Reward: -39\n",
      "Episode 14860, Total Reward: -40\n",
      "Episode 14880, Total Reward: -44\n",
      "Episode 14900, Total Reward: -37\n",
      "Episode 14920, Total Reward: -34\n",
      "Episode 14940, Total Reward: -44\n",
      "Episode 14960, Total Reward: -36\n",
      "Episode 14980, Total Reward: -35\n",
      "Episode 15000, Total Reward: -38\n",
      "Episode 15020, Total Reward: -41\n",
      "Episode 15040, Total Reward: -42\n",
      "Episode 15060, Total Reward: -46\n",
      "Episode 15080, Total Reward: -38\n",
      "Episode 15100, Total Reward: -41\n",
      "Episode 15120, Total Reward: -40\n",
      "Episode 15140, Total Reward: -41\n",
      "Episode 15160, Total Reward: -42\n",
      "Episode 15180, Total Reward: -40\n",
      "Episode 15200, Total Reward: -38\n",
      "Episode 15220, Total Reward: -36\n",
      "Episode 15240, Total Reward: -38\n",
      "Episode 15260, Total Reward: -35\n",
      "Episode 15280, Total Reward: -43\n",
      "Episode 15300, Total Reward: -38\n",
      "Episode 15320, Total Reward: -36\n",
      "Episode 15340, Total Reward: -43\n",
      "Episode 15360, Total Reward: -42\n",
      "Episode 15380, Total Reward: -39\n",
      "Episode 15400, Total Reward: -46\n",
      "Episode 15420, Total Reward: -38\n",
      "Episode 15440, Total Reward: -36\n",
      "Episode 15460, Total Reward: -37\n",
      "Episode 15480, Total Reward: -35\n",
      "Episode 15500, Total Reward: -40\n",
      "Episode 15520, Total Reward: -38\n",
      "Episode 15540, Total Reward: -35\n",
      "Episode 15560, Total Reward: -38\n",
      "Episode 15580, Total Reward: -37\n",
      "Episode 15600, Total Reward: -36\n",
      "Episode 15620, Total Reward: -41\n",
      "Episode 15640, Total Reward: -39\n",
      "Episode 15660, Total Reward: -36\n",
      "Episode 15680, Total Reward: -35\n",
      "Episode 15700, Total Reward: -35\n",
      "Episode 15720, Total Reward: -38\n",
      "Episode 15740, Total Reward: -39\n",
      "Episode 15760, Total Reward: -39\n",
      "Episode 15780, Total Reward: -41\n",
      "Episode 15800, Total Reward: -39\n",
      "Episode 15820, Total Reward: -38\n",
      "Episode 15840, Total Reward: -42\n",
      "Episode 15860, Total Reward: -35\n",
      "Episode 15880, Total Reward: -40\n",
      "Episode 15900, Total Reward: -32\n",
      "Episode 15920, Total Reward: -40\n",
      "Episode 15940, Total Reward: -42\n",
      "Episode 15960, Total Reward: -38\n",
      "Episode 15980, Total Reward: -38\n",
      "Episode 16000, Total Reward: -37\n",
      "Episode 16020, Total Reward: -38\n",
      "Episode 16040, Total Reward: -38\n",
      "Episode 16060, Total Reward: -36\n",
      "Episode 16080, Total Reward: -40\n",
      "Episode 16100, Total Reward: -42\n",
      "Episode 16120, Total Reward: -34\n",
      "Episode 16140, Total Reward: -43\n",
      "Episode 16160, Total Reward: -42\n",
      "Episode 16180, Total Reward: -45\n",
      "Episode 16200, Total Reward: -35\n",
      "Episode 16220, Total Reward: -42\n",
      "Episode 16240, Total Reward: -43\n",
      "Episode 16260, Total Reward: -38\n",
      "Episode 16280, Total Reward: -34\n",
      "Episode 16300, Total Reward: -35\n",
      "Episode 16320, Total Reward: -39\n",
      "Episode 16340, Total Reward: -38\n",
      "Episode 16360, Total Reward: -38\n",
      "Episode 16380, Total Reward: -35\n",
      "Episode 16400, Total Reward: -40\n",
      "Episode 16420, Total Reward: -37\n",
      "Episode 16440, Total Reward: -40\n",
      "Episode 16460, Total Reward: -40\n",
      "Episode 16480, Total Reward: -39\n",
      "Episode 16500, Total Reward: -38\n",
      "Episode 16520, Total Reward: -35\n",
      "Episode 16540, Total Reward: -38\n",
      "Episode 16560, Total Reward: -36\n",
      "Episode 16580, Total Reward: -42\n",
      "Episode 16600, Total Reward: -46\n",
      "Episode 16620, Total Reward: -41\n",
      "Episode 16640, Total Reward: -42\n",
      "Episode 16660, Total Reward: -38\n",
      "Episode 16680, Total Reward: -43\n",
      "Episode 16700, Total Reward: -39\n",
      "Episode 16720, Total Reward: -36\n",
      "Episode 16740, Total Reward: -40\n",
      "Episode 16760, Total Reward: -42\n",
      "Episode 16780, Total Reward: -39\n",
      "Episode 16800, Total Reward: -37\n",
      "Episode 16820, Total Reward: -39\n",
      "Episode 16840, Total Reward: -40\n",
      "Episode 16860, Total Reward: -40\n",
      "Episode 16880, Total Reward: -42\n",
      "Episode 16900, Total Reward: -43\n",
      "Episode 16920, Total Reward: -43\n",
      "Episode 16940, Total Reward: -44\n",
      "Episode 16960, Total Reward: -37\n",
      "Episode 16980, Total Reward: -36\n",
      "Episode 17000, Total Reward: -41\n",
      "Episode 17020, Total Reward: -40\n",
      "Episode 17040, Total Reward: -41\n",
      "Episode 17060, Total Reward: -43\n",
      "Episode 17080, Total Reward: -38\n",
      "Episode 17100, Total Reward: -38\n",
      "Episode 17120, Total Reward: -46\n",
      "Episode 17140, Total Reward: -40\n",
      "Episode 17160, Total Reward: -36\n",
      "Episode 17180, Total Reward: -38\n",
      "Episode 17200, Total Reward: -33\n",
      "Episode 17220, Total Reward: -38\n",
      "Episode 17240, Total Reward: -34\n",
      "Episode 17260, Total Reward: -38\n",
      "Episode 17280, Total Reward: -39\n",
      "Episode 17300, Total Reward: -39\n",
      "Episode 17320, Total Reward: -44\n",
      "Episode 17340, Total Reward: -35\n",
      "Episode 17360, Total Reward: -37\n",
      "Episode 17380, Total Reward: -35\n",
      "Episode 17400, Total Reward: -40\n",
      "Episode 17420, Total Reward: -42\n",
      "Episode 17440, Total Reward: -43\n",
      "Episode 17460, Total Reward: -40\n",
      "Episode 17480, Total Reward: -40\n",
      "Episode 17500, Total Reward: -38\n",
      "Episode 17520, Total Reward: -39\n",
      "Episode 17540, Total Reward: -50\n",
      "Episode 17560, Total Reward: -37\n",
      "Episode 17580, Total Reward: -37\n",
      "Episode 17600, Total Reward: -45\n",
      "Episode 17620, Total Reward: -34\n",
      "Episode 17640, Total Reward: -35\n",
      "Episode 17660, Total Reward: -35\n",
      "Episode 17680, Total Reward: -41\n",
      "Episode 17700, Total Reward: -40\n",
      "Episode 17720, Total Reward: -39\n",
      "Episode 17740, Total Reward: -36\n",
      "Episode 17760, Total Reward: -34\n",
      "Episode 17780, Total Reward: -36\n",
      "Episode 17800, Total Reward: -40\n",
      "Episode 17820, Total Reward: -35\n",
      "Episode 17840, Total Reward: -36\n",
      "Episode 17860, Total Reward: -37\n",
      "Episode 17880, Total Reward: -41\n",
      "Episode 17900, Total Reward: -32\n",
      "Episode 17920, Total Reward: -39\n",
      "Episode 17940, Total Reward: -39\n",
      "Episode 17960, Total Reward: -44\n",
      "Episode 17980, Total Reward: -38\n",
      "Episode 18000, Total Reward: -38\n",
      "Episode 18020, Total Reward: -37\n",
      "Episode 18040, Total Reward: -35\n",
      "Episode 18060, Total Reward: -42\n",
      "Episode 18080, Total Reward: -39\n",
      "Episode 18100, Total Reward: -40\n",
      "Episode 18120, Total Reward: -39\n",
      "Episode 18140, Total Reward: -38\n",
      "Episode 18160, Total Reward: -36\n",
      "Episode 18180, Total Reward: -41\n",
      "Episode 18200, Total Reward: -45\n",
      "Episode 18220, Total Reward: -44\n",
      "Episode 18240, Total Reward: -36\n",
      "Episode 18260, Total Reward: -48\n",
      "Episode 18280, Total Reward: -39\n",
      "Episode 18300, Total Reward: -38\n",
      "Episode 18320, Total Reward: -34\n",
      "Episode 18340, Total Reward: -41\n",
      "Episode 18360, Total Reward: -37\n",
      "Episode 18380, Total Reward: -38\n",
      "Episode 18400, Total Reward: -37\n",
      "Episode 18420, Total Reward: -36\n",
      "Episode 18440, Total Reward: -40\n",
      "Episode 18460, Total Reward: -48\n",
      "Episode 18480, Total Reward: -35\n",
      "Episode 18500, Total Reward: -36\n",
      "Episode 18520, Total Reward: -37\n",
      "Episode 18540, Total Reward: -32\n",
      "Episode 18560, Total Reward: -36\n",
      "Episode 18580, Total Reward: -36\n",
      "Episode 18600, Total Reward: -38\n",
      "Episode 18620, Total Reward: -41\n",
      "Episode 18640, Total Reward: -42\n",
      "Episode 18660, Total Reward: -36\n",
      "Episode 18680, Total Reward: -37\n",
      "Episode 18700, Total Reward: -40\n",
      "Episode 18720, Total Reward: -41\n",
      "Episode 18740, Total Reward: -38\n",
      "Episode 18760, Total Reward: -38\n",
      "Episode 18780, Total Reward: -39\n",
      "Episode 18800, Total Reward: -39\n",
      "Episode 18820, Total Reward: -37\n",
      "Episode 18840, Total Reward: -34\n",
      "Episode 18860, Total Reward: -38\n",
      "Episode 18880, Total Reward: -41\n",
      "Episode 18900, Total Reward: -39\n",
      "Episode 18920, Total Reward: -41\n",
      "Episode 18940, Total Reward: -43\n",
      "Episode 18960, Total Reward: -39\n",
      "Episode 18980, Total Reward: -40\n",
      "Episode 19000, Total Reward: -37\n",
      "Episode 19020, Total Reward: -40\n",
      "Episode 19040, Total Reward: -37\n",
      "Episode 19060, Total Reward: -38\n",
      "Episode 19080, Total Reward: -36\n",
      "Episode 19100, Total Reward: -36\n",
      "Episode 19120, Total Reward: -43\n",
      "Episode 19140, Total Reward: -37\n",
      "Episode 19160, Total Reward: -43\n",
      "Episode 19180, Total Reward: -36\n",
      "Episode 19200, Total Reward: -38\n",
      "Episode 19220, Total Reward: -42\n",
      "Episode 19240, Total Reward: -40\n",
      "Episode 19260, Total Reward: -32\n",
      "Episode 19280, Total Reward: -35\n",
      "Episode 19300, Total Reward: -36\n",
      "Episode 19320, Total Reward: -40\n",
      "Episode 19340, Total Reward: -38\n",
      "Episode 19360, Total Reward: -35\n",
      "Episode 19380, Total Reward: -32\n",
      "Episode 19400, Total Reward: -38\n",
      "Episode 19420, Total Reward: -33\n",
      "Episode 19440, Total Reward: -34\n",
      "Episode 19460, Total Reward: -37\n",
      "Episode 19480, Total Reward: -40\n",
      "Episode 19500, Total Reward: -36\n",
      "Episode 19520, Total Reward: -42\n",
      "Episode 19540, Total Reward: -40\n",
      "Episode 19560, Total Reward: -34\n",
      "Episode 19580, Total Reward: -47\n",
      "Episode 19600, Total Reward: -38\n",
      "Episode 19620, Total Reward: -36\n",
      "Episode 19640, Total Reward: -37\n",
      "Episode 19660, Total Reward: -37\n",
      "Episode 19680, Total Reward: -37\n",
      "Episode 19700, Total Reward: -38\n",
      "Episode 19720, Total Reward: -36\n",
      "Episode 19740, Total Reward: -39\n",
      "Episode 19760, Total Reward: -37\n",
      "Episode 19780, Total Reward: -35\n",
      "Episode 19800, Total Reward: -38\n",
      "Episode 19820, Total Reward: -37\n",
      "Episode 19840, Total Reward: -34\n",
      "Episode 19860, Total Reward: -37\n",
      "Episode 19880, Total Reward: -36\n",
      "Episode 19900, Total Reward: -36\n",
      "Episode 19920, Total Reward: -35\n",
      "Episode 19940, Total Reward: -41\n",
      "Episode 19960, Total Reward: -40\n",
      "Episode 19980, Total Reward: -39\n"
     ]
    }
   ],
   "source": [
    "## simulare the agent in the environment\n",
    "num_actions = len(env.get_wrapper_attr(\"actions\"))\n",
    "agent = tabularSARSA(num_feature= num_features, num_actions=num_actions)\n",
    "\n",
    "num_episodes = 20000\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    obs, info = env.reset()\n",
    "    state = rep2.get_features(obs)\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        action = agent.choose_action(state)\n",
    "        next_obs, reward, done, trunc, _ = env.step(action)\n",
    "        next_state = rep2.get_features(next_obs)\n",
    "        agent.update(state, action, reward, next_state)\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "    if episode % 20 == 0:\n",
    "        print(f\"Episode {episode}, Total Reward: {total_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " t: 0, observation: [0.18109896 0.34434002], reward: -1\n",
      " t: 1, observation: [0.17475463 0.2993989 ], reward: -1\n",
      " t: 2, observation: [0.15182374 0.26565034], reward: -1\n",
      " t: 3, observation: [0.19492423 0.26631517], reward: -1\n",
      " t: 4, observation: [0.2439562  0.26771019], reward: -1\n",
      " t: 5, observation: [0.23398311 0.21434351], reward: -1\n",
      " t: 6, observation: [0.23760286 0.18231771], reward: -1\n",
      " t: 7, observation: [0.288164   0.18658099], reward: -1\n",
      " t: 8, observation: [0.32486946 0.19163075], reward: -1\n",
      " t: 9, observation: [0.33249667 0.14952698], reward: -1\n",
      " t: 10, observation: [0.38148143 0.14305208], reward: -1\n",
      " t: 11, observation: [0.4224275  0.14263039], reward: -1\n",
      " t: 12, observation: [0.4688803 0.1467381], reward: -1\n",
      " t: 13, observation: [0.51998314 0.12676839], reward: -1\n",
      " t: 14, observation: [0.57920296 0.13413094], reward: -1\n",
      " t: 15, observation: [0.61304657 0.1410567 ], reward: -1\n",
      " t: 16, observation: [0.65328166 0.15052604], reward: -1\n",
      " t: 17, observation: [0.65426097 0.21747219], reward: -1\n",
      " t: 18, observation: [0.65000681 0.26153812], reward: -1\n",
      " t: 19, observation: [0.65014019 0.30879547], reward: -1\n",
      " t: 20, observation: [0.70963338 0.31240231], reward: -1\n",
      " t: 21, observation: [0.71571792 0.3591138 ], reward: -1\n",
      " t: 22, observation: [0.71425897 0.41467956], reward: -1\n",
      " t: 23, observation: [0.71454834 0.47696688], reward: -1\n",
      " t: 24, observation: [0.7129621  0.52877013], reward: -1\n",
      " t: 25, observation: [0.71550931 0.57374026], reward: -1\n",
      " t: 26, observation: [0.7053908  0.63168534], reward: -1\n",
      " t: 27, observation: [0.76231548 0.63596396], reward: -1\n",
      " t: 28, observation: [0.76581189 0.58659914], reward: -1\n",
      " t: 29, observation: [0.81934425 0.59369175], reward: -1\n",
      " t: 30, observation: [0.83191709 0.64874327], reward: -1\n",
      " t: 31, observation: [0.82870916 0.70354483], reward: -1\n",
      " t: 32, observation: [0.80505514 0.75305716], reward: -1\n",
      " t: 33, observation: [0.79913976 0.822134  ], reward: -1\n",
      " t: 34, observation: [0.86064792 0.82525923], reward: -1\n",
      " t: 35, observation: [0.86155641 0.89149582], reward: -1\n",
      " t: 36, observation: [0.92294137 0.88343463], reward: -1\n",
      " t: 37, observation: [0.92894856 0.89751151], reward: -1\n",
      " t: 38, observation: [0.93384993 0.94098825], reward: -1\n",
      " t: 39, observation: [0.97560003 0.94939418], reward: 0\n",
      "total reward in this episode: -39\n",
      "episode 0: reward: -39\n"
     ]
    }
   ],
   "source": [
    "#Test the trained model\n",
    "obs, info = env.reset()\n",
    "total_reward = 0\n",
    "episode_rewards = []\n",
    "frames = []\n",
    "observation = obs\n",
    "\n",
    "max_video_length = 120\n",
    "\n",
    "\n",
    "observation_list = []\n",
    "\n",
    "def greedy_policy(state):\n",
    "    q_table = agent.get_q_table()\n",
    "    q = q_table[state].sum(axis=0)\n",
    "    return q.argmax()\n",
    "\n",
    "def e_greedy_policy(state, epsilon=0.01):\n",
    "    q_table = agent.get_q_table()\n",
    "    q = q_table[state].sum(axis=0)\n",
    "    if np.random.rand() < epsilon:\n",
    "        return np.random.choice(num_actions)\n",
    "    else:\n",
    "        return q.argmax()\n",
    "\n",
    "for time_step in range(max_video_length):\n",
    "    \n",
    "    frames.append(env.render())\n",
    "\n",
    "    #action = agent.choose_action(rep2.get_features(observation))\n",
    "    action = e_greedy_policy(rep2.get_features(observation))\n",
    "    observation, reward, done, trunc, _ = env.step(action)\n",
    "\n",
    "    # store the observation for visualization\n",
    "    observation_list.append(observation)\n",
    "    \n",
    "    total_reward += reward\n",
    "    image = env.render()\n",
    "    #online_rendering(image) #uncomment this line to see the online rendering of the environment frame by frame\n",
    "    frames.append(image)\n",
    "\n",
    "    print(f\" t: {time_step}, observation: {observation}, reward: {reward}\") #uncomment this line to see the environment-agent interaction details\n",
    "\n",
    "    if done:\n",
    "      print(f\"total reward in this episode: {total_reward}\")\n",
    "      episode_rewards.append(total_reward)\n",
    "      total_reward = 0\n",
    "      break\n",
    "\n",
    "env.close()\n",
    "\n",
    "if episode_rewards == []:\n",
    "  print(\"no episode finished in this run.\")\n",
    "else:\n",
    "  for i, reward in enumerate(episode_rewards):\n",
    "    print(f\"episode {i}: reward: {reward}\")\n",
    "\n",
    "visualize(frames, \"./Video/sarsa_adaKan.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State (2D): (0.6, 0.7)\n",
      "Features (2D): [0.18268352 0.40656966 0.27253179 0.60653066]\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class RBFFeatureTransformer2D:\n",
    "    def __init__(self, num_rbf, low, high, spread_factor=1.0):\n",
    "        \"\"\"\n",
    "        Initialize the RBF Feature Transformer for 2D data.\n",
    "        \n",
    "        Args:\n",
    "            num_rbf (int): Number of radial basis functions per dimension.\n",
    "            low (float): Lower bound of the state space.\n",
    "            high (float): Upper bound of the state space.\n",
    "            spread_factor (float): Factor controlling the spread of RBFs.\n",
    "        \"\"\"\n",
    "        self.num_rbf = num_rbf\n",
    "        self.low = low\n",
    "        self.high = high\n",
    "        self.centers_x = np.linspace(low, high, num_rbf)\n",
    "        self.centers_y = np.linspace(low, high, num_rbf)\n",
    "        self.width = (high - low) / (num_rbf * spread_factor)\n",
    "    \n",
    "    def transform(self, state):\n",
    "        \"\"\"\n",
    "        Transform the continuous state into a feature vector using 2D RBFs.\n",
    "        \n",
    "        Args:\n",
    "            state (tuple): Current state, tuple of (x, y) coordinates.\n",
    "            \n",
    "        Returns:\n",
    "            features (np.array): Feature vector representing the state.\n",
    "        \"\"\"\n",
    "        x, y = state\n",
    "        features = np.zeros(self.num_rbf**2)\n",
    "        for i in range(self.num_rbf):\n",
    "            for j in range(self.num_rbf):\n",
    "                index = i * self.num_rbf + j\n",
    "                features[index] = np.exp(-((x - self.centers_x[i])**2 + (y - self.centers_y[j])**2) / (2 * self.width**2))\n",
    "        return features\n",
    "\n",
    "# Example usage:\n",
    "num_rbf = 2\n",
    "low = 0\n",
    "high = 1\n",
    "transformer_2d = RBFFeatureTransformer2D(num_rbf, low, high)\n",
    "\n",
    "# Transform a 2D state\n",
    "state_2d = (0.6, 0.7)\n",
    "features_2d = transformer_2d.transform(state_2d)\n",
    "print(\"State (2D):\", state_2d)\n",
    "print(\"Features (2D):\", features_2d)\n",
    "print(len(features_2d))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the q-table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the final Q-table\n",
    "q_table = agent.get_q_table()\n",
    "\n",
    "\n",
    "# get the prototype features\n",
    "prototypes = rep.get_prototypes()\n",
    "\n",
    "# visualize the Q-table and the prototypes (3d plot)\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "for i in range(num_actions):\n",
    "    ax.scatter(prototypes[:, 0], prototypes[:, 1], q_table[:, i], label=f\"Action {i}\")\n",
    "ax.set_xlabel('Feature 1')\n",
    "ax.set_ylabel('Feature 2')\n",
    "ax.set_zlabel('Q-value')\n",
    "ax.legend()\n",
    "\n",
    "# Set the viewing angle\n",
    "ax.view_init(elev=30, azim=45)  # Change the elevation and azimuth angles as needed\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -18.45404215,   -4.68226389,  -19.24410156,   -3.57488016],\n",
       "       [ -10.43833243,   -5.53672894,   -5.79071851,   -5.2421585 ],\n",
       "       [  -0.208639  ,    0.        ,    0.        ,    0.        ],\n",
       "       ...,\n",
       "       [  -3.72791679,   -3.40143382,   -3.41592404,   -3.86563408],\n",
       "       [-146.8265474 ,   -6.62141124,  -22.09249306,  -49.74864797],\n",
       "       [  -3.99594914,   -3.59295226,   -4.03088964,   -3.35068753]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Learning with Eligibility Trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tabularQlearningET:\n",
    "    def __init__(self, num_feature, num_actions, alpha=0.1, gamma=0.99, epsilon=0.1, lambda_=0.9, seed = selected_seed):\n",
    "        self.num_feature = num_feature\n",
    "        self.num_actions = num_actions\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.lambda_ = lambda_\n",
    "\n",
    "        # Initialize Q-table with zeros\n",
    "        self.q_table = np.zeros((self.num_feature, num_actions))\n",
    "        self.eligibility = np.zeros(self.num_feature)\n",
    "\n",
    "        self.seed = seed\n",
    "        # Set random seed\n",
    "        np.random.seed(self.seed)\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        \"\"\"Choose an action using epsilon-greedy policy\"\"\"\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            return np.random.choice(self.num_actions)\n",
    "        else:\n",
    "            q = self.q_table[state].sum(axis=0)\n",
    "            return q.argmax()\n",
    "    \n",
    "    def update(self, state, action, reward, next_state):\n",
    "        self.eligibility *= self.gamma * self.lambda_\n",
    "        self.eligibility[state] =1\n",
    "\n",
    "        v_next = self.gamma * self.q_table[next_state].sum(axis=0).max()\n",
    "\n",
    "        td_error = reward + v_next - self.q_table[state, action].sum()\n",
    "\n",
    "        alpha = self.alpha / len(state)\n",
    "\n",
    "        self.q_table[:, action] += alpha * td_error * self.eligibility\n",
    "\n",
    "    def erase_eligibility(self):\n",
    "        self.eligibility = np.zeros(self.num_feature)\n",
    "        \n",
    "    def get_q_table(self):\n",
    "        return self.q_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0, Total Reward: -1533.755641180166\n",
      "Episode 20, Total Reward: -69\n",
      "Episode 40, Total Reward: -76\n",
      "Episode 60, Total Reward: -98\n",
      "Episode 80, Total Reward: -205\n",
      "Episode 100, Total Reward: -71\n",
      "Episode 120, Total Reward: -73\n",
      "Episode 140, Total Reward: -59\n",
      "Episode 160, Total Reward: -40\n",
      "Episode 180, Total Reward: -41\n",
      "Episode 200, Total Reward: -47\n",
      "Episode 220, Total Reward: -52\n",
      "Episode 240, Total Reward: -52\n",
      "Episode 260, Total Reward: -47\n",
      "Episode 280, Total Reward: -61\n",
      "Episode 300, Total Reward: -61\n",
      "Episode 320, Total Reward: -50\n",
      "Episode 340, Total Reward: -45\n",
      "Episode 360, Total Reward: -62\n",
      "Episode 380, Total Reward: -42\n",
      "Episode 400, Total Reward: -48\n",
      "Episode 420, Total Reward: -44\n",
      "Episode 440, Total Reward: -45\n",
      "Episode 460, Total Reward: -38\n",
      "Episode 480, Total Reward: -42\n",
      "Episode 500, Total Reward: -42\n",
      "Episode 520, Total Reward: -49\n",
      "Episode 540, Total Reward: -45\n",
      "Episode 560, Total Reward: -41\n",
      "Episode 580, Total Reward: -39\n",
      "Episode 600, Total Reward: -38\n",
      "Episode 620, Total Reward: -49\n",
      "Episode 640, Total Reward: -52\n",
      "Episode 660, Total Reward: -41\n",
      "Episode 680, Total Reward: -40\n",
      "Episode 700, Total Reward: -50\n",
      "Episode 720, Total Reward: -42\n",
      "Episode 740, Total Reward: -37\n",
      "Episode 760, Total Reward: -48\n",
      "Episode 780, Total Reward: -42\n",
      "Episode 800, Total Reward: -39\n",
      "Episode 820, Total Reward: -49\n",
      "Episode 840, Total Reward: -40\n",
      "Episode 860, Total Reward: -57\n",
      "Episode 880, Total Reward: -60\n",
      "Episode 900, Total Reward: -43\n",
      "Episode 920, Total Reward: -53\n",
      "Episode 940, Total Reward: -40\n",
      "Episode 960, Total Reward: -46\n",
      "Episode 980, Total Reward: -43\n",
      "Episode 1000, Total Reward: -49\n",
      "Episode 1020, Total Reward: -41\n",
      "Episode 1040, Total Reward: -43\n",
      "Episode 1060, Total Reward: -36\n",
      "Episode 1080, Total Reward: -43\n",
      "Episode 1100, Total Reward: -52\n",
      "Episode 1120, Total Reward: -49\n",
      "Episode 1140, Total Reward: -68\n",
      "Episode 1160, Total Reward: -41\n",
      "Episode 1180, Total Reward: -39\n",
      "Episode 1200, Total Reward: -44\n",
      "Episode 1220, Total Reward: -52\n",
      "Episode 1240, Total Reward: -49\n",
      "Episode 1260, Total Reward: -40\n",
      "Episode 1280, Total Reward: -47\n",
      "Episode 1300, Total Reward: -56\n",
      "Episode 1320, Total Reward: -48\n",
      "Episode 1340, Total Reward: -50\n",
      "Episode 1360, Total Reward: -42\n",
      "Episode 1380, Total Reward: -44\n",
      "Episode 1400, Total Reward: -41\n",
      "Episode 1420, Total Reward: -50\n",
      "Episode 1440, Total Reward: -53\n",
      "Episode 1460, Total Reward: -40\n",
      "Episode 1480, Total Reward: -53\n",
      "Episode 1500, Total Reward: -40\n",
      "Episode 1520, Total Reward: -44\n",
      "Episode 1540, Total Reward: -48\n",
      "Episode 1560, Total Reward: -43\n",
      "Episode 1580, Total Reward: -48\n",
      "Episode 1600, Total Reward: -48\n",
      "Episode 1620, Total Reward: -51\n",
      "Episode 1640, Total Reward: -48\n",
      "Episode 1660, Total Reward: -43\n",
      "Episode 1680, Total Reward: -43\n",
      "Episode 1700, Total Reward: -40\n",
      "Episode 1720, Total Reward: -39\n",
      "Episode 1740, Total Reward: -49\n",
      "Episode 1760, Total Reward: -37\n",
      "Episode 1780, Total Reward: -41\n",
      "Episode 1800, Total Reward: -44\n",
      "Episode 1820, Total Reward: -51\n",
      "Episode 1840, Total Reward: -44\n",
      "Episode 1860, Total Reward: -46\n",
      "Episode 1880, Total Reward: -46\n",
      "Episode 1900, Total Reward: -42\n",
      "Episode 1920, Total Reward: -40\n",
      "Episode 1940, Total Reward: -43\n",
      "Episode 1960, Total Reward: -38\n",
      "Episode 1980, Total Reward: -44\n",
      "Episode 2000, Total Reward: -50\n",
      "Episode 2020, Total Reward: -41\n",
      "Episode 2040, Total Reward: -50\n",
      "Episode 2060, Total Reward: -43\n",
      "Episode 2080, Total Reward: -48\n",
      "Episode 2100, Total Reward: -45\n",
      "Episode 2120, Total Reward: -42\n",
      "Episode 2140, Total Reward: -45\n",
      "Episode 2160, Total Reward: -49\n",
      "Episode 2180, Total Reward: -47\n",
      "Episode 2200, Total Reward: -45\n",
      "Episode 2220, Total Reward: -43\n",
      "Episode 2240, Total Reward: -47\n",
      "Episode 2260, Total Reward: -40\n",
      "Episode 2280, Total Reward: -46\n",
      "Episode 2300, Total Reward: -48\n",
      "Episode 2320, Total Reward: -40\n",
      "Episode 2340, Total Reward: -37\n",
      "Episode 2360, Total Reward: -48\n",
      "Episode 2380, Total Reward: -37\n",
      "Episode 2400, Total Reward: -39\n",
      "Episode 2420, Total Reward: -44\n",
      "Episode 2440, Total Reward: -37\n",
      "Episode 2460, Total Reward: -47\n",
      "Episode 2480, Total Reward: -43\n",
      "Episode 2500, Total Reward: -41\n",
      "Episode 2520, Total Reward: -43\n",
      "Episode 2540, Total Reward: -40\n",
      "Episode 2560, Total Reward: -49\n",
      "Episode 2580, Total Reward: -41\n",
      "Episode 2600, Total Reward: -49\n",
      "Episode 2620, Total Reward: -39\n",
      "Episode 2640, Total Reward: -40\n",
      "Episode 2660, Total Reward: -41\n",
      "Episode 2680, Total Reward: -43\n",
      "Episode 2700, Total Reward: -45\n",
      "Episode 2720, Total Reward: -39\n",
      "Episode 2740, Total Reward: -40\n",
      "Episode 2760, Total Reward: -43\n",
      "Episode 2780, Total Reward: -40\n",
      "Episode 2800, Total Reward: -39\n",
      "Episode 2820, Total Reward: -51\n",
      "Episode 2840, Total Reward: -45\n",
      "Episode 2860, Total Reward: -39\n",
      "Episode 2880, Total Reward: -36\n",
      "Episode 2900, Total Reward: -43\n",
      "Episode 2920, Total Reward: -43\n",
      "Episode 2940, Total Reward: -46\n",
      "Episode 2960, Total Reward: -47\n",
      "Episode 2980, Total Reward: -41\n",
      "Episode 3000, Total Reward: -44\n",
      "Episode 3020, Total Reward: -47\n",
      "Episode 3040, Total Reward: -48\n",
      "Episode 3060, Total Reward: -42\n",
      "Episode 3080, Total Reward: -51\n",
      "Episode 3100, Total Reward: -45\n",
      "Episode 3120, Total Reward: -427.76713353894297\n",
      "Episode 3140, Total Reward: -42\n",
      "Episode 3160, Total Reward: -42\n",
      "Episode 3180, Total Reward: -37\n",
      "Episode 3200, Total Reward: -45\n",
      "Episode 3220, Total Reward: -40\n",
      "Episode 3240, Total Reward: -39\n",
      "Episode 3260, Total Reward: -39\n",
      "Episode 3280, Total Reward: -46\n",
      "Episode 3300, Total Reward: -41\n",
      "Episode 3320, Total Reward: -42\n",
      "Episode 3340, Total Reward: -39\n",
      "Episode 3360, Total Reward: -41\n",
      "Episode 3380, Total Reward: -38\n",
      "Episode 3400, Total Reward: -52\n",
      "Episode 3420, Total Reward: -46\n",
      "Episode 3440, Total Reward: -41\n",
      "Episode 3460, Total Reward: -40\n",
      "Episode 3480, Total Reward: -39\n",
      "Episode 3500, Total Reward: -37\n",
      "Episode 3520, Total Reward: -50\n",
      "Episode 3540, Total Reward: -45\n",
      "Episode 3560, Total Reward: -42\n",
      "Episode 3580, Total Reward: -42\n",
      "Episode 3600, Total Reward: -43\n",
      "Episode 3620, Total Reward: -39\n",
      "Episode 3640, Total Reward: -41\n",
      "Episode 3660, Total Reward: -48\n",
      "Episode 3680, Total Reward: -46\n",
      "Episode 3700, Total Reward: -38\n",
      "Episode 3720, Total Reward: -41\n",
      "Episode 3740, Total Reward: -45\n",
      "Episode 3760, Total Reward: -50\n",
      "Episode 3780, Total Reward: -49\n",
      "Episode 3800, Total Reward: -42\n",
      "Episode 3820, Total Reward: -44\n",
      "Episode 3840, Total Reward: -41\n",
      "Episode 3860, Total Reward: -42\n",
      "Episode 3880, Total Reward: -44\n",
      "Episode 3900, Total Reward: -56\n",
      "Episode 3920, Total Reward: -48\n",
      "Episode 3940, Total Reward: -38\n",
      "Episode 3960, Total Reward: -41\n",
      "Episode 3980, Total Reward: -41\n",
      "Episode 4000, Total Reward: -44\n",
      "Episode 4020, Total Reward: -40\n",
      "Episode 4040, Total Reward: -45\n",
      "Episode 4060, Total Reward: -46\n",
      "Episode 4080, Total Reward: -39\n",
      "Episode 4100, Total Reward: -45\n",
      "Episode 4120, Total Reward: -45\n",
      "Episode 4140, Total Reward: -51\n",
      "Episode 4160, Total Reward: -45\n",
      "Episode 4180, Total Reward: -37\n",
      "Episode 4200, Total Reward: -42\n",
      "Episode 4220, Total Reward: -42\n",
      "Episode 4240, Total Reward: -37\n",
      "Episode 4260, Total Reward: -40\n",
      "Episode 4280, Total Reward: -39\n",
      "Episode 4300, Total Reward: -40\n",
      "Episode 4320, Total Reward: -45\n",
      "Episode 4340, Total Reward: -43\n",
      "Episode 4360, Total Reward: -41\n",
      "Episode 4380, Total Reward: -49\n",
      "Episode 4400, Total Reward: -43\n",
      "Episode 4420, Total Reward: -51\n",
      "Episode 4440, Total Reward: -38\n",
      "Episode 4460, Total Reward: -43\n",
      "Episode 4480, Total Reward: -43\n",
      "Episode 4500, Total Reward: -39\n",
      "Episode 4520, Total Reward: -39\n",
      "Episode 4540, Total Reward: -42\n",
      "Episode 4560, Total Reward: -39\n",
      "Episode 4580, Total Reward: -41\n",
      "Episode 4600, Total Reward: -42\n",
      "Episode 4620, Total Reward: -46\n",
      "Episode 4640, Total Reward: -43\n",
      "Episode 4660, Total Reward: -48\n",
      "Episode 4680, Total Reward: -47\n",
      "Episode 4700, Total Reward: -45\n",
      "Episode 4720, Total Reward: -40\n",
      "Episode 4740, Total Reward: -48\n",
      "Episode 4760, Total Reward: -42\n",
      "Episode 4780, Total Reward: -46\n",
      "Episode 4800, Total Reward: -41\n",
      "Episode 4820, Total Reward: -34\n",
      "Episode 4840, Total Reward: -44\n",
      "Episode 4860, Total Reward: -50\n",
      "Episode 4880, Total Reward: -38\n",
      "Episode 4900, Total Reward: -43\n",
      "Episode 4920, Total Reward: -44\n",
      "Episode 4940, Total Reward: -42\n",
      "Episode 4960, Total Reward: -48\n",
      "Episode 4980, Total Reward: -46\n",
      "Episode 5000, Total Reward: -40\n",
      "Episode 5020, Total Reward: -40\n",
      "Episode 5040, Total Reward: -44\n",
      "Episode 5060, Total Reward: -51\n",
      "Episode 5080, Total Reward: -43\n",
      "Episode 5100, Total Reward: -44\n",
      "Episode 5120, Total Reward: -35\n",
      "Episode 5140, Total Reward: -53\n",
      "Episode 5160, Total Reward: -51\n",
      "Episode 5180, Total Reward: -39\n",
      "Episode 5200, Total Reward: -40\n",
      "Episode 5220, Total Reward: -40\n",
      "Episode 5240, Total Reward: -43\n",
      "Episode 5260, Total Reward: -40\n",
      "Episode 5280, Total Reward: -42\n",
      "Episode 5300, Total Reward: -47\n",
      "Episode 5320, Total Reward: -40\n",
      "Episode 5340, Total Reward: -40\n",
      "Episode 5360, Total Reward: -42\n",
      "Episode 5380, Total Reward: -46\n",
      "Episode 5400, Total Reward: -48\n",
      "Episode 5420, Total Reward: -45\n",
      "Episode 5440, Total Reward: -46\n",
      "Episode 5460, Total Reward: -39\n",
      "Episode 5480, Total Reward: -41\n",
      "Episode 5500, Total Reward: -36\n",
      "Episode 5520, Total Reward: -39\n",
      "Episode 5540, Total Reward: -37\n",
      "Episode 5560, Total Reward: -47\n",
      "Episode 5580, Total Reward: -36\n",
      "Episode 5600, Total Reward: -49\n",
      "Episode 5620, Total Reward: -41\n",
      "Episode 5640, Total Reward: -43\n",
      "Episode 5660, Total Reward: -39\n",
      "Episode 5680, Total Reward: -48\n",
      "Episode 5700, Total Reward: -38\n",
      "Episode 5720, Total Reward: -36\n",
      "Episode 5740, Total Reward: -43\n",
      "Episode 5760, Total Reward: -45\n",
      "Episode 5780, Total Reward: -42\n",
      "Episode 5800, Total Reward: -37\n",
      "Episode 5820, Total Reward: -44\n",
      "Episode 5840, Total Reward: -40\n",
      "Episode 5860, Total Reward: -40\n",
      "Episode 5880, Total Reward: -45\n",
      "Episode 5900, Total Reward: -41\n",
      "Episode 5920, Total Reward: -50\n",
      "Episode 5940, Total Reward: -38\n",
      "Episode 5960, Total Reward: -44\n",
      "Episode 5980, Total Reward: -38\n",
      "Episode 6000, Total Reward: -45\n",
      "Episode 6020, Total Reward: -39\n",
      "Episode 6040, Total Reward: -39\n",
      "Episode 6060, Total Reward: -38\n",
      "Episode 6080, Total Reward: -36\n",
      "Episode 6100, Total Reward: -40\n",
      "Episode 6120, Total Reward: -42\n",
      "Episode 6140, Total Reward: -46\n",
      "Episode 6160, Total Reward: -42\n",
      "Episode 6180, Total Reward: -41\n",
      "Episode 6200, Total Reward: -36\n",
      "Episode 6220, Total Reward: -42\n",
      "Episode 6240, Total Reward: -36\n",
      "Episode 6260, Total Reward: -44\n",
      "Episode 6280, Total Reward: -39\n",
      "Episode 6300, Total Reward: -40\n",
      "Episode 6320, Total Reward: -45\n",
      "Episode 6340, Total Reward: -43\n",
      "Episode 6360, Total Reward: -43\n",
      "Episode 6380, Total Reward: -37\n",
      "Episode 6400, Total Reward: -46\n",
      "Episode 6420, Total Reward: -37\n",
      "Episode 6440, Total Reward: -45\n",
      "Episode 6460, Total Reward: -40\n",
      "Episode 6480, Total Reward: -41\n",
      "Episode 6500, Total Reward: -38\n",
      "Episode 6520, Total Reward: -46\n",
      "Episode 6540, Total Reward: -37\n",
      "Episode 6560, Total Reward: -49\n",
      "Episode 6580, Total Reward: -48\n",
      "Episode 6600, Total Reward: -36\n",
      "Episode 6620, Total Reward: -39\n",
      "Episode 6640, Total Reward: -40\n",
      "Episode 6660, Total Reward: -46\n",
      "Episode 6680, Total Reward: -45\n",
      "Episode 6700, Total Reward: -45\n",
      "Episode 6720, Total Reward: -40\n",
      "Episode 6740, Total Reward: -48\n",
      "Episode 6760, Total Reward: -40\n",
      "Episode 6780, Total Reward: -50\n",
      "Episode 6800, Total Reward: -41\n",
      "Episode 6820, Total Reward: -40\n",
      "Episode 6840, Total Reward: -46\n",
      "Episode 6860, Total Reward: -43\n",
      "Episode 6880, Total Reward: -41\n",
      "Episode 6900, Total Reward: -45\n",
      "Episode 6920, Total Reward: -42\n",
      "Episode 6940, Total Reward: -44\n",
      "Episode 6960, Total Reward: -65\n",
      "Episode 6980, Total Reward: -35\n",
      "Episode 7000, Total Reward: -38\n",
      "Episode 7020, Total Reward: -49\n",
      "Episode 7040, Total Reward: -39\n",
      "Episode 7060, Total Reward: -39\n",
      "Episode 7080, Total Reward: -45\n",
      "Episode 7100, Total Reward: -45\n",
      "Episode 7120, Total Reward: -45\n",
      "Episode 7140, Total Reward: -46\n",
      "Episode 7160, Total Reward: -38\n",
      "Episode 7180, Total Reward: -47\n",
      "Episode 7200, Total Reward: -37\n",
      "Episode 7220, Total Reward: -41\n",
      "Episode 7240, Total Reward: -39\n",
      "Episode 7260, Total Reward: -41\n",
      "Episode 7280, Total Reward: -41\n",
      "Episode 7300, Total Reward: -45\n",
      "Episode 7320, Total Reward: -43\n",
      "Episode 7340, Total Reward: -40\n",
      "Episode 7360, Total Reward: -42\n",
      "Episode 7380, Total Reward: -38\n",
      "Episode 7400, Total Reward: -44\n",
      "Episode 7420, Total Reward: -45\n",
      "Episode 7440, Total Reward: -44\n",
      "Episode 7460, Total Reward: -42\n",
      "Episode 7480, Total Reward: -41\n",
      "Episode 7500, Total Reward: -42\n",
      "Episode 7520, Total Reward: -39\n",
      "Episode 7540, Total Reward: -42\n",
      "Episode 7560, Total Reward: -39\n",
      "Episode 7580, Total Reward: -41\n",
      "Episode 7600, Total Reward: -42\n",
      "Episode 7620, Total Reward: -35\n",
      "Episode 7640, Total Reward: -40\n",
      "Episode 7660, Total Reward: -47\n",
      "Episode 7680, Total Reward: -46\n",
      "Episode 7700, Total Reward: -48\n",
      "Episode 7720, Total Reward: -45\n",
      "Episode 7740, Total Reward: -39\n",
      "Episode 7760, Total Reward: -44\n",
      "Episode 7780, Total Reward: -39\n",
      "Episode 7800, Total Reward: -48\n",
      "Episode 7820, Total Reward: -41\n",
      "Episode 7840, Total Reward: -40\n",
      "Episode 7860, Total Reward: -40\n",
      "Episode 7880, Total Reward: -42\n",
      "Episode 7900, Total Reward: -41\n",
      "Episode 7920, Total Reward: -39\n",
      "Episode 7940, Total Reward: -48\n",
      "Episode 7960, Total Reward: -44\n",
      "Episode 7980, Total Reward: -46\n",
      "Episode 8000, Total Reward: -39\n",
      "Episode 8020, Total Reward: -46\n",
      "Episode 8040, Total Reward: -53\n",
      "Episode 8060, Total Reward: -42\n",
      "Episode 8080, Total Reward: -42\n",
      "Episode 8100, Total Reward: -42\n",
      "Episode 8120, Total Reward: -45\n",
      "Episode 8140, Total Reward: -39\n",
      "Episode 8160, Total Reward: -43\n",
      "Episode 8180, Total Reward: -39\n",
      "Episode 8200, Total Reward: -39\n",
      "Episode 8220, Total Reward: -47\n",
      "Episode 8240, Total Reward: -43\n",
      "Episode 8260, Total Reward: -47\n",
      "Episode 8280, Total Reward: -39\n",
      "Episode 8300, Total Reward: -44\n",
      "Episode 8320, Total Reward: -37\n",
      "Episode 8340, Total Reward: -42\n",
      "Episode 8360, Total Reward: -46\n",
      "Episode 8380, Total Reward: -43\n",
      "Episode 8400, Total Reward: -40\n",
      "Episode 8420, Total Reward: -44\n",
      "Episode 8440, Total Reward: -38\n",
      "Episode 8460, Total Reward: -42\n",
      "Episode 8480, Total Reward: -46\n",
      "Episode 8500, Total Reward: -41\n",
      "Episode 8520, Total Reward: -43\n",
      "Episode 8540, Total Reward: -40\n",
      "Episode 8560, Total Reward: -40\n",
      "Episode 8580, Total Reward: -46\n",
      "Episode 8600, Total Reward: -39\n",
      "Episode 8620, Total Reward: -42\n",
      "Episode 8640, Total Reward: -41\n",
      "Episode 8660, Total Reward: -43\n",
      "Episode 8680, Total Reward: -36\n",
      "Episode 8700, Total Reward: -37\n",
      "Episode 8720, Total Reward: -36\n",
      "Episode 8740, Total Reward: -40\n",
      "Episode 8760, Total Reward: -44\n",
      "Episode 8780, Total Reward: -52\n",
      "Episode 8800, Total Reward: -49\n",
      "Episode 8820, Total Reward: -44\n",
      "Episode 8840, Total Reward: -43\n",
      "Episode 8860, Total Reward: -43\n",
      "Episode 8880, Total Reward: -42\n",
      "Episode 8900, Total Reward: -42\n",
      "Episode 8920, Total Reward: -37\n",
      "Episode 8940, Total Reward: -43\n",
      "Episode 8960, Total Reward: -44\n",
      "Episode 8980, Total Reward: -42\n",
      "Episode 9000, Total Reward: -51\n",
      "Episode 9020, Total Reward: -45\n",
      "Episode 9040, Total Reward: -46\n",
      "Episode 9060, Total Reward: -42\n",
      "Episode 9080, Total Reward: -44\n",
      "Episode 9100, Total Reward: -46\n",
      "Episode 9120, Total Reward: -41\n",
      "Episode 9140, Total Reward: -44\n",
      "Episode 9160, Total Reward: -36\n",
      "Episode 9180, Total Reward: -43\n",
      "Episode 9200, Total Reward: -40\n",
      "Episode 9220, Total Reward: -38\n",
      "Episode 9240, Total Reward: -59\n",
      "Episode 9260, Total Reward: -39\n",
      "Episode 9280, Total Reward: -44\n",
      "Episode 9300, Total Reward: -41\n",
      "Episode 9320, Total Reward: -42\n",
      "Episode 9340, Total Reward: -48\n",
      "Episode 9360, Total Reward: -44\n",
      "Episode 9380, Total Reward: -44\n",
      "Episode 9400, Total Reward: -42\n",
      "Episode 9420, Total Reward: -39\n",
      "Episode 9440, Total Reward: -35\n",
      "Episode 9460, Total Reward: -42\n",
      "Episode 9480, Total Reward: -53\n",
      "Episode 9500, Total Reward: -51\n",
      "Episode 9520, Total Reward: -43\n",
      "Episode 9540, Total Reward: -42\n",
      "Episode 9560, Total Reward: -44\n",
      "Episode 9580, Total Reward: -40\n",
      "Episode 9600, Total Reward: -38\n",
      "Episode 9620, Total Reward: -47\n",
      "Episode 9640, Total Reward: -39\n",
      "Episode 9660, Total Reward: -36\n",
      "Episode 9680, Total Reward: -45\n",
      "Episode 9700, Total Reward: -41\n",
      "Episode 9720, Total Reward: -43\n",
      "Episode 9740, Total Reward: -39\n",
      "Episode 9760, Total Reward: -47\n",
      "Episode 9780, Total Reward: -43\n",
      "Episode 9800, Total Reward: -47\n",
      "Episode 9820, Total Reward: -51\n",
      "Episode 9840, Total Reward: -36\n",
      "Episode 9860, Total Reward: -39\n",
      "Episode 9880, Total Reward: -41\n",
      "Episode 9900, Total Reward: -47\n",
      "Episode 9920, Total Reward: -44\n",
      "Episode 9940, Total Reward: -43\n",
      "Episode 9960, Total Reward: -43\n",
      "Episode 9980, Total Reward: -37\n"
     ]
    }
   ],
   "source": [
    "## simulare the agent in the environment\n",
    "num_actions = len(env.get_wrapper_attr(\"actions\"))\n",
    "agent = tabularQlearningET(num_feature= num_features, num_actions=num_actions)\n",
    "\n",
    "num_episodes = 10000\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    obs, info = env.reset()\n",
    "    state = rep.get_features(obs)\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    agent.erase_eligibility()\n",
    "    while not done:\n",
    "        action = agent.choose_action(state)\n",
    "        next_obs, reward, done, trunc, _ = env.step(action)\n",
    "        next_state = rep.get_features(next_obs)\n",
    "        agent.update(state, action, reward, next_state)\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "    if episode % 20 == 0:\n",
    "        print(f\"Episode {episode}, Total Reward: {total_reward}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " t: 0, observation: [0.1990683  0.34000497], reward: -1\n",
      " t: 1, observation: [0.18893854 0.28541037], reward: -1\n",
      " t: 2, observation: [0.2102036  0.23854743], reward: -1\n",
      " t: 3, observation: [0.2105607  0.18982291], reward: -1\n",
      " t: 4, observation: [0.24704957 0.17697419], reward: -1\n",
      " t: 5, observation: [0.30892733 0.16661758], reward: -1\n",
      " t: 6, observation: [0.38089073 0.16949776], reward: -1\n",
      " t: 7, observation: [0.4439155  0.16016202], reward: -1\n",
      " t: 8, observation: [0.49364732 0.15383773], reward: -1\n",
      " t: 9, observation: [0.54735073 0.14762026], reward: -1\n",
      " t: 10, observation: [0.53718732 0.18165201], reward: -1\n",
      " t: 11, observation: [0.53874827 0.12206694], reward: -1\n",
      " t: 12, observation: [0.60397411 0.10741856], reward: -1\n",
      " t: 13, observation: [0.63836386 0.09987427], reward: -1\n",
      " t: 14, observation: [0.69183832 0.08142978], reward: -1\n",
      " t: 15, observation: [0.73270329 0.07611066], reward: -1\n",
      " t: 16, observation: [0.72838047 0.12042934], reward: -1\n",
      " t: 17, observation: [0.78075329 0.11011795], reward: -1\n",
      " t: 18, observation: [0.77589726 0.16593977], reward: -1\n",
      " t: 19, observation: [0.78419437 0.10399067], reward: -1\n",
      " t: 20, observation: [0.79343198 0.1647867 ], reward: -1\n",
      " t: 21, observation: [0.78733733 0.21214928], reward: -1\n",
      " t: 22, observation: [0.77419922 0.25540976], reward: -1\n",
      " t: 23, observation: [0.77255576 0.30266838], reward: -1\n",
      " t: 24, observation: [0.79474716 0.30895131], reward: -1\n",
      " t: 25, observation: [0.79698126 0.35874237], reward: -1\n",
      " t: 26, observation: [0.78651957 0.32759276], reward: -1\n",
      " t: 27, observation: [0.78945411 0.38140415], reward: -1\n",
      " t: 28, observation: [0.84629366 0.38029794], reward: -1\n",
      " t: 29, observation: [0.89741286 0.39179002], reward: -1\n",
      " t: 30, observation: [0.95483914 0.37503851], reward: -1\n",
      " t: 31, observation: [0.93957251 0.42545447], reward: -1\n",
      " t: 32, observation: [0.95964112 0.49154254], reward: -1\n",
      " t: 33, observation: [0.95151996 0.54621536], reward: -1\n",
      " t: 34, observation: [0.9541154  0.59921473], reward: -1\n",
      " t: 35, observation: [0.9580449  0.64006885], reward: -1\n",
      " t: 36, observation: [0.95397285 0.67659257], reward: -1\n",
      " t: 37, observation: [0.96813098 0.73186163], reward: -1\n",
      " t: 38, observation: [0.96347452 0.77683385], reward: -1\n",
      " t: 39, observation: [0.94810883 0.84014439], reward: -1\n",
      " t: 40, observation: [0.95333858 0.89456487], reward: -1\n",
      " t: 41, observation: [0.95009677 0.9565698 ], reward: 0\n",
      "total reward in this episode: -41\n",
      "episode 0: reward: -41\n"
     ]
    }
   ],
   "source": [
    "obs, info = env.reset()\n",
    "total_reward = 0\n",
    "episode_rewards = []\n",
    "frames = []\n",
    "observation = obs\n",
    "\n",
    "max_video_length = 120\n",
    "\n",
    "\n",
    "for time_step in range(max_video_length):\n",
    "    frames.append(env.render())\n",
    "\n",
    "    #action = greedy_policy(get_features(observation))\n",
    "    action = agent.choose_action(rep.get_features(observation))\n",
    "    observation, reward, done, trunc, _ = env.step(action)\n",
    "    total_reward += reward\n",
    "    image = env.render()\n",
    "    #online_rendering(image) #uncomment this line to see the online rendering of the environment frame by frame\n",
    "    frames.append(image)\n",
    "\n",
    "    print(f\" t: {time_step}, observation: {observation}, reward: {reward}\") #uncomment this line to see the environment-agent interaction details\n",
    "\n",
    "    if done:\n",
    "      print(f\"total reward in this episode: {total_reward}\")\n",
    "      episode_rewards.append(total_reward)\n",
    "      total_reward = 0\n",
    "      break\n",
    "\n",
    "env.close()\n",
    "\n",
    "if episode_rewards == []:\n",
    "  print(\"no episode finished in this run.\")\n",
    "else:\n",
    "  for i, reward in enumerate(episode_rewards):\n",
    "    print(f\"episode {i}: reward: {reward}\")\n",
    "\n",
    "visualize(frames, \"./Video/q_learning_Kan_ET.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self, input_dim, output_dim, alpha=0.001, gamma=0.99, epsilon=0.05):\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.q_network = DQN(input_dim, output_dim).to(self.device)\n",
    "        self.target_network = DQN(input_dim, output_dim).to(self.device)\n",
    "        self.target_network.load_state_dict(self.q_network.state_dict())\n",
    "        self.target_network.eval()\n",
    "\n",
    "        self.optimizer = optim.Adam(self.q_network.parameters(), lr=alpha)\n",
    "        self.loss_function = nn.MSELoss()\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        state = torch.FloatTensor(state).to(self.device)\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            return np.random.randint(0, self.output_dim)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                q_values = self.q_network(state)\n",
    "                return torch.argmax(q_values).item()\n",
    "    \n",
    "    def update(self, state, action, reward, next_state, done):\n",
    "        state = torch.FloatTensor(state).to(self.device)\n",
    "        action = torch.LongTensor([action]).to(self.device)\n",
    "        reward = torch.FloatTensor([reward]).to(self.device)\n",
    "        next_state = torch.FloatTensor(next_state).to(self.device)\n",
    "        done = torch.FloatTensor([done]).to(self.device)\n",
    "\n",
    "        q_value = self.q_network(state)[action]\n",
    "        next_q_value = self.target_network(next_state.unsqueeze(0)).max(1)[0]\n",
    "        target_q_value = reward + (1 - done) * self.gamma * next_q_value\n",
    "\n",
    "        loss = self.loss_function(q_value, target_q_value.detach())\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "\n",
    "    def update_target_network(self):\n",
    "        self.target_network.load_state_dict(self.q_network.state_dict())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/73/1wstfjwn76s193_38n9l19_h0000gn/T/ipykernel_20113/434083990.py:50: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  done = torch.FloatTensor([done]).to(self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0, Total Reward: -100\n",
      "Episode 20, Total Reward: -100\n",
      "Episode 40, Total Reward: -100\n",
      "Episode 60, Total Reward: -100\n",
      "Episode 80, Total Reward: -100\n",
      "Episode 100, Total Reward: -100\n",
      "Episode 120, Total Reward: -100\n",
      "Episode 140, Total Reward: -100\n",
      "Episode 160, Total Reward: -100\n",
      "Episode 180, Total Reward: -939.7736695997875\n",
      "Episode 200, Total Reward: -100\n",
      "Episode 220, Total Reward: -100\n",
      "Episode 240, Total Reward: -100\n",
      "Episode 260, Total Reward: -100\n",
      "Episode 280, Total Reward: -100\n",
      "Episode 300, Total Reward: -100\n",
      "Episode 320, Total Reward: -100\n",
      "Episode 340, Total Reward: -100\n",
      "Episode 360, Total Reward: -286.673586605981\n",
      "Episode 380, Total Reward: -100\n",
      "Episode 400, Total Reward: -896.7924275634095\n",
      "Episode 420, Total Reward: -858.6589824978024\n",
      "Episode 440, Total Reward: -538.0\n",
      "Episode 460, Total Reward: -851.469463598962\n",
      "Episode 480, Total Reward: -100\n",
      "Episode 500, Total Reward: -100\n",
      "Episode 520, Total Reward: -100\n",
      "Episode 540, Total Reward: -100\n",
      "Episode 560, Total Reward: -877.2126890053612\n",
      "Episode 580, Total Reward: -100\n",
      "Episode 600, Total Reward: -100\n",
      "Episode 620, Total Reward: -100\n",
      "Episode 640, Total Reward: -678.3395950462311\n",
      "Episode 660, Total Reward: -100\n",
      "Episode 680, Total Reward: -100\n",
      "Episode 700, Total Reward: -100\n",
      "Episode 720, Total Reward: -702.0665098081458\n",
      "Episode 740, Total Reward: -570.7874066813421\n",
      "Episode 760, Total Reward: -100\n",
      "Episode 780, Total Reward: -889.5801082216765\n",
      "Episode 800, Total Reward: -1145.8296291603751\n",
      "Episode 820, Total Reward: -100\n",
      "Episode 840, Total Reward: -100\n",
      "Episode 860, Total Reward: -100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[100], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m next_obs, reward, done, _, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m     17\u001b[0m next_state \u001b[38;5;241m=\u001b[39m rep\u001b[38;5;241m.\u001b[39mget_features(next_obs)\n\u001b[0;32m---> 18\u001b[0m agent\u001b[38;5;241m.\u001b[39mupdate(state, action, reward, next_state, done)\n\u001b[1;32m     19\u001b[0m state \u001b[38;5;241m=\u001b[39m next_state\n\u001b[1;32m     20\u001b[0m total_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n",
      "Cell \u001b[0;32mIn[96], line 59\u001b[0m, in \u001b[0;36mDQNAgent.update\u001b[0;34m(self, state, action, reward, next_state, done)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     58\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 59\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/optim/optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    382\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    383\u001b[0m             )\n\u001b[0;32m--> 385\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/optim/adam.py:166\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    155\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    157\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    158\u001b[0m         group,\n\u001b[1;32m    159\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    163\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    164\u001b[0m         state_steps)\n\u001b[0;32m--> 166\u001b[0m     adam(\n\u001b[1;32m    167\u001b[0m         params_with_grad,\n\u001b[1;32m    168\u001b[0m         grads,\n\u001b[1;32m    169\u001b[0m         exp_avgs,\n\u001b[1;32m    170\u001b[0m         exp_avg_sqs,\n\u001b[1;32m    171\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    172\u001b[0m         state_steps,\n\u001b[1;32m    173\u001b[0m         amsgrad\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamsgrad\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    174\u001b[0m         has_complex\u001b[38;5;241m=\u001b[39mhas_complex,\n\u001b[1;32m    175\u001b[0m         beta1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[1;32m    176\u001b[0m         beta2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[1;32m    177\u001b[0m         lr\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    178\u001b[0m         weight_decay\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    179\u001b[0m         eps\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meps\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    180\u001b[0m         maximize\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    181\u001b[0m         foreach\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforeach\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    182\u001b[0m         capturable\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcapturable\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    183\u001b[0m         differentiable\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    184\u001b[0m         fused\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfused\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    185\u001b[0m         grad_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad_scale\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    186\u001b[0m         found_inf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    187\u001b[0m     )\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/optim/adam.py:316\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    314\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 316\u001b[0m func(params,\n\u001b[1;32m    317\u001b[0m      grads,\n\u001b[1;32m    318\u001b[0m      exp_avgs,\n\u001b[1;32m    319\u001b[0m      exp_avg_sqs,\n\u001b[1;32m    320\u001b[0m      max_exp_avg_sqs,\n\u001b[1;32m    321\u001b[0m      state_steps,\n\u001b[1;32m    322\u001b[0m      amsgrad\u001b[38;5;241m=\u001b[39mamsgrad,\n\u001b[1;32m    323\u001b[0m      has_complex\u001b[38;5;241m=\u001b[39mhas_complex,\n\u001b[1;32m    324\u001b[0m      beta1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[1;32m    325\u001b[0m      beta2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[1;32m    326\u001b[0m      lr\u001b[38;5;241m=\u001b[39mlr,\n\u001b[1;32m    327\u001b[0m      weight_decay\u001b[38;5;241m=\u001b[39mweight_decay,\n\u001b[1;32m    328\u001b[0m      eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[1;32m    329\u001b[0m      maximize\u001b[38;5;241m=\u001b[39mmaximize,\n\u001b[1;32m    330\u001b[0m      capturable\u001b[38;5;241m=\u001b[39mcapturable,\n\u001b[1;32m    331\u001b[0m      differentiable\u001b[38;5;241m=\u001b[39mdifferentiable,\n\u001b[1;32m    332\u001b[0m      grad_scale\u001b[38;5;241m=\u001b[39mgrad_scale,\n\u001b[1;32m    333\u001b[0m      found_inf\u001b[38;5;241m=\u001b[39mfound_inf)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/optim/adam.py:439\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    437\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (exp_avg_sq\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    441\u001b[0m     param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n\u001b[1;32m    443\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the agent\n",
    "num_actions = len(env.get_wrapper_attr(\"actions\"))\n",
    "agent = DQNAgent(n_closest, num_actions, alpha=0.001, gamma=0.99, epsilon=0.05)\n",
    "\n",
    "num_episodes = 1000\n",
    "max_steps = 100\n",
    "update_target_network_every = 10\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    obs, info = env.reset()\n",
    "    state = rep.get_features(obs)\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    for step in range(max_steps):\n",
    "        action = agent.choose_action(state)\n",
    "        next_obs, reward, done, _, _ = env.step(action)\n",
    "        next_state = rep.get_features(next_obs)\n",
    "        agent.update(state, action, reward, next_state, done)\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "        if done:\n",
    "            break\n",
    "    if episode % update_target_network_every == 0:\n",
    "        agent.update_target_network()\n",
    "    if episode % 20 == 0:\n",
    "        print(f\"Episode {episode}, Total Reward: {total_reward}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HRL MAXQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([810,  22, 268, 276, 545, 107, 398, 582])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rep.get_features(env.reset()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 8 is out of bounds for axis 0 with size 8",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 103\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(episodes):\n\u001b[1;32m    102\u001b[0m     agent\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m--> 103\u001b[0m     agent\u001b[38;5;241m.\u001b[39mMAXQ_0(agent\u001b[38;5;241m.\u001b[39mroot, agent\u001b[38;5;241m.\u001b[39mrep\u001b[38;5;241m.\u001b[39mget_features(env\u001b[38;5;241m.\u001b[39mreset()[\u001b[38;5;241m0\u001b[39m]))  \u001b[38;5;66;03m# start in root\u001b[39;00m\n\u001b[1;32m    104\u001b[0m     sum_list\u001b[38;5;241m.\u001b[39mappend(agent\u001b[38;5;241m.\u001b[39mr_sum)\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m j \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[42], line 79\u001b[0m, in \u001b[0;36mPuddleWorldHRLAgent.MAXQ_0\u001b[0;34m(self, i, s_features)\u001b[0m\n\u001b[1;32m     77\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_terminal(i, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone):\n\u001b[0;32m---> 79\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgreed_act(i, s_features)\n\u001b[1;32m     80\u001b[0m     N \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mMAXQ_0(a, s_features)\n\u001b[1;32m     81\u001b[0m     evaluate_res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate(i, s_features)\n",
      "Cell \u001b[0;32mIn[42], line 61\u001b[0m, in \u001b[0;36mPuddleWorldHRLAgent.greed_act\u001b[0;34m(self, act, s_features)\u001b[0m\n\u001b[1;32m     59\u001b[0m e \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.001\u001b[39m\n\u001b[1;32m     60\u001b[0m possible_a \u001b[38;5;241m=\u001b[39m [act2 \u001b[38;5;28;01mfor\u001b[39;00m act2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph[act] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_primitive(act2) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_terminal(act2, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone)]\n\u001b[0;32m---> 61\u001b[0m Q \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mV[act2, s_features] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mC[act, s_features, act2] \u001b[38;5;28;01mfor\u001b[39;00m act2 \u001b[38;5;129;01min\u001b[39;00m possible_a])\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand() \u001b[38;5;241m<\u001b[39m e:\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(possible_a)\n",
      "Cell \u001b[0;32mIn[42], line 61\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     59\u001b[0m e \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.001\u001b[39m\n\u001b[1;32m     60\u001b[0m possible_a \u001b[38;5;241m=\u001b[39m [act2 \u001b[38;5;28;01mfor\u001b[39;00m act2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph[act] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_primitive(act2) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_terminal(act2, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone)]\n\u001b[0;32m---> 61\u001b[0m Q \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mV[act2, s_features] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mC[act, s_features, act2] \u001b[38;5;28;01mfor\u001b[39;00m act2 \u001b[38;5;129;01min\u001b[39;00m possible_a])\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand() \u001b[38;5;241m<\u001b[39m e:\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(possible_a)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 8 is out of bounds for axis 0 with size 8"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import copy\n",
    "from util.kanerva import BaseKanervaCoder\n",
    "\n",
    "class PuddleWorldHRLAgent:\n",
    "    def __init__(self, env, rep, alpha, gamma):\n",
    "        self.env = env\n",
    "        self.rep = rep\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.num_features = len(rep.get_features(self.env.reset()[0]))  # Use env.reset() to ensure proper initialization\n",
    "        self.V = np.zeros((self.num_features, env.action_space.n))\n",
    "        self.C = np.zeros((self.num_features, env.action_space.n, env.action_space.n))\n",
    "        \n",
    "        self.graph = self.build_graph()\n",
    "        self.root = len(self.graph) - 1\n",
    "\n",
    "        \n",
    "\n",
    "    def build_graph(self):\n",
    "        # Define the graph structure for the HRL agent\n",
    "        graph = [\n",
    "            set(),  # move_down\n",
    "            set(),  # move_up\n",
    "            set(),  # move_left\n",
    "            set(),  # move_right\n",
    "            set(),  # avoid_puddle\n",
    "            set(),  # go_to_goal\n",
    "            {0, 1, 2, 3},  # navigate\n",
    "            {4},  # avoid_puddle\n",
    "            {5},  # go_to_goal\n",
    "            {6, 7, 8},  # root\n",
    "        ]\n",
    "        return graph\n",
    "\n",
    "    def is_primitive(self, act):\n",
    "        return act < 4\n",
    "\n",
    "    def is_terminal(self, a, done):\n",
    "        if done:\n",
    "            return True\n",
    "        elif a == 4:  # avoid_puddle\n",
    "            return self.env.is_puddle(self.env.s)\n",
    "        elif a == 5:  # go_to_goal\n",
    "            return self.env.is_goal(self.env.s)\n",
    "        return False\n",
    "\n",
    "    def evaluate(self, act, s_features):\n",
    "        if self.is_primitive(act):\n",
    "            return self.V[act, s_features]\n",
    "        else:\n",
    "            for j in self.graph[act]:\n",
    "                self.V[j, s_features] = self.evaluate(j, s_features)\n",
    "            Q = np.array([self.V[a2, s_features] for a2 in self.graph[act]])\n",
    "            return np.max(Q)\n",
    "\n",
    "    def greed_act(self, act, s_features):\n",
    "        e = 0.001\n",
    "        possible_a = [act2 for act2 in self.graph[act] if self.is_primitive(act2) or not self.is_terminal(act2, self.done)]\n",
    "        Q = np.array([self.V[act2, s_features] + self.C[act, s_features, act2] for act2 in possible_a])\n",
    "        if np.random.rand() < e:\n",
    "            return np.random.choice(possible_a)\n",
    "        return possible_a[np.argmax(Q)]\n",
    "\n",
    "    def MAXQ_0(self, i, s_features):\n",
    "        if self.done:\n",
    "            i = self.num_features  # to end recursion\n",
    "        self.done = False\n",
    "        if self.is_primitive(i):\n",
    "            self.new_s, r, self.done, _ = self.env.step(i)\n",
    "            self.r_sum += r\n",
    "            self.num_of_ac += 1\n",
    "            self.V[i, s_features] += self.alpha * (r + self.gamma * self.V[i, s_features] - self.V[i, s_features])\n",
    "            return 1\n",
    "        else:\n",
    "            count = 0\n",
    "            while not self.is_terminal(i, self.done):\n",
    "                a = self.greed_act(i, s_features)\n",
    "                N = self.MAXQ_0(a, s_features)\n",
    "                evaluate_res = self.evaluate(i, s_features)\n",
    "                self.C[i, s_features, a] += self.alpha * (self.gamma ** N * evaluate_res - self.C[i, s_features, a])\n",
    "                count += N\n",
    "                s_features = self.rep.get_features(self.new_s)\n",
    "            return count\n",
    "\n",
    "    def reset(self):\n",
    "        self.env.reset()\n",
    "        self.r_sum = 0\n",
    "        self.num_of_ac = 0\n",
    "        self.done = False\n",
    "        self.new_s = self.rep.get_features(self.env.reset()[0])\n",
    "\n",
    "\n",
    "alpha = 0.2\n",
    "gamma = 0.99  # Changed from 1 to a typical discount factor less than 1\n",
    " \n",
    "agent = PuddleWorldHRLAgent(env, rep, alpha, gamma)\n",
    "episodes = 5001\n",
    "sum_list = []\n",
    "for j in range(episodes):\n",
    "    agent.reset()\n",
    "    agent.MAXQ_0(agent.root, agent.rep.get_features(env.reset()[0]))  # start in root\n",
    "    sum_list.append(agent.r_sum)\n",
    "    if j % 1000 == 0:\n",
    "        print('already made', j, 'episodes')\n",
    "\n",
    "# Plot the results\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(sum_list)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Reward')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REINFORCE Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "tensor(1) (<class 'torch.Tensor'>) invalid",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[207], line 68\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m episode \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m20\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     66\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpisode \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepisode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Total Reward: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_reward\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 68\u001b[0m train(env, num_episodes, feature_dim, num_actions)\n",
      "Cell \u001b[0;32mIn[207], line 60\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(env, num_episodes, feature_dim, num_actions)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[1;32m     59\u001b[0m     action \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mget_action(state)\n\u001b[0;32m---> 60\u001b[0m     next_obs, reward, done, trunc, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m     61\u001b[0m     next_state \u001b[38;5;241m=\u001b[39m rep\u001b[38;5;241m.\u001b[39mget_features(next_obs)\n\u001b[1;32m     62\u001b[0m     agent\u001b[38;5;241m.\u001b[39mupdate(state, action, reward)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/gymnasium/wrappers/order_enforcing.py:56\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep(action)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/gymnasium/wrappers/env_checker.py:49\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchecked_step:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchecked_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, action)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep(action)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:208\u001b[0m, in \u001b[0;36menv_step_passive_checker\u001b[0;34m(env, action)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"A passive check for the environment step, investigating the returning data then returning the data unchanged.\"\"\"\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;66;03m# We don't check the action as for some environments then out-of-bounds values can be given\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m result \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    210\u001b[0m     result, \u001b[38;5;28mtuple\u001b[39m\n\u001b[1;32m    211\u001b[0m ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpects step result to be a tuple, actual type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(result)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(result) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m:\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-UniversityofCalgary/@upperboundCompetition/gym-puddle/gym_puddle/env/puddle_env.py:77\u001b[0m, in \u001b[0;36mPuddleEnv.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     76\u001b[0m trunc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;66;03m# we don't have a truncation condition for this environment\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mcontains(action), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) invalid\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\n\u001b[1;32m     78\u001b[0m     action,\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28mtype\u001b[39m(action),\n\u001b[1;32m     80\u001b[0m )\n\u001b[1;32m     82\u001b[0m noise \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnp_random\u001b[38;5;241m.\u001b[39mnormal(loc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m, scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnoise, size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m,))\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactions[action] \u001b[38;5;241m+\u001b[39m noise\n",
      "\u001b[0;31mAssertionError\u001b[0m: tensor(1) (<class 'torch.Tensor'>) invalid"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "feature_dim = 8\n",
    "\n",
    "class Policy(nn.Module):\n",
    "    def __init__(self, feature_dim, num_actions):\n",
    "        super(Policy, self).__init__()\n",
    "        self.fc1 = nn.Linear(feature_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, num_actions)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class REINFORCE:\n",
    "    def __init__(self, feature_dim, num_actions, lr=0.01):\n",
    "        self.feature_dim = feature_dim\n",
    "        self.num_actions = num_actions\n",
    "        self.policy = Policy(self.feature_dim, num_actions)\n",
    "        self.optimizer = optim.Adam(self.policy.parameters(), lr=lr)\n",
    "\n",
    "    def get_policy(self, state):\n",
    "        state = torch.tensor(state).float().unsqueeze(0).unsqueeze(0)  # Add a batch dimension and a channel dimension\n",
    "        return self.policy(state)\n",
    "\n",
    "    def update(self, state, action, reward):\n",
    "        policy = self.get_policy(state)\n",
    "        log_prob = torch.log(policy[0, action])\n",
    "        loss = -log_prob * reward\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def get_action(self, state):\n",
    "        policy = self.get_policy(state)\n",
    "        \n",
    "        # Apply softmax to convert scores into probabilities\n",
    "        policy_probs = F.softmax(policy, dim=-1)\n",
    "\n",
    "        # Flatten the policy tensor to 1D\n",
    "        flattened_policy_probs = policy_probs.view(-1)\n",
    "\n",
    "        # Sample from the flattened policy tensor\n",
    "        return torch.multinomial(flattened_policy_probs, 1)[0]\n",
    "\n",
    "def train(env, num_episodes, feature_dim, num_actions):\n",
    "    agent = REINFORCE(feature_dim, num_actions)\n",
    "    for episode in range(num_episodes):\n",
    "        obs, info = env.reset()\n",
    "        state = rep.get_features(obs)\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "        while not done:\n",
    "            action = agent.get_action(state)\n",
    "            next_obs, reward, done, trunc, _ = env.step(action)\n",
    "            next_state = rep.get_features(next_obs)\n",
    "            agent.update(state, action, reward)\n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "        if episode % 20 == 0:\n",
    "            print(f\"Episode {episode}, Total Reward: {total_reward}\")\n",
    "\n",
    "train(env, num_episodes, feature_dim, num_actions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
